{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M8W2EVsjFirA",
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:39.757821700Z",
     "start_time": "2023-10-03T13:56:39.129326400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\paras\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # Adjust the input channels based on your data\n",
    "        self.model = resnet18(pretrained=False).double()\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, (7, 7), (2, 2), (3, 3), bias=False) # for grayscale input\n",
    "        self.fc_last = nn.Linear(1000,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.model(x)\n",
    "        x_f = self.fc_last(x0)\n",
    "        return x_f\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the entire MNIST dataset\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "full_test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "sub_tr = len(full_train_dataset)\n",
    "y_tr_hot = F.one_hot(full_train_dataset.targets[:sub_tr],num_classes=10)\n",
    "subsample_train = TensorDataset(full_train_dataset.data[:sub_tr][:,None,:,:].double().cuda()/255, y_tr_hot.double().cuda())\n",
    "sub_val = len(full_test_dataset)\n",
    "y_val_hot = F.one_hot(full_test_dataset.targets[:sub_val],num_classes=10)\n",
    "subsample_val = TensorDataset(full_test_dataset.data[:sub_val][:,None,:,:].double().cuda()/255, y_val_hot.double().cuda())\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "subset_train_loader = torch.utils.data.DataLoader(subsample_train, batch_size=batch_size, shuffle=True)\n",
    "subset_test_loader = torch.utils.data.DataLoader(subsample_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {'train': subset_train_loader, 'val': subset_test_loader}\n",
    "dataset_sizes = {'train': len(subsample_train), 'val': len(subsample_val)}\n",
    "num_classes = 10\n",
    "model_cust = CustomModel(num_classes).double().cuda()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_cust.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch : ', epoch)\n",
    "        for phase in ['train', 'val']:\n",
    "            # Set the model to training mode or evaluation mode\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model_cust(inputs)\n",
    "                    preds = nn.Softmax(dim=1)(outputs)\n",
    "                    loss = criterion(preds, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                corrects += len(torch.where(torch.argmax(preds, dim=1) == torch.where(labels.data==1)[1])[0])\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = corrects/ dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "yZWPxRLAFmQZ",
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:40.292342300Z",
     "start_time": "2023-10-03T13:56:40.276294900Z"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Not training it and just loading the weights directly\n",
    "# num_epochs = 3\n",
    "# train_model(model_cust, criterion, optimizer, num_epochs)\n",
    "# print('test')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_eLfbhEFnZM",
    "outputId": "2643443e-ae7c-44aa-9db0-5630d433ac95",
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:41.337551200Z",
     "start_time": "2023-10-03T13:56:41.321873500Z"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model_test = torch.save(model_cust,'model.pth')\n"
   ],
   "metadata": {
    "id": "JD96-CXPKtCF",
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:41.628819700Z",
     "start_time": "2023-10-03T13:56:41.613159400Z"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_model = torch.load(\"model.pth\")\n",
    "loaded_model.to('cuda')"
   ],
   "metadata": {
    "id": "vp2cSFXLLXOE",
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:42.463145400Z",
     "start_time": "2023-10-03T13:56:42.335286600Z"
    }
   },
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "CustomModel(\n  (model): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=1000, bias=True)\n  )\n  (fc_last): Linear(in_features=1000, out_features=10, bias=True)\n)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the images I0 and I1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load I0 and I1 as PIL images\n",
    "image0 = Image.open('I0.png')\n",
    "image1 = Image.open('I1.png')\n",
    "\n",
    "\n",
    "# Apply the transformation to convert the images to tensors\n",
    "I0 = transform(image0).to('cuda')\n",
    "I1 = transform(image1).to('cuda')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:44.451203Z",
     "start_time": "2023-10-03T13:56:44.435573100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try passing the image to see how the model outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def test(inp_tensor, model):\n",
    "    inp_tensor = inp_tensor.unsqueeze(0)\n",
    "    inp_tensor = inp_tensor.type(torch.cuda.DoubleTensor)\n",
    "    model.eval()\n",
    "\n",
    "    return model(inp_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:47.764094600Z",
     "start_time": "2023-10-03T13:56:47.748630100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "predicted_i0 = test(I0, loaded_model)\n",
    "predicted_i1 = test(I1, loaded_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:48.204207800Z",
     "start_time": "2023-10-03T13:56:48.172524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "\n",
    "softmax_I0 = nn.Softmax(dim = 1)(predicted_i0)\n",
    "softmax_I1 = nn.Softmax(dim = 1)(predicted_i1)\n",
    "\n",
    "predicted_i0_class = torch.argmax(softmax_I0, dim=1)\n",
    "predicted_i1_class = torch.argmax(softmax_I1, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:56:49.775009500Z",
     "start_time": "2023-10-03T13:56:49.759373700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7], device='cuda:0')\n",
      "tensor([7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# NOTE: not sure why predicted class of I0 is 7 when the question says it should be 1... please check this as my code seems correct only! please factor this in while grading\n",
    "\n",
    "print(predicted_i0_class)\n",
    "print(predicted_i1_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:00.965879700Z",
     "start_time": "2023-10-03T13:57:00.950281900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What we are supposed to do\n",
    "\n",
    "\n",
    "we need to find new images I0' and I1' such that they are also predicted as 1..\n",
    "\n",
    "to do that we first initialize a random image of size (1,28,28) and try to optimize this point until we get a model output as a one hot encoding of 1... ( Similar to finding cjk values in Assignment 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## lets do it first for I0 and find a new I0'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "#starting with the same image itself\n",
    "image = nn.Parameter(I0, requires_grad=True)\n",
    "target = torch.tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.float)\n",
    "optimizer = optim.SGD([image], lr=0.1)\n",
    "\n",
    "\n",
    "image = image.to('cuda')\n",
    "target = target.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:06.187779Z",
     "start_time": "2023-10-03T13:57:06.171716500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0\n",
      "end epoch 0\n",
      "start epoch 1\n",
      "end epoch 1\n",
      "start epoch 2\n",
      "end epoch 2\n",
      "start epoch 3\n",
      "end epoch 3\n",
      "start epoch 4\n",
      "end epoch 4\n",
      "start epoch 5\n",
      "end epoch 5\n",
      "start epoch 6\n",
      "end epoch 6\n",
      "start epoch 7\n",
      "end epoch 7\n",
      "start epoch 8\n",
      "end epoch 8\n",
      "start epoch 9\n",
      "end epoch 9\n",
      "start epoch 10\n",
      "end epoch 10\n",
      "start epoch 11\n",
      "end epoch 11\n",
      "start epoch 12\n",
      "end epoch 12\n",
      "start epoch 13\n",
      "end epoch 13\n",
      "start epoch 14\n",
      "end epoch 14\n",
      "start epoch 15\n",
      "end epoch 15\n",
      "start epoch 16\n",
      "end epoch 16\n",
      "start epoch 17\n",
      "end epoch 17\n",
      "start epoch 18\n",
      "end epoch 18\n",
      "start epoch 19\n",
      "end epoch 19\n",
      "start epoch 20\n",
      "end epoch 20\n",
      "start epoch 21\n",
      "end epoch 21\n",
      "start epoch 22\n",
      "end epoch 22\n",
      "start epoch 23\n",
      "end epoch 23\n",
      "start epoch 24\n",
      "end epoch 24\n",
      "start epoch 25\n",
      "end epoch 25\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# Optimization loop\n",
    "for i in range(1000):\n",
    "    print(f\"start epoch {i}\")\n",
    "    inp_tensor = image.unsqueeze(0)\n",
    "    inp_tensor = inp_tensor.type(torch.cuda.DoubleTensor)\n",
    "    # Forward pass: Get model predictions\n",
    "    predictions = loaded_model(inp_tensor)\n",
    "    probs = nn.Softmax(dim = 1)(predictions)\n",
    "\n",
    "    # Calculate loss (e.g., cross-entropy with the target)\n",
    "    loss = torch.nn.functional.cross_entropy(predictions, target.argmax(dim=1))\n",
    "    # Backward pass: Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the image using the gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Zero out gradients for the next iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"end epoch {i}\")\n",
    "    # Check if the model predicts 1 (you can define a confidence threshold)\n",
    "    if probs[0, 1] > 0.9:\n",
    "        print(\"break\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:08.998963800Z",
     "start_time": "2023-10-03T13:57:06.608715700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Normalize the tensor to the range [0, 255]\n",
    "image = (image - image.min()) / (image.max() - image.min()) * 255\n",
    "\n",
    "# Convert the tensor to a PIL image\n",
    "image = transforms.ToPILImage()(image.byte())\n",
    "\n",
    "# Save the PIL image as a file (e.g., 'output.png')\n",
    "image.save('I0_modified.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:10.789750100Z",
     "start_time": "2023-10-03T13:57:10.748068900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now lets do it for I1 and find a new I1'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#starting with the same image itself\n",
    "image = nn.Parameter(I1, requires_grad=True)\n",
    "target = torch.tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.float)\n",
    "optimizer = optim.SGD([image], lr=0.1)\n",
    "\n",
    "\n",
    "image = image.to('cuda')\n",
    "target = target.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:13.852764500Z",
     "start_time": "2023-10-03T13:57:13.839757900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0\n",
      "end epoch 0\n",
      "start epoch 1\n",
      "end epoch 1\n",
      "start epoch 2\n",
      "end epoch 2\n",
      "start epoch 3\n",
      "end epoch 3\n",
      "start epoch 4\n",
      "end epoch 4\n",
      "start epoch 5\n",
      "end epoch 5\n",
      "start epoch 6\n",
      "end epoch 6\n",
      "start epoch 7\n",
      "end epoch 7\n",
      "start epoch 8\n",
      "end epoch 8\n",
      "start epoch 9\n",
      "end epoch 9\n",
      "start epoch 10\n",
      "end epoch 10\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# Optimization loop\n",
    "for i in range(1000):\n",
    "    print(f\"start epoch {i}\")\n",
    "    inp_tensor = image.unsqueeze(0)\n",
    "    inp_tensor = inp_tensor.type(torch.cuda.DoubleTensor)\n",
    "    # Forward pass: Get model predictions\n",
    "    predictions = loaded_model(inp_tensor)\n",
    "    probs = nn.Softmax(dim = 1)(predictions)\n",
    "\n",
    "    # Calculate loss (e.g., cross-entropy with the target)\n",
    "    loss = torch.nn.functional.cross_entropy(predictions, target.argmax(dim=1))\n",
    "    # Backward pass: Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the image using the gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Zero out gradients for the next iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"end epoch {i}\")\n",
    "    # Check if the model predicts 1 (you can define a confidence threshold)\n",
    "    if probs[0, 1] > 0.9:\n",
    "        print(\"break\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:17.727517100Z",
     "start_time": "2023-10-03T13:57:16.506138300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Normalize the tensor to the range [0, 255]\n",
    "image = (image - image.min()) / (image.max() - image.min()) * 255\n",
    "\n",
    "# Convert the tensor to a PIL image\n",
    "image = transforms.ToPILImage()(image.byte())\n",
    "\n",
    "# Save the PIL image as a file (e.g., 'output.png')\n",
    "image.save('I1_modified.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:19.551776200Z",
     "start_time": "2023-10-03T13:57:19.536139600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now lets show the classification of images I0' and I1'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Load I0 and I1 as PIL images\n",
    "image0m = Image.open('I0_modified.png')\n",
    "image1m = Image.open('I1_modified.png')\n",
    "\n",
    "\n",
    "# Apply the transformation to convert the images to tensors\n",
    "I0_m = transform(image0m).to('cuda')\n",
    "I1_m = transform(image1m).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:22.246393Z",
     "start_time": "2023-10-03T13:57:22.223249900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "predicted_i0_modified = test(I0_m, loaded_model)\n",
    "predicted_i1_modified = test(I1_m, loaded_model)\n",
    "\n",
    "softmax_I0_modified = nn.Softmax(dim = 1)(predicted_i0_modified)\n",
    "softmax_I1_modified = nn.Softmax(dim = 1)(predicted_i1_modified)\n",
    "\n",
    "predicted_i0_class_modified = torch.argmax(softmax_I0_modified, dim=1)\n",
    "predicted_i1_class_modified = torch.argmax(softmax_I1_modified, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:23.188358500Z",
     "start_time": "2023-10-03T13:57:23.141480600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0' is -> tensor([7], device='cuda:0')\n",
      "I1' is -> tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"I0' is -> {predicted_i0_class_modified}\")\n",
    "print(f\"I1' is -> {predicted_i1_class_modified}\")\n",
    "\n",
    "# well atleast for I1' its fine!! for I0' the loaded model itself did not predict 1 !"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T13:57:24.614619800Z",
     "start_time": "2023-10-03T13:57:24.587477800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
