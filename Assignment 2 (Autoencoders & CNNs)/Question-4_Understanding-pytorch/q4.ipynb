{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:04.933905600Z",
     "start_time": "2023-09-30T12:57:01.073490100Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <u>Compare functions one by one</u>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. MaxPool1d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3731, 0.9901, 0.3004, 0.9839],\n        [0.1905, 0.2237, 0.6336, 0.2609],\n        [0.4826, 0.7048, 0.6619, 0.7387]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some random input\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:04.973897200Z",
     "start_time": "2023-09-30T12:57:04.933905600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9901, 0.9901, 0.9839],\n        [0.2237, 0.6336, 0.6336],\n        [0.7048, 0.7048, 0.7387]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pytorch equivalent\n",
    "pytorch_max_pool_fn = nn.MaxPool1d(kernel_size=2, stride=1, padding=0,dilation=1, return_indices=False, ceil_mode=False)\n",
    "output_from_pytorch = pytorch_max_pool_fn(random_tensor)\n",
    "output_from_pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.047809900Z",
     "start_time": "2023-09-30T12:57:04.973897200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9901, 0.9901, 0.9839],\n        [0.2237, 0.6336, 0.6336],\n        [0.7048, 0.7048, 0.7387]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define my custom implementation of maxPool1d ( assumes that x is 2D (C,W) shape)\n",
    "def my_MaxPool1d(x, kernel_size=2, stride=1, padding=0, dilation=1):\n",
    "    result = []\n",
    "    for row in x:\n",
    "        maxPoolForRow = []\n",
    "        #k represents start point of the kernel\n",
    "        for k in range(0, len(row) - kernel_size + 1, stride):\n",
    "            maxPoolForRow.append(max(row[k:k + kernel_size]))\n",
    "        result.append(maxPoolForRow)\n",
    "    result = torch.tensor(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "output_from_my_implementation = my_MaxPool1d(random_tensor)\n",
    "output_from_my_implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.055818200Z",
     "start_time": "2023-09-30T12:57:05.005845700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same\n",
    "torch.equal(output_from_pytorch, output_from_my_implementation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.056803Z",
     "start_time": "2023-09-30T12:57:05.020786400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. AvgPool1d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0499, 0.1304, 0.0914, 0.5263],\n        [0.3252, 0.3168, 0.3161, 0.8598],\n        [0.2753, 0.9019, 0.5978, 0.6983]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some random input\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.056803Z",
     "start_time": "2023-09-30T12:57:05.047809900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0901, 0.1109, 0.3089],\n        [0.3210, 0.3165, 0.5880],\n        [0.5886, 0.7499, 0.6481]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pytorch equivalent\n",
    "pytorch_avg_pool_fn = nn.AvgPool1d(kernel_size=2, stride=1, padding=0,ceil_mode=False, count_include_pad=True)\n",
    "output_from_pytorch = pytorch_avg_pool_fn(random_tensor)\n",
    "output_from_pytorch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.067067100Z",
     "start_time": "2023-09-30T12:57:05.050809900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0901, 0.1109, 0.3089],\n        [0.3210, 0.3165, 0.5880],\n        [0.5886, 0.7499, 0.6481]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define my custom implementation of avgPool1d ( assumes that x is 2D (C,W) shape)\n",
    "def my_AvgPool1d(x, kernel_size=2, stride=1, padding=0, dilation=1):\n",
    "    result = []\n",
    "    for row in x:\n",
    "        maxPoolForRow = []\n",
    "        #k represents start point of the kernel\n",
    "        for k in range(0, len(row) - kernel_size + 1, stride):\n",
    "            maxPoolForRow.append(sum(row[k:k + kernel_size])/kernel_size)\n",
    "        result.append(maxPoolForRow)\n",
    "    result = torch.tensor(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "output_from_my_implementation = my_AvgPool1d(random_tensor)\n",
    "output_from_my_implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.134389Z",
     "start_time": "2023-09-30T12:57:05.067067100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same\n",
    "torch.equal(output_from_pytorch, output_from_my_implementation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:05.258702400Z",
     "start_time": "2023-09-30T12:57:05.210514400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Conv1d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Loading the given filter and input tensors\n",
    "pixel_input = torch.load(\"./pixel_input.pt\") #Shape (1,1,32)\n",
    "filter = torch.load(\"./4_3_filter.pt\") #(Shape 3,1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:07.434130500Z",
     "start_time": "2023-09-30T12:57:07.417605400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.2125, 0.3250, 0.4375, 0.5500, 0.6625, 0.7750, 0.8875, 1.0000,\n          1.1125, 1.2250, 1.3375, 1.4500, 1.5625, 1.6750, 1.7500, 1.7625,\n          1.7000, 1.5875, 1.4750, 1.3625, 1.2500, 1.1375, 1.0250, 0.9125,\n          0.8000, 0.6875, 0.5750, 0.4625, 0.3500, 0.2375]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define pytorch equivalent\n",
    "pytorch_conv1d_output = nn.functional.conv1d(pixel_input, filter, bias = None,stride = 1, padding = 0, dilation = 1, groups = 1)\n",
    "\n",
    "#Shape is (1,3,32)\n",
    "\n",
    "pytorch_conv1d_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:34.910380100Z",
     "start_time": "2023-09-30T12:57:34.897916600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.2125, 0.3250, 0.4375, 0.5500, 0.6625, 0.7750, 0.8875, 1.0000,\n          1.1125, 1.2250, 1.3375, 1.4500, 1.5625, 1.6750, 1.7500, 1.7625,\n          1.7000, 1.5875, 1.4750, 1.3625, 1.2500, 1.1375, 1.0250, 0.9125,\n          0.8000, 0.6875, 0.5750, 0.4625, 0.3500, 0.2375]]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define custom implementation\n",
    "def my_Conv1d(inp, filter, stride=1, padding=0, dilation=1, groups = 1):\n",
    "    result = []\n",
    "\n",
    "    for f in filter:\n",
    "        #as f in this case is 1x1 ( but it could in theory be something like 1 x k)\n",
    "        f = f[0]\n",
    "        batch_row = []\n",
    "        for batch in inp: #(1,32)\n",
    "            conv_row = []\n",
    "            for channel in batch: #(32,)\n",
    "                #convolve f over this channel array using this filter by using dot product to convolve!\n",
    "                for f_ind in range(0, len(channel) - len(f) + 1, stride):\n",
    "                    f = np.array(f)\n",
    "                    conv_row.append(np.dot(f, np.array(channel[f_ind: f_ind + len(f)])))\n",
    "            batch_row.append(conv_row)\n",
    "        result.append(batch_row)\n",
    "\n",
    "    result = torch.tensor(result)\n",
    "\n",
    "    #permute it so that the shapes are correct.\n",
    "    result = result.permute(1,0,2)\n",
    "    return result\n",
    "\n",
    "my_conv1d_output = my_Conv1d(pixel_input, filter)\n",
    "my_conv1d_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:57:40.580392900Z",
     "start_time": "2023-09-30T12:57:40.531629600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same\n",
    "torch.allclose(output_from_pytorch, output_from_my_implementation, rtol=1e-05, atol=1e-05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T12:58:01.821714900Z",
     "start_time": "2023-09-30T12:58:01.775135500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Sigmoid\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8103, 0.1572],\n        [0.4445, 0.2277]])"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some random input\n",
    "random_tensor = torch.rand(2, 2)\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:19.144224500Z",
     "start_time": "2023-09-29T07:56:19.128594600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6922, 0.5392],\n        [0.6093, 0.5567]])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pytorch equivalent\n",
    "pytorch_sigmoid_fn = nn.Sigmoid()\n",
    "output_from_pytorch = pytorch_sigmoid_fn(random_tensor)\n",
    "output_from_pytorch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:22.223369600Z",
     "start_time": "2023-09-29T07:56:22.192083300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_5716\\1711964653.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_from_my_implementation = torch.tensor(my_Sigmoid(random_tensor))\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.6922, 0.5392],\n        [0.6093, 0.5567]])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define my custom implementation of maxPool1d ( assumes that x is 2D (C,W) shape)\n",
    "def my_Sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "output_from_my_implementation = torch.tensor(my_Sigmoid(random_tensor))\n",
    "output_from_my_implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:40.097067600Z",
     "start_time": "2023-09-29T07:56:40.063292600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same\n",
    "torch.equal(pytorch_conv1d_output, my_conv1d_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:42.316941Z",
     "start_time": "2023-09-29T07:56:42.300272800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. BatchNorm1d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.8012, 0.8653, 0.0883, 0.3625]],\n\n        [[0.9214, 0.6491, 0.8451, 0.5259]]])"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some random input\n",
    "random_tensor = torch.rand(2,1,4) #(batchsize,numfeatures, actualfeatures)\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:47.519816Z",
     "start_time": "2023-09-29T07:56:47.505259600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.6205,  0.8562, -1.9999, -0.9918]],\n\n        [[ 1.0624,  0.0616,  0.7822, -0.3914]]])"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pytorch equivalent\n",
    "pytorch_batchnorm_fn = nn.BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)\n",
    "output_from_pytorch = pytorch_batchnorm_fn(random_tensor)\n",
    "output_from_pytorch = output_from_pytorch.data.detach()\n",
    "output_from_pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:47.855829900Z",
     "start_time": "2023-09-29T07:56:47.808456700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.6205,  0.8562, -1.9999, -0.9918]],\n\n        [[ 1.0624,  0.0616,  0.7822, -0.3914]]])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define my custom implementation of batchnorm ( assumes that x is 3D (B,1,N) shape)\n",
    "def my_BatchNorm1d(x, eps=1e-05, momentum=0.1, affine=True):\n",
    "    #momentum is used only during training and not used during inference!\n",
    "    # Compute batch mean and batch variance\n",
    "    batch_mean = x.mean(dim=(0, 2), keepdim=True)\n",
    "    batch_var = x.var(dim=(0, 2), unbiased=False, keepdim=True)\n",
    "\n",
    "    # Normalize the input using batch mean and variance\n",
    "    x_normalized = (x - batch_mean) / torch.sqrt(batch_var + eps)\n",
    "\n",
    "    return x_normalized\n",
    "\n",
    "output_from_my_implementation = my_BatchNorm1d(random_tensor)\n",
    "output_from_my_implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:58.758686600Z",
     "start_time": "2023-09-29T07:56:58.727398300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same\n",
    "torch.allclose(output_from_pytorch, output_from_my_implementation, rtol=1e-05, atol=1e-05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T07:56:59.602092100Z",
     "start_time": "2023-09-29T07:56:59.570383900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Linear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#Create some random input\n",
    "weight = torch.load(\"./4_6_weight.pt\") #Shape (1,1,32)\n",
    "bias = torch.load(\"./4_6_bias.pt\") #(Shape 3,1,1)\n",
    "\n",
    "random_tensor = torch.rand(16,32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:15.938421400Z",
     "start_time": "2023-09-30T13:08:15.924269100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 32])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:16.465966700Z",
     "start_time": "2023-09-30T13:08:16.430166100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:17.114847400Z",
     "start_time": "2023-09-30T13:08:17.099214500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-4.5783e-01,  2.3023e-01, -7.9213e-02, -3.6524e-01,  3.6225e-01,\n          3.5586e-01,  1.8898e-01, -2.4559e-01, -1.1320e-01, -1.2822e-01,\n          1.6586e-01, -2.1026e-01,  2.1441e-01,  1.1249e-01,  5.5575e-01,\n          1.2107e-01],\n        [-4.7706e-01, -7.8368e-04, -2.0029e-01, -1.3794e-01,  1.6647e-01,\n          3.6221e-01,  6.5435e-02, -9.4932e-02,  6.3805e-02, -3.0431e-01,\n          3.0784e-01, -5.0099e-02,  2.2768e-01,  4.9945e-02,  6.4397e-01,\n         -1.4372e-01],\n        [-2.8248e-01,  3.3805e-01,  2.7837e-02, -1.0285e-01,  1.5755e-01,\n          6.7600e-01,  1.6041e-01, -1.7669e-01,  3.8766e-02, -3.3473e-01,\n          4.4163e-01, -2.8571e-01,  2.2416e-01,  5.7681e-03,  7.9890e-01,\n         -2.5715e-01],\n        [-5.1823e-01,  3.1956e-01,  5.3780e-02, -2.9436e-01,  1.2818e-01,\n          6.1528e-01, -1.3541e-02, -1.2519e-02, -1.7497e-03, -2.3324e-01,\n          8.7738e-02, -6.2706e-02, -6.3785e-02, -4.1430e-01,  7.7243e-01,\n         -2.1140e-01],\n        [-4.7259e-01,  4.2647e-01, -7.5742e-02, -1.5642e-01,  7.8066e-02,\n          7.4263e-01,  1.9887e-02, -1.7623e-01,  1.7287e-01, -2.7164e-01,\n          1.8352e-01, -6.5160e-02,  7.5319e-02, -9.3824e-02,  5.9917e-01,\n         -4.5517e-01],\n        [-8.0453e-01,  1.2893e-01, -2.2606e-01, -2.2209e-01,  4.3859e-01,\n          6.7664e-01,  3.8724e-01, -4.0323e-02, -1.7513e-01, -2.9943e-01,\n         -7.0823e-03,  1.1701e-02,  2.3503e-01, -2.2393e-01,  1.0721e+00,\n         -1.5166e-01],\n        [-3.6923e-01,  5.3107e-01,  4.7665e-02, -3.8656e-01, -8.9407e-02,\n          6.1833e-01, -7.9605e-02, -1.9518e-01,  6.5965e-02, -3.0474e-01,\n          3.5133e-01, -1.3246e-02,  2.3904e-01,  1.1611e-01,  6.8767e-01,\n         -6.0120e-02],\n        [-3.6900e-01,  3.9366e-01,  3.4455e-01, -3.9069e-01,  3.3334e-01,\n          6.5285e-01,  3.1863e-01,  8.0368e-02, -2.7822e-01, -7.9150e-02,\n          1.9431e-01, -4.5459e-01,  1.4548e-01,  3.8890e-02,  8.2784e-01,\n         -1.7795e-02],\n        [-7.2373e-02,  4.4661e-01, -3.6464e-01, -1.0971e-01,  2.6430e-01,\n          5.1810e-01,  1.6784e-01, -4.2045e-01,  2.5355e-01, -3.0239e-01,\n          3.1682e-01, -6.0582e-02,  2.6413e-01,  2.4582e-01,  6.4694e-01,\n         -5.7478e-02],\n        [-2.2645e-01,  5.6784e-01,  6.3582e-02, -3.0191e-01,  1.4650e-01,\n          6.2317e-01,  2.8903e-01, -1.8645e-01, -1.8603e-01,  1.1954e-02,\n          1.9340e-01, -2.2650e-01,  2.7314e-01,  2.7263e-01,  6.7085e-01,\n         -2.2775e-01],\n        [-4.5909e-01,  6.9164e-02, -2.0415e-01, -1.9218e-01,  2.2010e-01,\n          5.7812e-01,  1.5460e-01, -1.0758e-01, -1.5821e-01, -3.2519e-01,\n          2.2913e-01,  1.3502e-04,  3.7450e-01,  1.5191e-01,  6.2535e-01,\n         -3.6151e-02],\n        [-4.8010e-01,  6.2490e-01, -2.6673e-01, -5.5101e-01,  2.7333e-01,\n          3.3238e-01,  2.6656e-01,  1.3427e-02,  1.4361e-04, -5.4349e-02,\n          8.1902e-02,  7.8234e-03,  2.3014e-01,  2.8254e-02,  6.7947e-01,\n          9.6169e-02],\n        [-2.3391e-01,  4.8440e-01, -1.4757e-01, -4.4214e-01,  4.0440e-01,\n          4.1541e-01,  1.6138e-01, -2.7755e-01, -1.5652e-02, -1.9466e-01,\n          1.8240e-01, -2.6775e-01,  3.6730e-01,  2.1153e-02,  5.7947e-01,\n         -8.3597e-02],\n        [-6.3444e-01,  5.1327e-01, -1.1472e-01, -4.3615e-01, -1.5059e-01,\n          7.3976e-01,  1.4560e-01, -4.1983e-02, -7.2284e-03, -9.6401e-02,\n          1.5627e-01,  5.5950e-02,  8.7246e-02, -1.1809e-01,  4.9741e-01,\n         -2.9227e-01],\n        [-4.8588e-01,  2.2246e-01, -7.2034e-02, -2.0501e-01, -1.6687e-01,\n          3.8334e-01,  2.8423e-02, -3.1950e-01, -2.2683e-01, -7.5344e-02,\n          2.6750e-02,  5.9733e-02, -1.1081e-01, -6.9719e-02,  6.3627e-01,\n         -5.9539e-02],\n        [-3.6274e-01,  8.4877e-01, -2.0069e-01, -3.0636e-01,  6.6788e-02,\n          6.5781e-01,  2.4511e-01, -6.2768e-02,  7.8664e-02, -2.0046e-01,\n          1.6048e-01,  3.7994e-02,  4.2025e-01,  3.9980e-02,  7.3887e-01,\n         -2.9636e-01]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pytorch equivalent\n",
    "in_features = 32\n",
    "out_features = 16\n",
    "pytorch_linear_fn = nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "pytorch_linear_fn.weight = nn.Parameter(weight)\n",
    "pytorch_linear_fn.bias = nn.Parameter(bias)\n",
    "\n",
    "output_from_pytorch = pytorch_linear_fn(random_tensor)\n",
    "output_from_pytorch = output_from_pytorch.data.detach()\n",
    "output_from_pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:21.903719900Z",
     "start_time": "2023-09-30T13:08:21.874516800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_7592\\1457816834.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(np.matmul(x, weights)) + biases\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0426,  2.6996,  4.5106,  0.8164, -1.3926,  2.1177, -1.5440, -2.8177,\n          5.0069, -0.3544, -3.5589, -0.1442,  2.6068, -0.4582,  5.5969,  0.4362],\n        [ 2.1838,  2.9080,  5.6041,  0.3362, -6.7615, -0.8284,  3.1849, -3.8562,\n          4.3269, -0.0338, -5.0396,  0.6504,  3.4249,  0.3185,  4.0469, -2.3122],\n        [ 3.6485,  2.3772,  5.6710,  1.0802, -3.8698,  1.9853,  3.9599, -4.1320,\n          7.1967, -3.3152, -9.1698, -2.8233,  2.9046,  0.4814,  5.2547, -2.7222],\n        [ 1.7515,  3.5249,  7.1651,  4.8252, -3.8191,  0.1266,  1.8229, -4.9273,\n          7.0129, -4.6480, -6.7361, -0.9563,  8.0241, -1.7583,  5.1491, -2.2574],\n        [ 1.4616,  3.3655,  5.8384,  2.2593, -6.4336,  0.3365,  1.8535, -5.5435,\n          6.9341, -2.6563, -7.2061, -1.9507,  4.8486, -1.6909,  5.2024,  0.3090],\n        [ 1.4739,  1.2487,  3.7316,  2.6677, -3.0271, -0.1294,  1.4957, -2.0452,\n          3.6811, -2.4156, -4.1982, -3.0536,  1.8146, -2.7537,  5.4162, -0.3332],\n        [ 3.2257,  5.8419,  5.7637,  0.5982, -2.3050,  0.6528,  2.3987, -5.6618,\n          6.4390, -3.1430, -5.7449, -0.6879,  4.7054, -0.0678,  8.4493, -0.3755],\n        [ 1.0430,  2.7620,  2.9136, -0.7887, -2.5584,  1.4819,  2.2953, -5.3035,\n          6.0456, -1.7921, -6.7782, -3.3412,  1.9970, -1.5841,  6.0416, -0.6838],\n        [ 1.8638,  4.3139,  7.0509,  1.6078, -5.0376,  1.6784,  1.2361, -4.7188,\n          6.6069, -1.1905, -5.9406,  0.6541,  1.3137, -1.4669,  6.8740, -0.2694],\n        [ 0.1587,  2.2600,  6.5521,  2.3575, -5.2006,  0.8855,  0.1695, -4.9128,\n          5.7285, -2.4106, -6.9376, -0.9260,  5.7113, -2.5819,  6.1968,  0.0312],\n        [ 1.4843,  2.4642,  6.8709, -1.1673, -4.7429,  1.7621,  0.9211, -4.2324,\n          3.8048,  0.0424, -4.1758, -1.9352,  0.5026,  0.0601,  4.9401,  0.4390],\n        [ 0.4879,  4.5117,  3.0128,  1.1320, -1.1287,  0.4532, -1.5263, -2.7033,\n          3.5864,  0.4498, -3.5027,  1.4358,  3.9626, -0.5412,  9.3753, -1.8257],\n        [-0.4640,  3.9740,  4.0005,  1.5382, -2.9056,  0.8399,  2.1413, -5.6095,\n          4.1208,  1.3946, -3.5308,  0.6409,  2.2132,  1.8319,  6.8536, -1.0058],\n        [ 0.8129,  3.5830,  4.8042,  3.6102, -4.4948,  1.8944,  1.4696, -4.3949,\n          7.3256,  0.5883, -5.9226,  0.6920,  4.6523,  0.7939,  8.9116, -2.3843],\n        [-0.0597,  6.4680,  4.0739,  3.6381, -1.5677,  0.8380,  1.3488, -2.5708,\n          9.0234,  0.0424, -1.6231,  1.3755,  4.4833, -1.4226,  7.7147,  1.0051],\n        [ 0.8167,  1.3105,  6.2031,  0.0781, -3.3494,  1.2939,  1.4923, -4.3777,\n          4.2691, -1.5234, -7.6752, -2.7482,  4.8848, -1.3575,  6.3670, -1.2874]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define my custom implementation of batchnorm ( assumes that x is 3D (B,1,N) shape)\n",
    "def my_Linear(x, in_features=32, out_features=16):\n",
    "    weights = torch.randn(in_features, out_features)  # Corrected order\n",
    "    biases = torch.randn(out_features)\n",
    "\n",
    "    # Perform linear transformation\n",
    "    return torch.tensor(np.matmul(x, weights)) + biases\n",
    "\n",
    "output_from_my_implementation = my_Linear(random_tensor)\n",
    "output_from_my_implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:38.656716100Z",
     "start_time": "2023-09-30T13:08:38.616817800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assert that both are the same size as the data inside may be random\n",
    "output_from_pytorch.shape == output_from_my_implementation.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:08:40.912187700Z",
     "start_time": "2023-09-30T13:08:40.878289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
