1. Dataloaders [DONE]

- Take the dataset and do  (Batch=2 (or) 4, Bag=10, Channel=3, Width=32, Height=32) -> num steps in 1 epoch (either 2k or 1k)
- find out the normalization constants by running that script and store it (X)
- augmentation (flips, rotations)
- also wrote ucc dataloader, rcc dataloader , autoencoder dataloader on test data and the kde test dataloader

2. Models [DONE]
- Note better to keep the KDE layer as a separate one! ( or atleast keep a track of it in the forward method )
- UCC model:
- UCC + RCC model:
- KDE model
Thoughts from call :
(Batch, 10, 3, 32,32)

feature size = J
(Num nodes here is 11 for some reason , maybe num_classes + 1)
(batch, 10, J) -> KDE -> (batch, J*num_nodes) -> MAGIC!! -> (batch, 4)

3. Trainers [In Progress]
- UCC model:
* things to track:
- ucc loss, ae loss, combined loss
- ucc accuracy
* track ucc accuracy- loss, autoencoder-loss, combined loss after epoch. do one batch of ucc reconstruction
* implement that model and also ensure that the values assigned for the loss value (alpha value is indicative of what I want to optimize) more.
* Autoencoder + UCC loss

- UCC-RCC model:
* do SSIM loss + RCC path + the new loss(es)
* Autoencoder + UCC loss + RCC loss + UCC-RCC loss
* This UCC-RCC loss is like threshold the RCC vector and see if the no of things which are greater than 1 is equal to the UCC ka argmax


4. Autoencoder predictions for each class
* Looks like we need both the features ka mean and the distribution of features?
- Use the pure dataloader and the trained encoder model and get all the features (2 paths from here)

* Path 1 (JS Divergence):
- Use features and also pass it through the KDE layer and get the tensor of KDE values for all images in one class store it
- Actually also store the features also seperately!
- Use this entire thing to calculate the JS divergence between 2 things (most probably no need to take the average here? probably better to do it this way only !)
- Create confusion matrix and pick the min

* Path 2 ( Clustering):
- Use the stored features along with its corresponding labels and then do kmeans on top of it ( do it the same way done by the original authors)
- store the score metrics calculated by the original authors ( see cluster.py) and store those values (remember the GT cluster labels)
- run clustering and then obtain the predicted cluster labels..( see obtain_cluster_results)
* but how to ensure that the cluster labels here are indeed the same GT labels?
- calculate cluster accuracy -> do some linear_sum_assignment problem ( i.e. match the cluster labels) by creating a matrix of costs ( true label, predicted label) [exactly recreate this !]



Troubles!:

1. gradclip gave weird issue in colab (X)
2. unsigned char had to make everything into float (X)
3. val loss is giving nan (X)
4. val loss is too high , need to check if i am dividing correctly in the code
5. val loss when appending to history is still a tensor need to use .item()
5.a plot code gives issues
6. test loss is also too high , need to check
7. js divergence and clustering code gives errors
8. rcc model expects double when doing validation and not float during the validation hook phase.
9. ?

Things to try:

1. Change the dataset in the following manner:
- change bag size to 12 (done)
- try normalization (of the entire dataset) (done) (DIDNT WORK!)
- for each ucc ensure equal split and ensure that the images are in order and not in random order (done)
- try normalization in the transforms

2. Check each model and ensure that you try xavier initialization or something (done)
3. for encoder ensure that the final layer is sigmoid (done)

