{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:34:33.818870800Z",
     "start_time": "2023-10-13T05:34:33.755887400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing relevant things"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:38:05.106477500Z",
     "start_time": "2023-10-13T05:38:05.048150800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :(40000, 32, 32, 3)\n",
      "y_train shape :(40000, 1)\n",
      "x_val shape :(10000, 32, 32, 3)\n",
      "y_val shape :(10000, 1)\n",
      "x_test shape :(10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "splitted_dataset = np.load('splitted_cifar10_dataset.npz')\n",
    "\n",
    "x_train = splitted_dataset['x_train']\n",
    "print(f\"x_train shape :{x_train.shape}\")\n",
    "\n",
    "y_train = splitted_dataset['y_train']\n",
    "print(f\"y_train shape :{y_train.shape}\")\n",
    "\n",
    "x_val = splitted_dataset['x_val']\n",
    "print(f\"x_val shape :{x_val.shape}\")\n",
    "\n",
    "y_val = splitted_dataset['y_val']\n",
    "print(f\"y_val shape :{y_val.shape}\")\n",
    "\n",
    "x_test = splitted_dataset['x_test']\n",
    "print(f\"x_test shape :{x_test.shape}\")\n",
    "\n",
    "y_test = splitted_dataset['y_test']\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:51:43.335046500Z",
     "start_time": "2023-10-13T05:51:43.037483400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the class names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:51:43.843389800Z",
     "start_time": "2023-10-13T05:51:43.794280Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a custom dataset loader to calculate UCC and RCC (TODO)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=16):\n",
    "        '''\n",
    "        Note these are numpy arrays\n",
    "\n",
    "        :param x_train:\n",
    "        :param y_train:\n",
    "        :param x_val:\n",
    "        :param y_val:\n",
    "        :param x_test:\n",
    "        :param y_test:\n",
    "        '''\n",
    "        self.num_classes = 10\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # converting it all into a tensor (its not yet one hotified)\n",
    "        self.x_train = torch.from_numpy(x_train)\n",
    "        self.y_train = torch.from_numpy(y_train)\n",
    "        self.x_val = torch.from_numpy(x_val)\n",
    "        self.y_val = torch.from_numpy(y_val)\n",
    "        self.x_test = torch.from_numpy(x_test)\n",
    "        self.y_test = torch.from_numpy(y_test)\n",
    "\n",
    "        # create datasets\n",
    "        self.train_dataset = TensorDataset(self.x_train, self.y_train)\n",
    "        self.val_dataset = TensorDataset(self.x_val, self.y_val)\n",
    "        self.test_dataset = TensorDataset(self.x_test, self.y_test)\n",
    "\n",
    "        # create loaders for going through the dataset to create the new final dataset\n",
    "        self.train_loader = DeviceDataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "        self.val_loader = DeviceDataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "        self.test_loader = DeviceDataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    # get UCC\n",
    "    def construct_datasets_with_ucc(self):\n",
    "        train_dataset_with_ucc = self.construct_dataset_with_ucc(self.train_loader)\n",
    "        val_dataset_with_ucc = self.construct_dataset_with_ucc(self.val_loader)\n",
    "        test_dataset_with_ucc = self.construct_dataset_with_ucc(self.test_loader)\n",
    "\n",
    "        return train_dataset_with_ucc, val_dataset_with_ucc, test_dataset_with_ucc\n",
    "\n",
    "    def construct_dataset_with_ucc(self, dataloader):\n",
    "        image_tensors = []\n",
    "        ucc_tensors = []\n",
    "\n",
    "        for data in tqdm(dataloader):\n",
    "            images, labels = data\n",
    "\n",
    "            ucc = self.get_ucc_from_labels_of_batch(labels)\n",
    "\n",
    "            image_tensors.append(images)\n",
    "            ucc_tensors.append(ucc)\n",
    "\n",
    "\n",
    "        return TensorDataset(\n",
    "            torch.stack(image_tensors),\n",
    "            torch.stack(ucc_tensors)\n",
    "        )\n",
    "\n",
    "    def construct_datasets_with_ucc_and_rcc(self):\n",
    "        train_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.train_loader)\n",
    "        val_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.val_loader)\n",
    "        test_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.test_loader)\n",
    "\n",
    "        return train_dataset_with_ucc_and_rcc, val_dataset_with_ucc_and_rcc, test_dataset_with_ucc_and_rcc\n",
    "\n",
    "    # get both UCC and RCC\n",
    "    def construct_dataset_with_ucc_and_rcc(self, dataloader):\n",
    "        image_tensors = []\n",
    "        ucc_tensors = []\n",
    "        rcc_tensors = []\n",
    "\n",
    "        for data in tqdm(dataloader):\n",
    "            images, labels = data\n",
    "\n",
    "            #get ucc\n",
    "            ucc = self.get_ucc_from_labels_of_batch(labels)\n",
    "\n",
    "            #get rcc\n",
    "            rcc = self.get_rcc_from_labels_of_batch(labels)\n",
    "\n",
    "            image_tensors.append(images)\n",
    "            ucc_tensors.append(ucc)\n",
    "            rcc_tensors.append(rcc)\n",
    "\n",
    "\n",
    "        return TensorDataset(\n",
    "            torch.stack(image_tensors),\n",
    "            torch.stack(ucc_tensors),\n",
    "            torch.stack(rcc_tensors),\n",
    "        )\n",
    "\n",
    "    def get_ucc_from_labels_of_batch(self, labels):\n",
    "        unique_count = torch.unique(labels).size(0)\n",
    "        unique_count = torch.tensor(unique_count)\n",
    "        ucc = self.one_hot(unique_count)\n",
    "        return ucc\n",
    "\n",
    "    def get_rcc_from_labels_of_batch(self, labels):\n",
    "        labels = labels.squeeze()\n",
    "        rcc = torch.zeros(self.num_classes, dtype=torch.int32)\n",
    "        # Count the occurrences of each class\n",
    "        for i in range(self.num_classes):\n",
    "            rcc[i] = (labels == i).sum()\n",
    "        return rcc\n",
    "\n",
    "    # util\n",
    "    def one_hot(self, label):\n",
    "        # Create a one-hot tensor\n",
    "        one_hot = torch.zeros(self.num_classes)\n",
    "\n",
    "        # since each label is in range of [1,10] getting it to a range of [0,9]\n",
    "        one_hot[label-1] = 1\n",
    "        return one_hot\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Things left to do\n",
    "\n",
    "1. set up the model architecture for both appproaches (#1 with only ac + ucc , #2 with ac + ucc + rcc)\n",
    "2. set up the training module code\n",
    "3. find out how to use JS divergence and KDE\n",
    "4. Write clustering code\n",
    "5. train it"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
