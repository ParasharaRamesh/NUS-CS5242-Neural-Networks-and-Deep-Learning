{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installing python modules used later on"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SlpsuqkV1iPk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pytorch_msssim\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_msssim) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_msssim) (1.3.0)\n",
      "Installing collected packages: pytorch_msssim\n",
      "Successfully installed pytorch_msssim-1.0.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "!pip install pytorch_msssim"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhfdu7AB1iPq",
    "outputId": "9ea96ef5-751c-446a-97e0-ebb04a63b270"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mount Google Drive"
   ],
   "metadata": {
    "collapsed": false,
    "id": "aPdt08JV1iPt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T05:34:33.818870800Z",
     "start_time": "2023-10-13T05:34:33.755887400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUtNUuoA1iPu",
    "outputId": "b81799ca-0d52-4ed8-8f60-1ea573aea308"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing relevant things"
   ],
   "metadata": {
    "collapsed": false,
    "id": "MSXaxVQa1iPu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:38:05.106477500Z",
     "start_time": "2023-10-13T05:38:05.048150800Z"
    },
    "id": "kDt34Hh61iPv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from pytorch_msssim import SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config params"
   ],
   "metadata": {
    "collapsed": false,
    "id": "30WA5eST1iPw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    drive_path = \"/content/drive/MyDrive\"\n",
    "    datasets_path = f\"{drive_path}/splitted_cifar10_dataset.npz\"\n",
    "    weights_path = f\"{drive_path}/weights\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    sigma = 0.1\n",
    "    num_nodes = 11\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    weight_decay = 1e-4\n",
    "    grad_clip = 0.1\n",
    "\n",
    "    batch_size = 2\n",
    "    ucc_limit = 4\n",
    "    rcc_limit = 10\n",
    "    bag_size = 10\n",
    "\n",
    "config = Config()\n"
   ],
   "metadata": {
    "id": "xjKkRwyL1iPw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Au0yZcaw1iPx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape :(40000, 32, 32, 3)\n",
      "y_train shape :(40000, 1)\n",
      "x_val shape :(10000, 32, 32, 3)\n",
      "y_val shape :(10000, 1)\n",
      "x_test shape :(10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "splitted_dataset = np.load(config.datasets_path)\n",
    "\n",
    "x_train = splitted_dataset['x_train']\n",
    "print(f\"x_train shape :{x_train.shape}\")\n",
    "\n",
    "y_train = splitted_dataset['y_train']\n",
    "print(f\"y_train shape :{y_train.shape}\")\n",
    "\n",
    "x_val = splitted_dataset['x_val']\n",
    "print(f\"x_val shape :{x_val.shape}\")\n",
    "\n",
    "y_val = splitted_dataset['y_val']\n",
    "print(f\"y_val shape :{y_val.shape}\")\n",
    "\n",
    "x_test = splitted_dataset['x_test']\n",
    "print(f\"x_test shape :{x_test.shape}\")\n",
    "\n",
    "y_test = splitted_dataset['y_test']\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T05:51:43.335046500Z",
     "start_time": "2023-10-13T05:51:43.037483400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt12NdvB1iPx",
    "outputId": "f429a880-a7f2-4dc1-b1f7-70c7c955e2b8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Dataloader\n",
    "\n",
    "This dataloader moves data directly to the device when yielding data"
   ],
   "metadata": {
    "collapsed": false,
    "id": "xbz27xgV1iP1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "'''\n",
    "Wrapper on top of dataloader to move tensors to device\n",
    "'''\n",
    "class DeviceDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            yield self._move_to_device(batch)\n",
    "\n",
    "    def _move_to_device(self, batch):\n",
    "        if isinstance(batch, torch.Tensor):\n",
    "            return batch.to(self.device)\n",
    "        elif isinstance(batch, (list, tuple)):\n",
    "            return [self._move_to_device(item) for item in batch]\n",
    "        elif isinstance(batch, dict):\n",
    "            return {key: self._move_to_device(value) for key, value in batch.items()}\n",
    "        else:\n",
    "            return batch\n"
   ],
   "metadata": {
    "id": "aZ3q0u8X1iP2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SL4Quij91iP2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "                 batch_size=config.batch_size, bag_size=config.bag_size,\n",
    "                 ucc_limit=config.ucc_limit, rcc_limit=config.rcc_limit\n",
    "                 ):\n",
    "        '''\n",
    "        Note these are numpy arrays\n",
    "\n",
    "        :param x_train:\n",
    "        :param y_train:\n",
    "        :param x_val:\n",
    "        :param y_val:\n",
    "        :param x_test:\n",
    "        :param y_test:\n",
    "        '''\n",
    "        self.num_classes = rcc_limit\n",
    "        self.bag_size = bag_size\n",
    "        self.ucc_limit = ucc_limit\n",
    "        self.rcc_limit = rcc_limit\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # transforms to apply\n",
    "        self.transforms = [\n",
    "            # normal\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            # random horizontal flips\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            # random vertical flips\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            # random rotations\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomRotation(14),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            # random rotations & flips\n",
    "            transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "        ]\n",
    "\n",
    "        # converting it all into a tensor (it's not yet one hotified)\n",
    "        self.x_train = torch.from_numpy(x_train)\n",
    "        self.y_train = torch.from_numpy(y_train)\n",
    "        self.x_test = torch.from_numpy(x_test)\n",
    "        self.y_test = torch.from_numpy(y_test)\n",
    "        self.x_val = torch.from_numpy(x_val)\n",
    "        self.y_val = torch.from_numpy(y_val)\n",
    "\n",
    "        # create subdatasets ([class_0_imgs, class_1_imgs,... class_9_imgs])\n",
    "        self.train_sub_datasets = self.create_sub_datasets(self.x_train, self.y_train)\n",
    "        self.test_sub_datasets = self.create_sub_datasets(self.x_test, self.y_test)\n",
    "        self.val_sub_datasets = self.create_sub_datasets(self.x_val, self.y_val)\n",
    "\n",
    "        # create dataloaders\n",
    "        print(\"Creating KDE dataloaders\")\n",
    "        self.kde_test_dataloaders = self.create_kde_dataloaders(self.test_sub_datasets)\n",
    "\n",
    "        print(\"Created KDE dataloaders, now creating autoencoder dataloaders\")\n",
    "        #batch size is 1 as we care about image level features anyway\n",
    "        self.autoencoder_test_dataloaders = [DeviceDataLoader(test_sub_dataset, 1) for test_sub_dataset in\n",
    "                                             self.test_sub_datasets]\n",
    "        print(\"Created autoencoder dataloaders, now creating ucc dataloaders\")\n",
    "        self.ucc_train_dataloader, self.ucc_test_dataloader, self.ucc_val_dataloader = self.get_dataloaders_for_ucc()\n",
    "        print(\"Created ucc dataloaders, now creating rcc dataloaders\")\n",
    "        self.ucc_rcc_train_dataloader, self.ucc_rcc_test_dataloader, self.ucc_rcc_val_dataloader = self.get_dataloaders_for_ucc_and_rcc()\n",
    "\n",
    "        print(\"Initilized all dataloaders\")\n",
    "\n",
    "    # create dataloaders\n",
    "    def create_kde_dataloaders(self, sub_datasets):\n",
    "        kde_datasets = []\n",
    "\n",
    "        for chosen_class, pure_sub_dataset in tqdm(enumerate(sub_datasets)):\n",
    "            total_bags_for_pure_subset = len(pure_sub_dataset) // self.bag_size\n",
    "            bag_tensors = []\n",
    "\n",
    "            pure_sub_dataset_idx = 0\n",
    "            current_bag = self.create_bag()\n",
    "\n",
    "            while pure_sub_dataset_idx < len(pure_sub_dataset):\n",
    "                # get the image from this pure sub dataset\n",
    "                img = pure_sub_dataset[pure_sub_dataset_idx][0].permute((2, 0, 1))\n",
    "                bag_idx = pure_sub_dataset_idx % 10\n",
    "                current_bag[bag_idx] = img\n",
    "\n",
    "                if bag_idx == 9:\n",
    "                    # the last value has been filled, so add it to the total bags\n",
    "                    bag_tensors.append(torch.stack(current_bag))\n",
    "\n",
    "                    # create a new bag for the next set of bags to be filled\n",
    "                    current_bag = self.create_bag()\n",
    "                pure_sub_dataset_idx += 1\n",
    "\n",
    "            kde_datasets.append(TensorDataset(torch.stack(bag_tensors)))\n",
    "\n",
    "        print(\"Finished constructing the kde_datasets from the test dataset, now creating dataloaders\")\n",
    "\n",
    "        #NOTE. the batch size here can be different if required.\n",
    "        kde_data_loaders = [DeviceDataLoader(kde_sub_dataset, self.batch_size) for kde_sub_dataset in kde_datasets]\n",
    "        return kde_data_loaders\n",
    "\n",
    "    def get_dataloaders_for_ucc(self):\n",
    "        train_dataset_with_ucc, test_dataset_with_ucc, val_dataset_with_ucc = self.construct_datasets_with_ucc()\n",
    "        return DeviceDataLoader(train_dataset_with_ucc, self.batch_size), \\\n",
    "            DeviceDataLoader(test_dataset_with_ucc, self.batch_size), \\\n",
    "            DeviceDataLoader(val_dataset_with_ucc, self.batch_size)\n",
    "\n",
    "    def get_dataloaders_for_ucc_and_rcc(self):\n",
    "        train_dataset_with_ucc_and_rcc, test_dataset_with_ucc_and_rcc, val_dataset_with_ucc_and_rcc = self.construct_datasets_with_ucc_and_rcc()\n",
    "        return DeviceDataLoader(train_dataset_with_ucc_and_rcc, self.batch_size), \\\n",
    "            DeviceDataLoader(test_dataset_with_ucc_and_rcc, self.batch_size), \\\n",
    "            DeviceDataLoader(val_dataset_with_ucc_and_rcc, self.batch_size)\n",
    "\n",
    "    # create sub datasets\n",
    "    def create_sub_datasets(self, x, y):\n",
    "        # Initialize an empty list to store the sub-datasets\n",
    "        sub_datasets = []\n",
    "\n",
    "        # Split the original dataset into 10 sub-datasets\n",
    "        for class_label in range(self.num_classes):\n",
    "            # Select indices for the current class\n",
    "            indices = torch.where(y == class_label)[0]\n",
    "\n",
    "            # Extract data for the current class\n",
    "            x_class = x[indices]\n",
    "\n",
    "            # Create a TensorDataset for the current class\n",
    "            class_dataset = TensorDataset(x_class)\n",
    "\n",
    "            # Append the current class dataset to the list\n",
    "            sub_datasets.append(class_dataset)\n",
    "        return sub_datasets\n",
    "\n",
    "    # pick random image from ith class\n",
    "    def pick_random_from_ith_sub_dataset(self, sub_datasets, i, is_eval):\n",
    "        assert 0 <= i < self.num_classes\n",
    "        sub_dataset = sub_datasets[i]\n",
    "        sub_dataset_length = len(sub_dataset)\n",
    "        random_idx = random.randint(0, sub_dataset_length - 1)\n",
    "        random_img = sub_dataset[random_idx][0]\n",
    "        random_img = random_img.permute((2, 0, 1))\n",
    "        if not is_eval:\n",
    "            random_transform = random.choice(self.transforms)\n",
    "            random_img = random_transform(random_img)\n",
    "        return random_img\n",
    "\n",
    "    # construct UCC dataset\n",
    "    def construct_datasets_with_ucc(self):\n",
    "        train_dataset_with_ucc = self.construct_dataset_with_ucc(self.train_sub_datasets, False)\n",
    "        test_dataset_with_ucc = self.construct_dataset_with_ucc(self.test_sub_datasets, True)\n",
    "        val_dataset_with_ucc = self.construct_dataset_with_ucc(self.val_sub_datasets, True)\n",
    "\n",
    "        return train_dataset_with_ucc, test_dataset_with_ucc, val_dataset_with_ucc\n",
    "\n",
    "    def construct_dataset_with_ucc(self, sub_datasets, is_eval):\n",
    "        bag_tensors = []\n",
    "        ucc_tensors = []\n",
    "\n",
    "        # calculate no of bags needed (NOTE: we are not going to pick every image here!)\n",
    "        total_bags = 0\n",
    "        for sub_dataset in sub_datasets:\n",
    "            total_bags += len(sub_dataset)\n",
    "        total_bags = total_bags // self.bag_size\n",
    "\n",
    "        # NOTE: we can technically pick more images before I am not enforcing that I am picking every image.\n",
    "        for b in tqdm(range(total_bags)):\n",
    "            # this will keep picking ucc (1 -> 4) in a cyclic manner\n",
    "            ucc = (b % self.ucc_limit) + 1\n",
    "            bag_tensor = self.create_bag()\n",
    "\n",
    "            # you are choosing random classes of size {ucc}. Using this knowledge you have to fill the bag up.\n",
    "            chosen_classes = random.sample(list(range(self.num_classes)), ucc)\n",
    "            random_bag_pos = random.sample(list(range(self.bag_size)), self.bag_size)\n",
    "\n",
    "            # fill all the values for ucc first and then fill the remaining with random sampling with replacement\n",
    "            for chosen_class, bag_pos in zip(chosen_classes, random_bag_pos[:len(chosen_classes)]):\n",
    "                bag_tensor[bag_pos] = self.pick_random_from_ith_sub_dataset(sub_datasets, chosen_class, is_eval)\n",
    "\n",
    "            # fill bag_tensor pos by pos\n",
    "            for bag_pos in random_bag_pos[len(chosen_classes):]:\n",
    "                chosen_class = random.choice(chosen_classes)\n",
    "                bag_tensor[bag_pos] = self.pick_random_from_ith_sub_dataset(sub_datasets, chosen_class, is_eval)\n",
    "\n",
    "            bag_tensors.append(torch.stack(bag_tensor))\n",
    "            ucc_tensors.append(self.one_hot(ucc, self.ucc_limit))\n",
    "\n",
    "        return TensorDataset(\n",
    "            torch.stack(bag_tensors),\n",
    "            torch.stack(ucc_tensors)\n",
    "        )\n",
    "\n",
    "    # create UCC and RCC dataset\n",
    "    def construct_datasets_with_ucc_and_rcc(self):\n",
    "        train_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.train_sub_datasets, False)\n",
    "        test_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.val_sub_datasets, True)\n",
    "        val_dataset_with_ucc_and_rcc = self.construct_dataset_with_ucc_and_rcc(self.test_sub_datasets, True)\n",
    "\n",
    "        return train_dataset_with_ucc_and_rcc, test_dataset_with_ucc_and_rcc, val_dataset_with_ucc_and_rcc\n",
    "\n",
    "    def construct_dataset_with_ucc_and_rcc(self, sub_datasets, is_eval):\n",
    "        bag_tensors = []\n",
    "        ucc_tensors = []\n",
    "        rcc_tensors = []\n",
    "\n",
    "        # calculate no of bags needed (NOTE: we are not going to pick every image here!)\n",
    "        total_bags = 0\n",
    "        for sub_dataset in sub_datasets:\n",
    "            total_bags += len(sub_dataset)\n",
    "        total_bags = total_bags // self.bag_size\n",
    "\n",
    "        for b in tqdm(range(total_bags)):\n",
    "            # this will keep picking ucc (1 -> 4) in a cyclic manner\n",
    "            ucc = (b % self.ucc_limit) + 1\n",
    "            bag_tensor = self.create_bag()\n",
    "            rcc_tensor = [0] * self.rcc_limit\n",
    "\n",
    "            # you are choosing random classes of size {ucc}. Using this knowledge you have to fill the bag up.\n",
    "            chosen_classes = random.sample(list(range(self.num_classes)), ucc)\n",
    "            random_bag_pos = random.sample(list(range(self.bag_size)), self.bag_size)\n",
    "\n",
    "            # fill all the values for ucc first and then fill the remaining with random sampling with replacement\n",
    "            for chosen_class, bag_pos in zip(chosen_classes, random_bag_pos[:len(chosen_classes)]):\n",
    "                bag_tensor[bag_pos] = self.pick_random_from_ith_sub_dataset(sub_datasets, chosen_class, is_eval)\n",
    "                rcc_tensor[chosen_class] += 1\n",
    "\n",
    "            # fill bag_tensor pos by pos\n",
    "            for bag_pos in random_bag_pos[len(chosen_classes):]:\n",
    "                chosen_class = random.choice(chosen_classes)\n",
    "                bag_tensor[bag_pos] = self.pick_random_from_ith_sub_dataset(sub_datasets, chosen_class, is_eval)\n",
    "                rcc_tensor[chosen_class] += 1\n",
    "\n",
    "            bag_tensors.append(torch.stack(bag_tensor))\n",
    "            ucc_tensors.append(self.one_hot(ucc, self.ucc_limit))\n",
    "            rcc_tensors.append(torch.tensor(rcc_tensor))\n",
    "\n",
    "        return TensorDataset(\n",
    "            torch.stack(bag_tensors),\n",
    "            torch.stack(ucc_tensors),\n",
    "            torch.stack(rcc_tensors),\n",
    "        )\n",
    "\n",
    "    # util\n",
    "    def one_hot(self, label, limit):\n",
    "        # Create a one-hot tensor\n",
    "        one_hot = torch.zeros(limit)\n",
    "\n",
    "        # since each label is in range of [1,10] getting it to a range of [0,9]\n",
    "        one_hot[label - 1] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def create_bag(self):\n",
    "        return [None] * 10\n"
   ],
   "metadata": {
    "id": "JkfzExFo1iP3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the dataset object"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zh4SdAvF1iP5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating KDE dataloaders\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0a3428cbfab4922ba5a5819651bff65"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished constructing the kde_datasets from the test dataset, now creating dataloaders\n",
      "Created KDE dataloaders, now creating autoencoder dataloaders\n",
      "Created autoencoder dataloaders, now creating ucc dataloaders\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ed3aa79907e41749053fc6a2d8c7878"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6e2fa49e88d4c5993992632c6e4ed1d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f27428f6a839491992eebe2c46ec7a87"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created ucc dataloaders, now creating rcc dataloaders\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fc2ce4bba644c9ba75fd83b8bcdf781"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0562a595ba36497f968988c4f30007cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa05d1c7781c4bb6b7083cebc02d9070"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initilized all dataloaders\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_train, y_train, x_val, y_val, x_test, y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345,
     "referenced_widgets": [
      "b0a3428cbfab4922ba5a5819651bff65",
      "45b9899987b0457697b98094691fe533",
      "38811dd740724070bdee0edf35dc4adc",
      "1e1ef139001343bb9f3c1418cfb46c93",
      "4139665d030c4587b6eef55fd176443c",
      "4fa71b74e950444baee1d7bab67f31c3",
      "216fbc7e6cb747bc90d4cfe5157d4ebf",
      "6c322c79438b438e8cd4e949ee407530",
      "7342b7067b2541ae97ab185fb9b9cac1",
      "cd8c90fab7a14cf18b3dbcd4cea03f25",
      "6b39ef7bfc0a4aa18d4e58f939d88124",
      "1ed3aa79907e41749053fc6a2d8c7878",
      "fcde7ada4c7c4a83aacc5ff2633c20f2",
      "58e4b6572b2644198c451ec4eb339dc2",
      "d51b939bfd3d47798ca0ee3dce139d30",
      "aadef4806a674d14834012356ca7f06d",
      "da3b9b86c6294344b2099b907710153b",
      "13f4f2dabdf2481da33d584e3c5fcbb9",
      "a557936305f646ab8a0e61d3f47900ef",
      "fb44fe378f99457ab7eb7854761fb19e",
      "db45c5e4a7e74f1eb6ea5387a15871d8",
      "aad32bd7d0d1449caba3abacc701d81b",
      "a6e2fa49e88d4c5993992632c6e4ed1d",
      "7d69537adda54076a03c9acea74fb497",
      "9ea7f77f3dfa4793a4f9da35fd3df7b5",
      "d1859a99cc364d6cb41a89178d427f8f",
      "98bcbffae02c401ebe1782629d146c65",
      "73f99b4b27ba4ddc89727b936c08ee3b",
      "db92fa9c53d641528ee879774213400d",
      "dccbad301c0a40729a2077ef3abed5f2",
      "3fd55dc0b97242baa14d76bcf3dc10a7",
      "64d4b51a25314baf8b3954e5d5ce2108",
      "47fd830936af4604af5e63fd8bc6059a",
      "f27428f6a839491992eebe2c46ec7a87",
      "fc6780cdfd0441db880a6a10ab95b5e4",
      "9e973ee8841d433cad9a92448ac161e5",
      "a4a987db4ec349a89da43f5b41d9d49e",
      "97523dd1039f498b9804022d64055993",
      "ce1de4909d9140188ffc8e451d9e7a87",
      "e8220451de4443bca4fd44acbd4c4cb7",
      "e274322b2d9048bea857a5e4ba634820",
      "220b871f5a364b24bbd16a7d058a8c7e",
      "c7de9f94413d4978bf718d1c7a355e75",
      "d3ebeecef2a44cfdb8113a5f9bf2e3d2",
      "7fc2ce4bba644c9ba75fd83b8bcdf781",
      "badd6cd298104eebab15f7e5d915b323",
      "bfda78f7eb924c198a7c89298310f0fa",
      "e79c4cdb6aae4cf48712e542f96735e1",
      "dbfe9b827823418c96bad872edd6dcef",
      "fa2724e5cb274e1ba27c2f4eea804b0c",
      "bf59694ff0ad4ea9bc70f38565f9f3ae",
      "f0a892ad718b4eabaf944ae14b535e28",
      "d7f5634e049e4c80bd47a8da7ce0b4a7",
      "102e3115507142fb870b0c4f51af43b2",
      "4f2dbb3c20ee409fa70a00a6dcc14a86",
      "0562a595ba36497f968988c4f30007cd",
      "0257652b341d4b6b92f5e413c2f01737",
      "44b36e153d44450f8c9289f23d540c58",
      "524f59f623e94391bc4d1ec2f858d4f8",
      "eca6b1c065604ced9c3d847afa286065",
      "f1b21338c4174675bb4bcbaa30639afd",
      "48a7c73005b243aa8f859772ef6c699d",
      "daf98be49204424ab8a76db200535a63",
      "8d18b7cd3f994b6b8c365f67a6b6e33f",
      "8721e904f0a44d2085b0a7f5753223e0",
      "f10e12bfde6a4273a9abf00b79135751",
      "fa05d1c7781c4bb6b7083cebc02d9070",
      "0473b48309db4fb6885d59673fec2ce0",
      "d885c01d564d40bb8018857a5e7ff238",
      "20e7741c0a704bc7a4d1042a886f50af",
      "24d75655e37a40b7b5ba1676142adc0d",
      "8e7ae96813ce4601b8a051cce09448e2",
      "34f094d5d63340a685ec4bb33bdd68f0",
      "1e667bfa596249d2925be3d7d12f4c65",
      "412a26eae95f47189196ad2482ea7f1a",
      "6dfb53d9dd194832be055e5918503592",
      "c84bbf1170ab4bd68f34058e94fa8a95"
     ]
    },
    "id": "Vhk3aDMf1iP6",
    "outputId": "fcbf64d6-6f89-4adb-b2e2-a9f64d004655"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the class names"
   ],
   "metadata": {
    "collapsed": false,
    "id": "u-v89qee1iP6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T05:51:43.843389800Z",
     "start_time": "2023-10-13T05:51:43.794280Z"
    },
    "id": "t4gCeRZm1iP6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model architectures"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SngRtCVv1iP7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4DQxh8Y41iP7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(24, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(48 * 16, 48 * 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),  # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        reshaped_encoded = encoded.view(-1, 48, 4, 4)\n",
    "        decoded = self.decoder(reshaped_encoded)\n",
    "        return encoded, decoded\n"
   ],
   "metadata": {
    "id": "hWonpW8X1iP7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kernel Density Estimator"
   ],
   "metadata": {
    "collapsed": false,
    "id": "7dDCCYEI1iP8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class KDE(nn.Module):\n",
    "    def __init__(self, device=config.device, num_nodes=config.num_nodes, sigma=config.sigma):\n",
    "        super(KDE, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.sigma = sigma\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        batch_size, bag_size, num_features = data.size()  # Batch, bag, J\n",
    "\n",
    "        # Create a tensor for the sample points\n",
    "        k_sample_points = torch.linspace(0, 1, steps=self.num_nodes).repeat(batch_size, bag_size, 1).to(\n",
    "            self.device)  # B, bag, num_nodes\n",
    "\n",
    "        # Constants\n",
    "        k_alfa = 1 / np.sqrt(2 * np.pi * np.square(self.sigma))\n",
    "        k_beta = -1 / (2 * self.sigma ** 2)\n",
    "\n",
    "        out_list = []\n",
    "\n",
    "        for j in range(num_features):\n",
    "            data_j = data[:, :, j]  # shape (Batch, bag)\n",
    "            temp_data = data_j.view(-1, bag_size, 1)  # shape (Batch, bag, 1)\n",
    "            temp_data = temp_data.expand(-1, -1, self.num_nodes)  # shape ( Batch, bag, num_nodes)\n",
    "\n",
    "            k_diff = k_sample_points - temp_data  # shape ( Batch, bag, num_nodes)\n",
    "            k_diff_2 = torch.square(k_diff)  # shape ( Batch, bag, num_nodes)\n",
    "            k_result = k_alfa * torch.exp(k_beta * k_diff_2)  # shape ( Batch, bag, num_nodes)\n",
    "            k_out_unnormalized = torch.sum(k_result, dim=1)  # (B, num_nodes)\n",
    "            k_norm_coeff = k_out_unnormalized.sum(dim=1).view(batch_size, 1)  # (B,1)\n",
    "            k_out = k_out_unnormalized / k_norm_coeff.expand(-1, k_out_unnormalized.size(1))  # (B, num_nodes)\n",
    "\n",
    "            out_list.append(k_out)\n",
    "        # out_list is of shape (J, B, num_nodes)\n",
    "        concat_out = torch.cat(out_list, dim=-1)  # shape is (Batch, J*num_nodes)\n",
    "        return concat_out  # shape is (Batch, J*num_nodes) -> (1, 8448)"
   ],
   "metadata": {
    "id": "9cjeF5dQ1iP8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UCC Prediction model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JGmU46C_1iP8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class UCCPredictor(nn.Module):\n",
    "    def __init__(self, device=config.device, ucc_limit=config.ucc_limit):\n",
    "        super().__init__()\n",
    "        # Input size: [Batch, Bag, 48*16]\n",
    "        # Output size: [Batch, 4]\n",
    "        self.kde = KDE(device)\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # shape 4224\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),  # shape 2112\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2112, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, ucc_limit),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        kde_prob_distributions = self.kde(x)  # shape (Batch, 8448)\n",
    "        ucc_logits = self.stack(kde_prob_distributions)  # shape (Batch, 4)\n",
    "        return ucc_logits\n"
   ],
   "metadata": {
    "id": "4WOcBMfx1iP9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RCC Prediction model\n",
    "\n",
    "This is the additional multi task path which predicts the \"Real Class Counts\""
   ],
   "metadata": {
    "collapsed": false,
    "id": "CZPGaWEN1iP9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class RCCPredictor(nn.Module):\n",
    "    def __init__(self, device=config.device, rcc_limit=config.rcc_limit):\n",
    "        super().__init__()\n",
    "        # Input size: [Batch, Bag, 48*16]\n",
    "        # Output size: [Batch, 4]\n",
    "        self.kde = KDE(device)\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # shape 4224\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),  # shape 2112\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2112, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, rcc_limit),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        kde_prob_distributions = self.kde(x)  # shape (Batch, 8448)\n",
    "        rcc_logits = self.stack(kde_prob_distributions)  # shape (Batch, 10)\n",
    "        return rcc_logits\n"
   ],
   "metadata": {
    "id": "KNZvFZkc1iP9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXPERIMENT-1 : UCC Model\n",
    "\n",
    "This model tries to replicate the paper where we have an autoencoder path and a ucc path.\n",
    "\n",
    "Similarly experiment-2 will be the improvement model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "TDnB0lju1iP-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code for plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eJ6_aB7_1iP-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def plot_ucc_model_stats(\n",
    "        experiment, epochs,\n",
    "        ucc_training_losses, ae_training_losses, combined_training_losses,\n",
    "        ucc_training_accuracy,\n",
    "        ucc_validation_losses, ae_validation_losses, combined_validation_losses,\n",
    "        ucc_validation_accuracy\n",
    "    ):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "    # Plot training losses\n",
    "    axes[0, 0].plot(epochs, ucc_training_losses, marker=\"o\", color=\"red\", label=\"UCC Training Loss\")\n",
    "    axes[0, 0].plot(epochs, ae_training_losses, marker=\"o\", color=\"blue\", label=\"AE Training Loss\")\n",
    "    axes[0, 0].plot(epochs, combined_training_losses, marker=\"o\", color=\"green\", label=\"Combined Training Loss\")\n",
    "    axes[0, 0].set_title(f'{experiment}: Training Loss vs Epochs')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Training Loss')\n",
    "    axes[0, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot training accuracy\n",
    "    axes[0, 1].plot(epochs, ucc_training_accuracy, marker=\"o\", color=\"red\", label=\"UCC Training Accuracy\")\n",
    "    axes[0, 1].set_title(f'{experiment}: Training Accuracy vs Epochs')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Training Accuracy')\n",
    "    axes[0, 1].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation losses\n",
    "    axes[1, 0].plot(epochs, ucc_validation_losses, marker=\"o\", color=\"red\", label=\"UCC Validation Loss\")\n",
    "    axes[1, 0].plot(epochs, ae_validation_losses, marker=\"o\", color=\"blue\", label=\"AE Validation Loss\")\n",
    "    axes[1, 0].plot(epochs, combined_validation_losses, marker=\"o\", color=\"green\", label=\"Combined Validation Loss\")\n",
    "    axes[1, 0].set_title(f'{experiment}: Validation Loss vs Epochs')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Validation Loss')\n",
    "    axes[1, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation accuracy 1,1\n",
    "    axes[1, 1].plot(epochs, ucc_validation_accuracy, marker=\"o\", color=\"red\", label=\"UCC Validation Accuracy\")\n",
    "    axes[1, 1].set_title(f'{experiment}: Validation Accuracy vs Epochs')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Validation Accuracy')\n",
    "    axes[1, 1].legend()  # Display the legend\n",
    "\n",
    "    # Add space between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # close it properly\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ],
   "metadata": {
    "id": "x2DZEDgD1iP-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UCC Trainer class"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eQFSEJr71iP_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class UCCTrainer:\n",
    "    def __init__(self,\n",
    "                 name, autoencoder_model, ucc_predictor_model,\n",
    "                 dataset, save_dir, device=config.device):\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "        self.device = device\n",
    "\n",
    "        # data\n",
    "        self.train_loader = dataset.ucc_train_dataloader\n",
    "        self.test_loader = dataset.ucc_test_dataloader\n",
    "        self.val_loader = dataset.ucc_val_dataloader\n",
    "        self.kde_loaders = dataset.kde_test_dataloaders  # each dataloader here will return shape of (batch, bag, 3,32,32) of a pure dataset\n",
    "        self.autoencoder_loaders = dataset.autoencoder_test_dataloaders\n",
    "\n",
    "        # create the directory if it doesn't exist!\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.save_dir, self.name), exist_ok=True)\n",
    "\n",
    "        self.autoencoder_model = autoencoder_model\n",
    "        self.ucc_predictor_model = ucc_predictor_model\n",
    "\n",
    "        # Adam optimizer(s)\n",
    "        self.ae_optimizer = optim.Adam(self.autoencoder_model.parameters(), lr=config.learning_rate,\n",
    "                                       weight_decay=config.weight_decay)\n",
    "        self.ucc_optimizer = optim.Adam(self.ucc_predictor_model.parameters(), lr=config.learning_rate,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "\n",
    "        # Loss criterion(s)\n",
    "        self.ae_loss_criterion = nn.MSELoss()\n",
    "        self.ucc_loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Transforms\n",
    "        self.tensor_to_img_transform = transforms.ToPILImage()\n",
    "\n",
    "        # Values which can change based on loaded checkpoint\n",
    "        self.start_epoch = 0\n",
    "        self.epoch_numbers = []\n",
    "        self.training_ae_losses = []\n",
    "        self.training_ucc_losses = []\n",
    "        self.training_losses = []\n",
    "        self.training_ucc_accuracies = []\n",
    "\n",
    "        self.val_ae_losses = []\n",
    "        self.val_ucc_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_ucc_accuracies = []\n",
    "\n",
    "        self.train_correct_predictions = 0\n",
    "        self.train_total_batches = 0\n",
    "\n",
    "    # main train code\n",
    "    def train(self,\n",
    "              num_epochs,\n",
    "              resume_epoch_num=None,\n",
    "              load_from_checkpoint=False,\n",
    "              epoch_saver_count=2):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # initialize the params from the saved checkpoint\n",
    "        self.init_params_from_checkpoint_hook(load_from_checkpoint, resume_epoch_num)\n",
    "\n",
    "        # set up scheduler\n",
    "        self.init_scheduler_hook(num_epochs)\n",
    "\n",
    "        # Custom progress bar for total epochs with color and displaying average epoch batch_loss\n",
    "        total_progress_bar = tqdm(\n",
    "            total=num_epochs, desc=f\"Total Epochs\", position=0,\n",
    "            bar_format=\"{desc}: {percentage}% |{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\",\n",
    "            dynamic_ncols=True, ncols=100, colour='red'\n",
    "        )\n",
    "\n",
    "        # Train loop\n",
    "        for epoch in range(self.start_epoch, self.start_epoch + num_epochs):\n",
    "            # Custom progress bar for each epoch with color\n",
    "            epoch_progress_bar = tqdm(\n",
    "                total=len(self.train_loader),\n",
    "                desc=f\"Epoch {epoch + 1}/{self.start_epoch + num_epochs}\",\n",
    "                position=1,\n",
    "                leave=False,\n",
    "                dynamic_ncols=True,\n",
    "                ncols=100,\n",
    "                colour='green'\n",
    "            )\n",
    "\n",
    "            # set all models to train mode\n",
    "            self.autoencoder_model.train()\n",
    "            self.ucc_predictor_model.train()\n",
    "\n",
    "            # set the epoch training batch_loss\n",
    "            epoch_training_loss = 0.0\n",
    "            epoch_ae_loss = 0.0\n",
    "            epoch_ucc_loss = 0.0\n",
    "\n",
    "            # iterate over each batch\n",
    "            for batch_idx, data in enumerate(self.train_loader):\n",
    "                images, one_hot_ucc_labels = data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                ae_loss, encoded, decoded = self.forward_propagate_autoencoder(images)\n",
    "                ucc_loss, batch_ucc_accuracy = self.forward_propogate_ucc(encoded, one_hot_ucc_labels, True)\n",
    "\n",
    "                # calculate combined loss\n",
    "                batch_loss = ae_loss + ucc_loss\n",
    "\n",
    "                # Gradient clipping\n",
    "                nn.utils.clip_grad_value_(self.autoencoder_model.parameters(), config.grad_clip)\n",
    "                nn.utils.clip_grad_value_(self.ucc_predictor_model.parameters(), config.grad_clip)\n",
    "\n",
    "                # do optimizer step and zerograd for autoencoder model\n",
    "                self.ae_optimizer.step()\n",
    "                self.ae_optimizer.zero_grad()\n",
    "\n",
    "                # do optimizer step and zerograd for ucc model\n",
    "                self.ucc_optimizer.step()\n",
    "                self.ucc_optimizer.zero_grad()\n",
    "\n",
    "                # scheduler update (remove if it doesnt work!)\n",
    "                self.ae_scheduler.step()\n",
    "                self.ucc_scheduler.step()\n",
    "\n",
    "                # add to epoch batch_loss\n",
    "                epoch_training_loss += batch_loss.item()\n",
    "                epoch_ae_loss += ae_loss.item()\n",
    "                epoch_ucc_loss += ucc_loss.item()\n",
    "\n",
    "                # Update the epoch progress bar (overwrite in place)\n",
    "                batch_stats = {\n",
    "                    \"batch_loss\": batch_loss.item(),\n",
    "                    \"ae_loss\": ae_loss.item(),\n",
    "                    \"ucc_loss\": ucc_loss.item(),\n",
    "                    \"batch_ucc_acc\": batch_ucc_accuracy\n",
    "                }\n",
    "\n",
    "                epoch_progress_bar.set_postfix(batch_stats)\n",
    "                epoch_progress_bar.update(1)\n",
    "\n",
    "            # close the epoch progress bar\n",
    "            epoch_progress_bar.close()\n",
    "\n",
    "            # calculate average epoch train statistics\n",
    "            avg_train_stats = self.calculate_avg_train_stats_hook(epoch_training_loss, epoch_ae_loss, epoch_ucc_loss)\n",
    "\n",
    "            # calculate validation statistics\n",
    "            avg_val_stats = self.validation_hook()\n",
    "\n",
    "            # Store running history\n",
    "            self.store_running_history_hook(epoch, avg_train_stats, avg_val_stats)\n",
    "\n",
    "            # Show epoch stats\n",
    "            print(f\"# Epoch {epoch + 1}\")\n",
    "            epoch_postfix = self.calculate_and_print_epoch_stats_hook(avg_train_stats, avg_val_stats)\n",
    "\n",
    "            # Update the total progress bar\n",
    "            total_progress_bar.set_postfix(epoch_postfix)\n",
    "\n",
    "            # Close tqdm bar\n",
    "            total_progress_bar.update(1)\n",
    "\n",
    "            # Save model checkpoint periodically\n",
    "            need_to_save_model_checkpoint = (epoch + 1) % epoch_saver_count == 0\n",
    "            if need_to_save_model_checkpoint:\n",
    "                print(f\"Going to save model {self.name} @ Epoch:{epoch + 1}\")\n",
    "                self.save_model_checkpoint_hook(epoch, avg_train_stats, avg_val_stats)\n",
    "\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        # Close the total progress bar\n",
    "        total_progress_bar.close()\n",
    "\n",
    "        # Return the current state\n",
    "        return self.get_current_running_history_state_hook()\n",
    "\n",
    "    # hooks\n",
    "    def init_params_from_checkpoint_hook(self, load_from_checkpoint, resume_epoch_num):\n",
    "        if load_from_checkpoint:\n",
    "            # NOTE: resume_epoch_num can be None here if we want to load from the most recently saved checkpoint!\n",
    "            checkpoint_path = self.get_model_checkpoint_path(resume_epoch_num)\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "            # load previous state of models\n",
    "            self.autoencoder_model.load_state_dict(checkpoint['ae_model_state_dict'])\n",
    "            self.ucc_predictor_model.load_state_dict(checkpoint['ucc_model_state_dict'])\n",
    "\n",
    "            # load previous state of optimizers\n",
    "            self.ae_optimizer.load_state_dict(checkpoint['ae_optimizer_state_dict'])\n",
    "            self.ucc_optimizer.load_state_dict(checkpoint['ucc_optimizer_state_dict'])\n",
    "\n",
    "            # Things we are keeping track of\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.epoch_numbers = checkpoint['epoch_numbers']\n",
    "\n",
    "            self.training_losses = checkpoint['training_losses']\n",
    "            self.training_ae_losses = checkpoint['training_ae_losses']\n",
    "            self.training_ucc_losses = checkpoint['training_ucc_losses']\n",
    "            self.training_ucc_accuracies = checkpoint['training_ucc_accuracies']\n",
    "\n",
    "            self.val_losses = checkpoint['val_losses']\n",
    "            self.val_ae_losses = checkpoint['val_ae_losses']\n",
    "            self.val_ucc_losses = checkpoint['val_ucc_losses']\n",
    "            self.val_ucc_accuracies = checkpoint['val_ucc_accuracies']\n",
    "\n",
    "            print(f\"Model checkpoint for {self.name} is loaded from {checkpoint_path}!\")\n",
    "\n",
    "    def init_scheduler_hook(self, num_epochs):\n",
    "        # steps per epoch here is multiplied with bag size as we are doing it at an image level\n",
    "        self.ae_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.ae_optimizer,\n",
    "            config.learning_rate,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "            # steps_per_epoch=len(self.train_loader) * config.bag_size # this is only if I decide to go image by image level loss as opposed to bag level loss\n",
    "        )\n",
    "\n",
    "        # here we are doing it at a bag level\n",
    "        self.ucc_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.ucc_optimizer,\n",
    "            config.learning_rate,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "        )\n",
    "\n",
    "    def forward_propagate_autoencoder(self, images):\n",
    "        # data is of shape (batchsize=2,bag=10,channels=3,height=32,width=32)\n",
    "        # generally batch size of 16 is good for cifar10 so predicting 20 won't be so bad\n",
    "        batch_size, bag_size, num_channels, height, width = images.size()\n",
    "        batches_of_bag_images = images.view(batch_size * bag_size, num_channels, height, width)\n",
    "        encoded, decoded = self.autoencoder_model(\n",
    "            batches_of_bag_images)  # we are feeding in Batch*bag images of shape (3,32,32)\n",
    "        ae_loss = self.ae_loss_criterion(decoded, batches_of_bag_images)  # compares (Batch * Bag, 3,32,32)\n",
    "        return ae_loss, encoded, decoded\n",
    "\n",
    "    def forward_propogate_ucc(self, encoded, one_hot_ucc_labels, is_train_mode=True):\n",
    "        # encoded is of shape [Batch * Bag, 48*16] ->  make it into shape [Batch, Bag, 48*16]\n",
    "        batch_times_bag_size, feature_size = encoded.size()\n",
    "        bag_size = config.bag_size\n",
    "        batch_size = batch_times_bag_size // bag_size\n",
    "        encoded = encoded.view(batch_size, bag_size, feature_size)\n",
    "        ucc_logits = self.ucc_predictor_model(encoded)\n",
    "\n",
    "        # compute the ucc_loss\n",
    "        ucc_loss = self.ucc_loss_criterion(ucc_logits, one_hot_ucc_labels)\n",
    "\n",
    "        # compute the batch stats right here and save it\n",
    "        ucc_probs = nn.Softmax(dim=1)(ucc_logits)\n",
    "        predicted = torch.argmax(ucc_probs, 1)\n",
    "        labels = torch.argmax(one_hot_ucc_labels, 1)\n",
    "        batch_correct_predictions = (predicted == labels).sum().item()\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        # calculate batchwise accuracy/ucc_loss\n",
    "        batch_ucc_accuracy = batch_correct_predictions / batch_size\n",
    "        if is_train_mode:\n",
    "            self.train_correct_predictions += batch_correct_predictions\n",
    "            self.train_total_batches += batch_size\n",
    "        else:\n",
    "            self.eval_correct_predictions += batch_correct_predictions\n",
    "            self.eval_total_batches += batch_size\n",
    "        return ucc_loss, batch_ucc_accuracy\n",
    "\n",
    "    def calculate_avg_train_stats_hook(self, epoch_training_loss, epoch_ae_loss, epoch_ucc_loss):\n",
    "        avg_training_loss_for_epoch = epoch_training_loss / len(self.train_loader)\n",
    "        avg_ae_loss_for_epoch = epoch_ae_loss / len(self.train_loader)\n",
    "        avg_ucc_loss_for_epoch = epoch_ucc_loss / len(self.train_loader)\n",
    "        avg_ucc_training_accuracy = self.train_correct_predictions / self.train_total_batches\n",
    "\n",
    "        epoch_train_stats = {\n",
    "            \"avg_training_loss\": avg_training_loss_for_epoch,\n",
    "            \"avg_ae_loss\": avg_ae_loss_for_epoch,\n",
    "            \"avg_ucc_loss\": avg_ucc_loss_for_epoch,\n",
    "            \"avg_ucc_training_accuracy\": avg_ucc_training_accuracy\n",
    "        }\n",
    "\n",
    "        # reset\n",
    "        self.train_correct_predictions = 0\n",
    "        self.train_total_batches = 0\n",
    "\n",
    "        return epoch_train_stats\n",
    "\n",
    "    def validation_hook(self):\n",
    "        # class level init\n",
    "        self.eval_correct_predictions = 0\n",
    "        self.eval_total_batches = 0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_ae_loss = 0.0\n",
    "        val_ucc_loss = 0.0\n",
    "\n",
    "        # set all models to eval mode\n",
    "        self.autoencoder_model.eval()\n",
    "        self.ucc_predictor_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx, val_data in enumerate(self.val_loader):\n",
    "                val_images, val_one_hot_ucc_labels = val_data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                val_batch_ae_loss, val_encoded, val_decoded = self.forward_propagate_autoencoder(val_images)\n",
    "                val_batch_ucc_loss, val_batch_ucc_accuracy = self.forward_propogate_ucc(val_encoded,\n",
    "                                                                                        val_one_hot_ucc_labels, False)\n",
    "\n",
    "                # calculate combined loss\n",
    "                val_batch_loss = val_batch_ae_loss + val_batch_ucc_loss\n",
    "\n",
    "                # cummulate the losses\n",
    "                val_ae_loss += val_batch_ae_loss\n",
    "                val_ucc_loss += val_batch_ucc_loss\n",
    "                val_loss += val_batch_loss\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = val_loss / len(self.val_loader)\n",
    "        avg_val_ucc_loss = val_ucc_loss / len(self.val_loader)\n",
    "        avg_val_ae_loss = val_ae_loss / len(self.val_loader)\n",
    "        avg_val_ucc_training_accuracy = self.eval_correct_predictions / self.eval_total_batches\n",
    "\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.val_loader)\n",
    "\n",
    "        return {\n",
    "            \"avg_val_loss\": avg_val_loss,\n",
    "            \"avg_val_ae_loss\": avg_val_ae_loss,\n",
    "            \"avg_val_ucc_loss\": avg_val_ucc_loss,\n",
    "            \"avg_val_ucc_training_accuracy\": avg_val_ucc_training_accuracy\n",
    "        }\n",
    "\n",
    "    def calculate_and_print_epoch_stats_hook(self, avg_train_stats, avg_val_stats):\n",
    "        epoch_loss = avg_train_stats[\"avg_training_loss\"]\n",
    "        epoch_ae_loss = avg_train_stats[\"avg_ae_loss\"]\n",
    "        epoch_ucc_loss = avg_train_stats[\"avg_ucc_loss\"]\n",
    "        epoch_ucc_accuracy = avg_train_stats[\"avg_ucc_training_accuracy\"]\n",
    "\n",
    "        epoch_val_loss = avg_val_stats[\"avg_val_loss\"]\n",
    "        epoch_val_ae_loss = avg_val_stats[\"avg_val_ae_loss\"]\n",
    "        epoch_val_ucc_loss = avg_val_stats[\"avg_val_ucc_loss\"]\n",
    "        epoch_val_ucc_accuracy = avg_val_stats[\"avg_val_ucc_training_accuracy\"]\n",
    "\n",
    "        print(\n",
    "            f\"[TRAIN]: Epoch Loss: {epoch_loss} | AE Loss: {epoch_ae_loss} | UCC Loss: {epoch_ucc_loss} | UCC Acc: {epoch_ucc_accuracy}\")\n",
    "        print(\n",
    "            f\"[VAL]: Val Loss: {epoch_val_loss} | Val AE Loss: {epoch_val_ae_loss} | Val UCC Loss: {epoch_val_ucc_loss} | Val UCC Acc: {epoch_val_ucc_accuracy}\")\n",
    "\n",
    "        return {\n",
    "            \"epoch_loss\": epoch_loss,\n",
    "            \"epoch_ae_loss\": epoch_ae_loss,\n",
    "            \"epoch_ucc_loss\": epoch_ucc_loss,\n",
    "            \"epoch_ucc_acc\": epoch_ucc_accuracy,\n",
    "            \"epoch_val_loss\": epoch_val_loss,\n",
    "            \"epoch_val_ae_loss\": epoch_val_ae_loss,\n",
    "            \"epoch_val_ucc_loss\": epoch_val_ucc_loss,\n",
    "            \"epoch_val_ucc_acc\": epoch_val_ucc_accuracy\n",
    "        }\n",
    "\n",
    "    def store_running_history_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
    "        self.epoch_numbers.append(epoch + 1)\n",
    "\n",
    "        self.training_ae_losses.append(avg_train_stats[\"avg_ae_loss\"])\n",
    "        self.training_ucc_losses.append(avg_train_stats[\"avg_ucc_loss\"])\n",
    "        self.training_losses.append(avg_train_stats[\"avg_training_loss\"])\n",
    "        self.training_ucc_accuracies.append(avg_train_stats[\"avg_ucc_training_accuracy\"])\n",
    "\n",
    "        self.val_ae_losses.append(avg_val_stats[\"avg_val_ae_loss\"])\n",
    "        self.val_ucc_losses.append(avg_val_stats[\"avg_val_ucc_loss\"])\n",
    "        self.val_losses.append(avg_val_stats[\"avg_val_loss\"])\n",
    "        self.val_ucc_accuracies.append(avg_val_stats[\"avg_val_ucc_training_accuracy\"])\n",
    "\n",
    "    def get_current_running_history_state_hook(self):\n",
    "        return self.epoch_numbers, \\\n",
    "            self.training_ae_losses, self.training_ucc_losses, self.training_losses, self.training_ucc_accuracies, \\\n",
    "            self.val_ae_losses, self.val_ucc_losses, self.val_losses, self.val_ucc_accuracies\n",
    "\n",
    "    def save_model_checkpoint_hook(self, epoch):\n",
    "        # set it to train mode to save the weights (but doesn't matter apparently!)\n",
    "        self.autoencoder_model.train()\n",
    "        self.ucc_predictor_model.train()\n",
    "\n",
    "        # create the directory if it doesn't exist\n",
    "        model_save_directory = os.path.join(self.save_dir, self.name)\n",
    "        os.makedirs(model_save_directory, exist_ok=True)\n",
    "\n",
    "        # Checkpoint the model at the end of each epoch\n",
    "        checkpoint_path = os.path.join(model_save_directory, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(\n",
    "            {\n",
    "                'ae_model_state_dict': self.autoencoder_model.state_dict(),\n",
    "                'ucc_model_state_dict': self.ucc_predictor_model.state_dict(),\n",
    "                'ae_optimizer_state_dict': self.ae_optimizer.state_dict(),\n",
    "                'ucc_optimizer_state_dict': self.ucc_optimizer.state_dict(),\n",
    "                'epoch': epoch + 1,\n",
    "                'epoch_numbers': self.epoch_numbers,\n",
    "                'training_losses': self.training_losses,\n",
    "                'training_ae_losses': self.training_ae_losses,\n",
    "                'training_ucc_losses': self.training_ucc_losses,\n",
    "                'training_ucc_accuracies': self.training_ucc_accuracies,\n",
    "                'val_losses': self.val_losses,\n",
    "                'val_ae_losses': self.val_ae_losses,\n",
    "                'val_ucc_losses': self.val_ucc_losses,\n",
    "                'val_ucc_accuracies': self.val_ucc_accuracies,\n",
    "            },\n",
    "            checkpoint_path\n",
    "        )\n",
    "        print(f\"Saved the model checkpoint for experiment {self.name} for epoch {epoch + 1}\")\n",
    "\n",
    "    # find the most recent file and return the path\n",
    "    def get_model_checkpoint_path(self, epoch_num=None):\n",
    "        directory = os.path.join(self.save_dir, self.name)\n",
    "        if epoch_num == None:\n",
    "            # Get a list of all files in the directory\n",
    "            files = os.listdir(directory)\n",
    "\n",
    "            # Filter out only the files (exclude directories)\n",
    "            files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "            # Sort the files by their modification time in descending order (most recent first)\n",
    "            files.sort(key=lambda x: os.path.getmtime(os.path.join(directory, x)), reverse=True)\n",
    "\n",
    "            # Get the name of the most recently added file\n",
    "            model_file = files[0] if files else None\n",
    "        else:\n",
    "            model_file = f\"model_epoch_{epoch_num}.pt\"\n",
    "        return os.path.join(directory, model_file)\n",
    "\n",
    "    def show_sample_reconstructions(self, dataloader):\n",
    "        self.autoencoder_model.eval()\n",
    "\n",
    "        # Create a subplot grid\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(9, 9))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_data in dataloader:\n",
    "                val_images, _ = val_data\n",
    "\n",
    "                batch_size, bag_size, num_channels, height, width = val_images.size()\n",
    "                bag_val_images = val_images.view(batch_size * bag_size, num_channels, height, width)\n",
    "\n",
    "                # Forward pass through the model\n",
    "                _, _, val_reconstructed_images = self.forward_propagate_autoencoder(val_images)\n",
    "\n",
    "                # take only one image from the bag\n",
    "                sample_image = bag_val_images[0]\n",
    "                predicted_image = val_reconstructed_images[0]\n",
    "\n",
    "                # get it to cpu\n",
    "                sample_image = sample_image.to(\"cpu\")\n",
    "                predicted_image = predicted_image.to(\"cpu\")\n",
    "\n",
    "                # convert to PIL Image\n",
    "                sample_image = self.tensor_to_img_transform(sample_image)\n",
    "                predicted_image = self.tensor_to_img_transform(predicted_image)\n",
    "\n",
    "                axes[0].imshow(sample_image)\n",
    "                axes[0].set_title(f\"Sample Original Image\", color='green')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                axes[1].imshow(predicted_image)\n",
    "                axes[1].set_title(f\"Sample Reconstructed Image\", color='red')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # show only one image\n",
    "                break\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def test_model(self):\n",
    "        # class level init\n",
    "        self.eval_correct_predictions = 0\n",
    "        self.eval_total_batches = 0\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_ae_loss = 0.0\n",
    "        test_ucc_loss = 0.0\n",
    "\n",
    "        # set all models to eval mode\n",
    "        self.autoencoder_model.eval()\n",
    "        self.ucc_predictor_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_batch_idx, test_data in enumerate(self.test_loader):\n",
    "                test_images, test_one_hot_ucc_labels = test_data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                test_batch_ae_loss, test_encoded, test_decoded = self.forward_propagate_autoencoder(test_images)\n",
    "                test_batch_ucc_loss, test_batch_ucc_accuracy = self.forward_propogate_ucc(test_encoded,\n",
    "                                                                                          test_one_hot_ucc_labels,\n",
    "                                                                                          False)\n",
    "\n",
    "                # calculate combined loss\n",
    "                test_batch_loss = test_batch_ae_loss + test_batch_ucc_loss\n",
    "\n",
    "                # cummulate the losses\n",
    "                test_ae_loss += test_batch_ae_loss\n",
    "                test_ucc_loss += test_batch_ucc_loss\n",
    "                test_loss += test_batch_loss\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_test_loss = test_loss / len(self.val_loader)\n",
    "        avg_test_ucc_loss = test_ucc_loss / len(self.val_loader)\n",
    "        avg_test_ae_loss = test_ae_loss / len(self.val_loader)\n",
    "        avg_test_ucc_training_accuracy = self.eval_correct_predictions / self.eval_total_batches\n",
    "\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.test_loader)\n",
    "\n",
    "        return {\n",
    "            \"avg_test_loss\": avg_test_loss,\n",
    "            \"avg_test_ae_loss\": avg_test_ae_loss,\n",
    "            \"avg_test_ucc_loss\": avg_test_ucc_loss,\n",
    "            \"avg_test_ucc_training_accuracy\": avg_test_ucc_training_accuracy\n",
    "        }\n",
    "\n",
    "    def js_divergence(self, p, q):\n",
    "        \"\"\"\n",
    "        Calculate the Jensen-Shannon Divergence between two probability distributions p and q.\n",
    "\n",
    "        Args:\n",
    "        p (torch.Tensor): Probability distribution p.\n",
    "        q (torch.Tensor): Probability distribution q.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Jensen-Shannon Divergence between p and q.\n",
    "        \"\"\"\n",
    "        # Calculate the average distribution 'm'\n",
    "        m = 0.5 * (p + q)\n",
    "\n",
    "        # Calculate the KL Divergence of 'p' and 'q' from 'm'\n",
    "        kl_div_p = F.kl_div(p.log(), m, reduction='batchmean')\n",
    "        kl_div_q = F.kl_div(q.log(), m, reduction='batchmean')\n",
    "\n",
    "        # Compute the JS Divergence\n",
    "        js_divergence = 0.5 * (kl_div_p + kl_div_q)\n",
    "\n",
    "        return js_divergence\n",
    "\n",
    "    def calculate_min_js_divergence(self):\n",
    "        num_classes = len(self.kde_loaders)\n",
    "        kde_per_class = {class_idx: 0.0 for class_idx in range(num_classes)}\n",
    "\n",
    "        # find the average kde across all classes\n",
    "        for class_idx, pure_class_kde_loader in tqdm(enumerate(self.kde_loaders)):\n",
    "            num_imgs_in_class = 0\n",
    "            for batch_idx, images in tqdm(enumerate(pure_class_kde_loader)):\n",
    "                # batch data is of shape ( Batch,bag, 3,32,32)\n",
    "                batch_size, bag_size, num_channels, height, width = images.size()\n",
    "                # reshaping to shape ( batch * bag, 3 ,32,32)\n",
    "                batches_of_bag_images = images.view(batch_size * bag_size, num_channels, height, width)\n",
    "                latent_features = self.autoencoder_model.encoder(batches_of_bag_images)  # shape (Batch * bag, 48*16)\n",
    "                batch_kde_distributions = self.ucc_predictor_model.kde(latent_features)  # shape [Batch=2, 8448]\n",
    "                num_imgs_in_class += batch_kde_distributions.size(0)\n",
    "                kde_distributions = torch.sum(batch_kde_distributions, dim=0)\n",
    "                kde_per_class[class_idx] += kde_distributions\n",
    "            kde_per_class[class_idx] /= num_imgs_in_class\n",
    "\n",
    "        # find the js_divergence\n",
    "        min_divergence = torch.inf\n",
    "        best_i = None\n",
    "        best_j = None\n",
    "        for i in range(num_classes):\n",
    "            for j in range(i + 1, num_classes):\n",
    "                divergence = self.js_divergence(kde_per_class[i], kde_per_class[j])\n",
    "                print(f\"JS Divergence between {i} & {j} is {divergence}\")\n",
    "                if divergence < min_divergence:\n",
    "                    min_divergence = divergence\n",
    "                    best_i = i\n",
    "                    best_j = j\n",
    "\n",
    "        print(f\"Min JS Divergence is {min_divergence} between classes {best_i} & {best_j}\")\n",
    "        # return the min divergence\n",
    "        return min_divergence\n",
    "\n",
    "    def calculate_clustering_accuracy(self):\n",
    "        all_latent_features = []\n",
    "        truth_labels_arr = []\n",
    "        for pure_autoencoder_loader in self.autoencoder_loaders:\n",
    "            for batch_idx, data in tqdm(enumerate(pure_autoencoder_loader)):\n",
    "                # batch data is of shape (1,3,32,32), (1,1)\n",
    "                image, label = data\n",
    "                latent_features = self.autoencoder_model.encoder(image)  # shape (1, 48*16)\n",
    "\n",
    "                latent_features = latent_features.squeeze().numpy()  # ndarray shape (48*16)\n",
    "                label = label.squeeze().numpy()  # ndarray shape (1)\n",
    "\n",
    "                all_latent_features.append(latent_features)\n",
    "                truth_labels_arr.append(label)\n",
    "\n",
    "        all_latent_features = np.array(all_latent_features)\n",
    "\n",
    "        # Do kmeans fit\n",
    "        estimator = KMeans(n_clusters=10, init='k-means++', n_init=10)\n",
    "        estimator.fit(all_latent_features)\n",
    "        predicted_clustering_labels = estimator.labels_\n",
    "\n",
    "        # Calculate accuracy\n",
    "        cost_matrix = np.zeros((10, 10))\n",
    "        num_samples = np.zeros(10)\n",
    "        for truth_val in range(10):\n",
    "            temp_sample_indices = np.where(truth_labels_arr == truth_val)[0]\n",
    "            num_samples[truth_val] = temp_sample_indices.shape[0]\n",
    "\n",
    "            temp_predicted_labels = predicted_clustering_labels[temp_sample_indices]\n",
    "\n",
    "            for predicted_val in range(10):\n",
    "                temp_matching_pairs = np.where(temp_predicted_labels == predicted_val)[0]\n",
    "                cost_matrix[truth_val, predicted_val] = 1 - (temp_matching_pairs.shape[0] / temp_sample_indices.shape[0])\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        cost = cost_matrix[row_ind, col_ind]\n",
    "\n",
    "        clustering_acc = ((1 - cost) * num_samples).sum() / num_samples.sum()\n",
    "        return clustering_acc"
   ],
   "metadata": {
    "id": "M60Wtb3q1iP_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the model instances\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "x4uMZhWh1iQC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "experiment1 = \"ucc\"\n",
    "save_dir = os.path.abspath(config.weights_path)\n",
    "autoencoder_ucc_model = Autoencoder().to(config.device)\n",
    "ucc_predictor_model = UCCPredictor().to(config.device)\n",
    "\n",
    "#creating the trainer\n",
    "ucc_trainer = UCCTrainer(experiment1, autoencoder_ucc_model, ucc_predictor_model, dataset, save_dir)"
   ],
   "metadata": {
    "id": "VpCY1qx_1iQC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Sx9jdjiT1iQD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Total Epochs: 0.0% |          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e019bd261274eb889e12a6bb803980d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ff1edef82854a08af9b0b671cab1582"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-e4a2d3b1c4ee>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mexp1_epoch_numbers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_training_ae_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_training_ucc_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_training_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_training_ucc_accuracies\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_val_ae_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_val_ucc_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_val_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp1_val_ucc_accuracies\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mucc_trainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_saver_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-23-20e6049c255c>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, num_epochs, resume_epoch_num, load_from_checkpoint, epoch_saver_count)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m                 \u001B[0;31m# Gradient clipping\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m                 \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclip_grad_value_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautoencoder_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad_clip\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m                 \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclip_grad_value_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mucc_predictor_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad_clip\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001B[0m in \u001B[0;36mclip_grad_value_\u001B[0;34m(parameters, clip_value, foreach)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 122\u001B[0;31m     \u001B[0mgrouped_grads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_group_tensors_by_device_and_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgrouped_grads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# type: ignore[assignment]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mctx_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_foreach_utils.py\u001B[0m in \u001B[0;36m_group_tensors_by_device_and_dtype\u001B[0;34m(tensorlistlist, with_indices)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr_dtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr_dtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_group_tensors_by_device_and_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensorlistlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwith_indices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m     }\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected nested_tensorlist[0].size() > 0 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "exp1_epoch_numbers, exp1_training_ae_losses, exp1_training_ucc_losses, exp1_training_losses, exp1_training_ucc_accuracies, exp1_val_ae_losses, exp1_val_ucc_losses, exp1_val_losses, exp1_val_ucc_accuracies = ucc_trainer.train(1, epoch_saver_count=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "2e019bd261274eb889e12a6bb803980d",
      "df9c0ae2b09746f78a992e73f382d46a",
      "7c14752a41c74babaee2f3b760d87952",
      "5bd551ff08954c95b31b654d8c741d63",
      "078c903c16594b1e800c5f921255fa08",
      "59398352661e4b1587cc3a6a3db5943c",
      "8e8e378b32d647ef838c4cb6427142b9",
      "2f0300a87dee4820a74e31a748394c46",
      "f4f7aaf438284532a00e9f6332b3b87b",
      "e109cc3b98e14e849f5464b5fc855ee3",
      "b46466bcecd24d89a33497be7c1aaa02",
      "3ff1edef82854a08af9b0b671cab1582",
      "a3ac8abffcbd43e1ae49cbddd6cc8782",
      "f7c70ff1bd4a475a92d34df099e89f22",
      "83dbc2ae508147f3b38005bcc5a90c59",
      "b0735fb89e274ab681caaa38006316c3",
      "54ab6b76da194e0595828bf1e6ea2d0d",
      "d9d78c8f00f942ac9397fa879e45ae30",
      "cc4933629e7141ecb0e5471bc96619cc",
      "c5d6c9dfc393428087c79064f0b68306",
      "7e45ceb9b1f54c2e81300214c5791195",
      "ffdc49f364ce4d6a9ec43d119f51ea9a"
     ]
    },
    "id": "fMmNzHjh1iQD",
    "outputId": "720f08c8-3ae9-4527-f683-2725ddbb4524"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Training if required"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Z5E9BBOW1iQD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# exp1_epoch_numbers, exp1_training_ae_losses, exp1_training_ucc_losses, exp1_training_losses, exp1_training_ucc_accuracies, exp1_val_ae_losses, exp1_val_ucc_losses, exp1_val_losses, exp1_val_ucc_accuracies = ucc_trainer.train(10, epoch_saver_count=2, load_from_checkpoint=True, resume_epoch_num=42)"
   ],
   "metadata": {
    "id": "oll7t0Um1iQE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "657-1hre1iQE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ucc_model_stats(experiment1, exp1_epoch_numbers, exp1_training_ucc_losses, exp1_training_ae_losses, exp1_training_losses,\n",
    "                     exp1_training_ucc_accuracies, exp1_val_ucc_losses, exp1_val_ae_losses, exp1_val_losses,\n",
    "                     exp1_val_ucc_accuracies)"
   ],
   "metadata": {
    "id": "M_XL0foF1iQR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AdTrkEp51iQS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ucc_trainer.test_model()"
   ],
   "metadata": {
    "id": "33EoZ35D1iQS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Min JS Divergence"
   ],
   "metadata": {
    "collapsed": false,
    "id": "kV7zMOmV1iQS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp1_min_js_divg = ucc_trainer.calculate_min_js_divergence()\n",
    "exp1_min_js_divg"
   ],
   "metadata": {
    "id": "CHfm5y2F1iQT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Clustering Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "id": "glJIi-uG1iQU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp1_clustering_accuracies = ucc_trainer.calculate_clustering_accuracy()\n",
    "exp1_clustering_accuracies"
   ],
   "metadata": {
    "id": "p08wTB5R1iQU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "yGs7nH431iQU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXPERIMENT-2 : UCC-RCC Model\n",
    "\n",
    "This model is an improvement to the original model as we are also trying to predict the RCC (Real Class Counts) as a separate multitask path. This approach in theory should improve the accuracy of the model.\n",
    "\n",
    "Additionally we use the SSIM loss for the autoencoder as that is known to be a good loss function when it comes to autoencoders.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "VrT8asRY1iQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SSIM Loss definition"
   ],
   "metadata": {
    "collapsed": false,
    "id": "A1oDEUBr1iQV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.ssim = SSIM()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Calculate SSIM\n",
    "        ssim_value = self.ssim(x, y)\n",
    "        # Subtract SSIM from 1\n",
    "        loss = 1 - ssim_value\n",
    "        return loss"
   ],
   "metadata": {
    "id": "6l9rTIPl1iQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code for plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OBPzYFLB1iQV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_ucc_rcc_model_stats(\n",
    "        experiment, epochs,\n",
    "        ucc_training_losses, ae_training_losses, rcc_training_losses, combined_training_losses,\n",
    "        ucc_training_accuracy, rcc_training_accuracy,\n",
    "        ucc_validation_losses, ae_validation_losses, rcc_validation_losses, combined_validation_losses,\n",
    "        ucc_validation_accuracy, rcc_validation_accuracy\n",
    "    ):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "    # Plot training losses\n",
    "    axes[0, 0].plot(epochs, ucc_training_losses, marker=\"o\", color=\"red\", label=\"UCC Training Loss\")\n",
    "    axes[0, 0].plot(epochs, ae_training_losses, marker=\"o\", color=\"blue\", label=\"AE Training Loss\")\n",
    "    axes[0, 0].plot(epochs, rcc_training_losses, marker=\"o\", color=\"yellow\", label=\"RCC Training Loss\")\n",
    "    axes[0, 0].plot(epochs, combined_training_losses, marker=\"o\", color=\"green\", label=\"Combined Training Loss\")\n",
    "    axes[0, 0].set_title(f'{experiment}: Training Loss vs Epochs')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Training Loss')\n",
    "    axes[0, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot training accuracy\n",
    "    axes[0, 1].plot(epochs, ucc_training_accuracy, marker=\"o\", color=\"red\", label=\"UCC Training Accuracy\")\n",
    "    axes[0, 1].plot(epochs, rcc_training_accuracy, marker=\"o\", color=\"green\", label=\"RCC Training Accuracy\")\n",
    "    axes[0, 1].set_title(f'{experiment}: Training Accuracy vs Epochs')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Training Accuracy')\n",
    "    axes[0, 1].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation losses\n",
    "    axes[1, 0].plot(epochs, ucc_validation_losses, marker=\"o\", color=\"red\", label=\"UCC Validation Loss\")\n",
    "    axes[1, 0].plot(epochs, ae_validation_losses, marker=\"o\", color=\"blue\", label=\"AE Validation Loss\")\n",
    "    axes[1, 0].plot(epochs, rcc_validation_losses, marker=\"o\", color=\"yellow\", label=\"RCC Validation Loss\")\n",
    "    axes[1, 0].plot(epochs, combined_validation_losses, marker=\"o\", color=\"green\", label=\"Combined Validation Loss\")\n",
    "    axes[1, 0].set_title(f'{experiment}: Validation Loss vs Epochs')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Validation Loss')\n",
    "    axes[1, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation accuracy 1,1\n",
    "    axes[1, 1].plot(epochs, ucc_validation_accuracy, marker=\"o\", color=\"red\", label=\"UCC Validation Accuracy\")\n",
    "    axes[1, 1].plot(epochs, rcc_validation_accuracy, marker=\"o\", color=\"green\", label=\"RCC Validation Accuracy\")\n",
    "    axes[1, 1].set_title(f'{experiment}: Validation Accuracy vs Epochs')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Validation Accuracy')\n",
    "    axes[1, 1].legend()  # Display the legend\n",
    "\n",
    "    # Add space between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # close it properly\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ],
   "metadata": {
    "id": "NiPt-qD41iQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RCC Trainer class"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OrfJdCET1iQW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RCCTrainer:\n",
    "    def __init__(self,\n",
    "                 name, autoencoder_model, ucc_predictor_model, rcc_predictor_model,\n",
    "                 dataset, save_dir, device=config.device):\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "        self.device = device\n",
    "\n",
    "        # data\n",
    "        self.train_loader = dataset.ucc_rcc_train_dataloader\n",
    "        self.test_loader = dataset.ucc_rcc_test_dataloader\n",
    "        self.val_loader = dataset.ucc_rcc_val_dataloader\n",
    "        self.kde_loaders = dataset.kde_test_dataloaders  # each dataloader here will return shape of (batch, bag, 3,32,32) of a pure dataset\n",
    "        self.autoencoder_loaders = dataset.autoencoder_test_dataloaders\n",
    "\n",
    "        # create the directory if it doesn't exist!\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.save_dir, self.name), exist_ok=True)\n",
    "\n",
    "        self.autoencoder_model = autoencoder_model\n",
    "        self.ucc_predictor_model = ucc_predictor_model\n",
    "        self.rcc_predictor_model = rcc_predictor_model\n",
    "\n",
    "        # Adam optimizer(s)\n",
    "        self.ae_optimizer = optim.Adam(self.autoencoder_model.parameters(), lr=config.learning_rate,\n",
    "                                       weight_decay=config.weight_decay)\n",
    "        self.ucc_optimizer = optim.Adam(self.ucc_predictor_model.parameters(), lr=config.learning_rate,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "        self.rcc_optimizer = optim.Adam(self.rcc_predictor_model.parameters(), lr=config.learning_rate,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "\n",
    "        # Loss criterion(s)\n",
    "        self.ae_loss_criterion = SSIMLoss()\n",
    "        self.ucc_loss_criterion = nn.CrossEntropyLoss()\n",
    "        self.rcc_loss_criterion = nn.MSELoss()\n",
    "\n",
    "        # Transforms\n",
    "        self.tensor_to_img_transform = transforms.ToPILImage()\n",
    "\n",
    "        # Values which can change based on loaded checkpoint\n",
    "        self.start_epoch = 0\n",
    "        self.epoch_numbers = []\n",
    "\n",
    "        self.training_losses = []\n",
    "        self.training_ae_losses = []\n",
    "        self.training_ucc_losses = []\n",
    "        self.training_rcc_losses = []\n",
    "        self.training_ucc_accuracies = []\n",
    "        self.training_rcc_accuracies = []\n",
    "\n",
    "        self.val_losses = []\n",
    "        self.val_ae_losses = []\n",
    "        self.val_ucc_losses = []\n",
    "        self.val_rcc_losses = []\n",
    "        self.val_ucc_accuracies = []\n",
    "        self.val_rcc_accuracies = []\n",
    "\n",
    "        self.train_ucc_correct_predictions = 0\n",
    "        self.train_ucc_total_batches = 0\n",
    "\n",
    "        self.train_rcc_correct_predictions = 0\n",
    "        self.train_rcc_total_batches = 0\n",
    "\n",
    "    # main train code\n",
    "    def train(self,\n",
    "              num_epochs,\n",
    "              resume_epoch_num=None,\n",
    "              load_from_checkpoint=False,\n",
    "              epoch_saver_count=2):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # initialize the params from the saved checkpoint\n",
    "        self.init_params_from_checkpoint_hook(load_from_checkpoint, resume_epoch_num)\n",
    "\n",
    "        # set up scheduler\n",
    "        self.init_scheduler_hook(num_epochs)\n",
    "\n",
    "        # Custom progress bar for total epochs with color and displaying average epoch batch_loss\n",
    "        total_progress_bar = tqdm(\n",
    "            total=num_epochs, desc=f\"Total Epochs\", position=0,\n",
    "            bar_format=\"{desc}: {percentage}% |{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\",\n",
    "            dynamic_ncols=True, ncols=100, colour='red'\n",
    "        )\n",
    "\n",
    "        # Train loop\n",
    "        for epoch in range(self.start_epoch, self.start_epoch + num_epochs):\n",
    "            # Custom progress bar for each epoch with color\n",
    "            epoch_progress_bar = tqdm(\n",
    "                total=len(self.train_loader),\n",
    "                desc=f\"Epoch {epoch + 1}/{self.start_epoch + num_epochs}\",\n",
    "                position=1,\n",
    "                leave=False,\n",
    "                dynamic_ncols=True,\n",
    "                ncols=100,\n",
    "                colour='green'\n",
    "            )\n",
    "\n",
    "            # set all models to train mode\n",
    "            self.autoencoder_model.train()\n",
    "            self.ucc_predictor_model.train()\n",
    "            self.rcc_predictor_model.train()\n",
    "\n",
    "            # set the epoch training batch_loss\n",
    "            epoch_training_loss = 0.0\n",
    "            epoch_ae_loss = 0.0\n",
    "            epoch_ucc_loss = 0.0\n",
    "            epoch_rcc_loss = 0.0\n",
    "\n",
    "            # iterate over each batch\n",
    "            for batch_idx, data in enumerate(self.train_loader):\n",
    "                images, one_hot_ucc_labels, rcc_labels = data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                ae_loss, encoded, decoded = self.forward_propagate_autoencoder(images)\n",
    "                ucc_loss, batch_ucc_accuracy = self.forward_propogate_ucc(encoded, one_hot_ucc_labels, True)\n",
    "                rcc_loss, batch_rcc_accuracy = self.forward_propogate_rcc(encoded, rcc_labels, True)\n",
    "\n",
    "                # calculate combined loss\n",
    "                batch_loss = ae_loss + ucc_loss + rcc_loss\n",
    "\n",
    "                # Gradient clipping\n",
    "                nn.utils.clip_grad_value_(self.autoencoder_model.parameters(), config.grad_clip)\n",
    "                nn.utils.clip_grad_value_(self.ucc_predictor_model.parameters(), config.grad_clip)\n",
    "\n",
    "                # do optimizer step and zerograd for autoencoder model\n",
    "                self.ae_optimizer.step()\n",
    "                self.ae_optimizer.zero_grad()\n",
    "\n",
    "                # do optimizer step and zerograd for ucc model\n",
    "                self.ucc_optimizer.step()\n",
    "                self.ucc_optimizer.zero_grad()\n",
    "\n",
    "                # do optimizer step and zerograd for rcc model\n",
    "                self.rcc_optimizer.step()\n",
    "                self.rcc_optimizer.zero_grad()\n",
    "\n",
    "                # scheduler update (remove if it doesnt work!)\n",
    "                self.ae_scheduler.step()\n",
    "                self.ucc_scheduler.step()\n",
    "                self.rcc_scheduler.step()\n",
    "\n",
    "                # add to epoch batch_loss\n",
    "                epoch_training_loss += batch_loss.item()\n",
    "                epoch_ae_loss += ae_loss.item()\n",
    "                epoch_ucc_loss += ucc_loss.item()\n",
    "                epoch_rcc_loss += rcc_loss.item()\n",
    "\n",
    "                # Update the epoch progress bar (overwrite in place)\n",
    "                batch_stats = {\n",
    "                    \"batch_loss\": batch_loss.item(),\n",
    "                    \"ae_loss\": ae_loss.item(),\n",
    "                    \"ucc_loss\": ucc_loss.item(),\n",
    "                    \"rcc_loss\": rcc_loss.item(),\n",
    "                    \"batch_ucc_acc\": batch_ucc_accuracy,\n",
    "                    \"batch_rcc_acc\": batch_rcc_accuracy\n",
    "                }\n",
    "\n",
    "                epoch_progress_bar.set_postfix(batch_stats)\n",
    "                epoch_progress_bar.update(1)\n",
    "\n",
    "            # close the epoch progress bar\n",
    "            epoch_progress_bar.close()\n",
    "\n",
    "            # calculate average epoch train statistics\n",
    "            avg_train_stats = self.calculate_avg_train_stats_hook(epoch_training_loss, epoch_ae_loss, epoch_ucc_loss,\n",
    "                                                                  epoch_rcc_loss)\n",
    "\n",
    "            # calculate validation statistics\n",
    "            avg_val_stats = self.validation_hook()\n",
    "\n",
    "            # Store running history\n",
    "            self.store_running_history_hook(epoch, avg_train_stats, avg_val_stats)\n",
    "\n",
    "            # Show epoch stats\n",
    "            print(f\"# Epoch {epoch + 1}\")\n",
    "            epoch_postfix = self.calculate_and_print_epoch_stats_hook(avg_train_stats, avg_val_stats)\n",
    "\n",
    "            # Update the total progress bar\n",
    "            total_progress_bar.set_postfix(epoch_postfix)\n",
    "\n",
    "            # Close tqdm bar\n",
    "            total_progress_bar.update(1)\n",
    "\n",
    "            # Save model checkpoint periodically\n",
    "            need_to_save_model_checkpoint = (epoch + 1) % epoch_saver_count == 0\n",
    "            if need_to_save_model_checkpoint:\n",
    "                print(f\"Going to save model {self.name} @ Epoch:{epoch + 1}\")\n",
    "                self.save_model_checkpoint_hook(epoch)\n",
    "\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        # Close the total progress bar\n",
    "        total_progress_bar.close()\n",
    "\n",
    "        # Return the current state\n",
    "        return self.get_current_running_history_state_hook()\n",
    "\n",
    "    # hooks\n",
    "    # DONE\n",
    "    def init_params_from_checkpoint_hook(self, load_from_checkpoint, resume_epoch_num):\n",
    "        if load_from_checkpoint:\n",
    "            # NOTE: resume_epoch_num can be None here if we want to load from the most recently saved checkpoint!\n",
    "            checkpoint_path = self.get_model_checkpoint_path(resume_epoch_num)\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "            # load previous state of models\n",
    "            self.autoencoder_model.load_state_dict(checkpoint['ae_model_state_dict'])\n",
    "            self.ucc_predictor_model.load_state_dict(checkpoint['ucc_model_state_dict'])\n",
    "            self.rcc_predictor_model.load_state_dict(checkpoint['rcc_model_state_dict'])\n",
    "\n",
    "            # load previous state of optimizers\n",
    "            self.ae_optimizer.load_state_dict(checkpoint['ae_optimizer_state_dict'])\n",
    "            self.ucc_optimizer.load_state_dict(checkpoint['ucc_optimizer_state_dict'])\n",
    "            self.rcc_optimizer.load_state_dict(checkpoint['rcc_optimizer_state_dict'])\n",
    "\n",
    "            # Things we are keeping track of\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.epoch_numbers = checkpoint['epoch_numbers']\n",
    "\n",
    "            self.training_losses = checkpoint['training_losses']\n",
    "            self.training_ae_losses = checkpoint['training_ae_losses']\n",
    "            self.training_ucc_losses = checkpoint['training_ucc_losses']\n",
    "            self.training_rcc_losses = checkpoint['training_rcc_losses']\n",
    "            self.training_ucc_accuracies = checkpoint['training_ucc_accuracies']\n",
    "            self.training_rcc_accuracies = checkpoint['training_rcc_accuracies']\n",
    "\n",
    "            self.val_losses = checkpoint['val_losses']\n",
    "            self.val_ae_losses = checkpoint['val_ae_losses']\n",
    "            self.val_ucc_losses = checkpoint['val_ucc_losses']\n",
    "            self.val_rcc_losses = checkpoint['val_rcc_losses']\n",
    "            self.val_ucc_accuracies = checkpoint['val_ucc_accuracies']\n",
    "            self.val_rcc_accuracies = checkpoint['val_rcc_accuracies']\n",
    "\n",
    "            print(f\"Model checkpoint for {self.name} is loaded from {checkpoint_path}!\")\n",
    "\n",
    "    # DONE\n",
    "    def init_scheduler_hook(self, num_epochs):\n",
    "        # steps per epoch here is multiplied with bag size as we are doing it at an image level\n",
    "        self.ae_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.ae_optimizer,\n",
    "            config.learning_rate,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "            # steps_per_epoch=len(self.train_loader) * config.bag_size # this is only if I decide to go image by image level loss as opposed to bag level loss\n",
    "        )\n",
    "\n",
    "        # here we are doing it at a bag level\n",
    "        self.ucc_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.ucc_optimizer,\n",
    "            config.learning_rate,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "        )\n",
    "\n",
    "        # here we are doing it at a bag level\n",
    "        self.rcc_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.rcc_optimizer,\n",
    "            config.learning_rate,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "        )\n",
    "\n",
    "    # DONE\n",
    "    def forward_propagate_autoencoder(self, images):\n",
    "        # data is of shape (batchsize=2,bag=10,channels=3,height=32,width=32)\n",
    "        # generally batch size of 16 is good for cifar10 so predicting 20 won't be so bad\n",
    "        batch_size, bag_size, num_channels, height, width = images.size()\n",
    "        batches_of_bag_images = images.view(batch_size * bag_size, num_channels, height, width)\n",
    "        encoded, decoded = self.autoencoder_model(\n",
    "            batches_of_bag_images)  # we are feeding in Batch*bag images of shape (3,32,32)\n",
    "        ae_loss = self.ae_loss_criterion(decoded, batches_of_bag_images)  # compares (Batch * Bag, 3,32,32)\n",
    "        return ae_loss, encoded, decoded\n",
    "\n",
    "    # DONE\n",
    "    def forward_propogate_ucc(self, encoded, one_hot_ucc_labels, is_train_mode=True):\n",
    "        # decoded is of shape [Batch * Bag, 48*16] ->  make it into shape [Batch, Bag, 48*16]\n",
    "        batch_times_bag_size, feature_size = encoded.size()\n",
    "        bag_size = config.bag_size\n",
    "        batch_size = batch_times_bag_size // bag_size\n",
    "        encoded = encoded.view(batch_size, bag_size, feature_size)\n",
    "        ucc_logits = self.ucc_predictor_model(encoded)\n",
    "\n",
    "        # compute the ucc_loss\n",
    "        ucc_loss = self.ucc_loss_criterion(ucc_logits, one_hot_ucc_labels)\n",
    "\n",
    "        # compute the batch stats right here and save it\n",
    "        ucc_probs = nn.Softmax(dim=1)(ucc_logits)\n",
    "        predicted = torch.argmax(ucc_probs, 1)\n",
    "        labels = torch.argmax(one_hot_ucc_labels, 1)\n",
    "        batch_correct_predictions = (predicted == labels).sum().item()\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        # calculate batchwise accuracy/ucc_loss\n",
    "        batch_ucc_accuracy = batch_correct_predictions / batch_size\n",
    "        if is_train_mode:\n",
    "            self.train_ucc_correct_predictions += batch_correct_predictions\n",
    "            self.train_ucc_total_batches += batch_size\n",
    "        else:\n",
    "            self.eval_ucc_correct_predictions += batch_correct_predictions\n",
    "            self.eval_ucc_total_batches += batch_size\n",
    "        return ucc_loss, batch_ucc_accuracy\n",
    "\n",
    "    # DONE\n",
    "    '''\n",
    "    NOTE: To improve this I can also add a rcc-ucc-enforcement loss where the number of unique classes should match the ucc exactly\n",
    "    '''\n",
    "\n",
    "    def forward_propogate_rcc(self, encoded, rcc_labels, is_train_mode=True):\n",
    "        # decoded is of shape [Batch * Bag, 48*16] ->  make it into shape [Batch, Bag, 48*16]\n",
    "        batch_times_bag_size, feature_size = encoded.size()\n",
    "        bag_size = config.bag_size\n",
    "        batch_size = batch_times_bag_size // bag_size\n",
    "        encoded = encoded.view(batch_size, bag_size, feature_size)\n",
    "        rcc_logits = self.rcc_predictor_model(encoded) #Predicts (Batch, rcc length)\n",
    "\n",
    "        # round it to the nearest integer\n",
    "        predicted = torch.round(rcc_logits)\n",
    "\n",
    "        # compute the rcc_loss\n",
    "        rcc_loss = self.rcc_loss_criterion(rcc_logits, rcc_labels)\n",
    "\n",
    "        # NOTE: not sure if it is dim\n",
    "        batch_correct_predictions = (predicted == rcc_labels).sum().item()\n",
    "\n",
    "        # calculate batchwise accuracy/ucc_loss\n",
    "        batch_rcc_accuracy = batch_correct_predictions / batch_times_bag_size\n",
    "        if is_train_mode:\n",
    "            self.train_rcc_correct_predictions += batch_correct_predictions\n",
    "            self.train_rcc_total_batches += batch_times_bag_size\n",
    "        else:\n",
    "            self.eval_rcc_correct_predictions += batch_correct_predictions\n",
    "            self.eval_rcc_total_batches += batch_times_bag_size\n",
    "        return rcc_loss, batch_rcc_accuracy\n",
    "\n",
    "    # DONE\n",
    "    def calculate_avg_train_stats_hook(self, epoch_training_loss, epoch_ae_loss, epoch_ucc_loss, epoch_rcc_loss):\n",
    "        avg_training_loss_for_epoch = epoch_training_loss / len(self.train_loader)\n",
    "        avg_ae_loss_for_epoch = epoch_ae_loss / len(self.train_loader)\n",
    "        avg_ucc_loss_for_epoch = epoch_ucc_loss / len(self.train_loader)\n",
    "        avg_rcc_loss_for_epoch = epoch_rcc_loss / len(self.train_loader)\n",
    "        avg_ucc_training_accuracy = self.train_ucc_correct_predictions / self.train_ucc_total_batches\n",
    "        avg_rcc_training_accuracy = self.train_rcc_correct_predictions / self.train_rcc_total_batches\n",
    "\n",
    "        epoch_train_stats = {\n",
    "            \"avg_training_loss\": avg_training_loss_for_epoch,\n",
    "            \"avg_ae_loss\": avg_ae_loss_for_epoch,\n",
    "            \"avg_ucc_loss\": avg_ucc_loss_for_epoch,\n",
    "            \"avg_rcc_loss\": avg_rcc_loss_for_epoch,\n",
    "            \"avg_ucc_training_accuracy\": avg_ucc_training_accuracy,\n",
    "            \"avg_rcc_training_accuracy\": avg_rcc_training_accuracy\n",
    "        }\n",
    "\n",
    "        # reset\n",
    "        self.train_ucc_correct_predictions = 0\n",
    "        self.train_ucc_total_batches = 0\n",
    "\n",
    "        self.train_rcc_correct_predictions = 0\n",
    "        self.train_rcc_total_batches = 0\n",
    "\n",
    "        return epoch_train_stats\n",
    "\n",
    "    # DONE\n",
    "    def validation_hook(self):\n",
    "        # class level init\n",
    "        self.eval_ucc_correct_predictions = 0\n",
    "        self.eval_ucc_total_batches = 0\n",
    "\n",
    "        self.eval_rcc_correct_predictions = 0\n",
    "        self.eval_rcc_total_batches = 0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_ae_loss = 0.0\n",
    "        val_ucc_loss = 0.0\n",
    "        val_rcc_loss = 0.0\n",
    "\n",
    "        # set all models to eval mode\n",
    "        self.autoencoder_model.eval()\n",
    "        self.ucc_predictor_model.eval()\n",
    "        self.rcc_predictor_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx, val_data in enumerate(self.val_loader):\n",
    "                val_images, val_one_hot_ucc_labels, val_rcc_labels = val_data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                val_batch_ae_loss, val_encoded, val_decoded = self.forward_propagate_autoencoder(val_images)\n",
    "                val_batch_ucc_loss, val_batch_ucc_accuracy = self.forward_propogate_ucc(val_encoded,\n",
    "                                                                                        val_one_hot_ucc_labels, False)\n",
    "                val_batch_rcc_loss, val_batch_rcc_accuracy = self.forward_propogate_rcc(val_encoded, val_rcc_labels,\n",
    "                                                                                        False)\n",
    "\n",
    "                # calculate combined loss\n",
    "                val_batch_loss = val_batch_ae_loss + val_batch_ucc_loss + val_batch_rcc_loss\n",
    "\n",
    "                # cummulate the losses\n",
    "                val_loss += val_batch_loss\n",
    "                val_ae_loss += val_batch_ae_loss\n",
    "                val_ucc_loss += val_batch_ucc_loss\n",
    "                val_rcc_loss += val_batch_rcc_loss\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = val_loss / len(self.val_loader)\n",
    "        avg_val_ucc_loss = val_ucc_loss / len(self.val_loader)\n",
    "        avg_val_rcc_loss = val_rcc_loss / len(self.val_loader)\n",
    "        avg_val_ae_loss = val_ae_loss / len(self.val_loader)\n",
    "        avg_val_ucc_training_accuracy = self.eval_ucc_correct_predictions / self.eval_ucc_total_batches\n",
    "        avg_val_rcc_training_accuracy = self.eval_rcc_correct_predictions / self.eval_rcc_total_batches\n",
    "\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.val_loader)\n",
    "\n",
    "        return {\n",
    "            \"avg_val_loss\": avg_val_loss,\n",
    "            \"avg_val_ae_loss\": avg_val_ae_loss,\n",
    "            \"avg_val_ucc_loss\": avg_val_ucc_loss,\n",
    "            \"avg_val_rcc_loss\": avg_val_rcc_loss,\n",
    "            \"avg_val_ucc_training_accuracy\": avg_val_ucc_training_accuracy,\n",
    "            \"avg_val_rcc_training_accuracy\": avg_val_rcc_training_accuracy\n",
    "        }\n",
    "\n",
    "    # DONE\n",
    "    def calculate_and_print_epoch_stats_hook(self, avg_train_stats, avg_val_stats):\n",
    "        epoch_loss = avg_train_stats[\"avg_training_loss\"]\n",
    "        epoch_ae_loss = avg_train_stats[\"avg_ae_loss\"]\n",
    "        epoch_ucc_loss = avg_train_stats[\"avg_ucc_loss\"]\n",
    "        epoch_rcc_loss = avg_train_stats[\"avg_rcc_loss\"]\n",
    "        epoch_ucc_accuracy = avg_train_stats[\"avg_ucc_training_accuracy\"]\n",
    "        epoch_rcc_accuracy = avg_train_stats[\"avg_rcc_training_accuracy\"]\n",
    "\n",
    "        epoch_val_loss = avg_val_stats[\"avg_val_loss\"]\n",
    "        epoch_val_ae_loss = avg_val_stats[\"avg_val_ae_loss\"]\n",
    "        epoch_val_ucc_loss = avg_val_stats[\"avg_val_ucc_loss\"]\n",
    "        epoch_val_rcc_loss = avg_val_stats[\"avg_val_rcc_loss\"]\n",
    "        epoch_val_ucc_accuracy = avg_val_stats[\"avg_val_ucc_training_accuracy\"]\n",
    "        epoch_val_rcc_accuracy = avg_val_stats[\"avg_val_rcc_training_accuracy\"]\n",
    "\n",
    "        print(\n",
    "            f\"[TRAIN]: Epoch Loss: {epoch_loss} | AE Loss: {epoch_ae_loss} | UCC Loss: {epoch_ucc_loss} | UCC Acc: {epoch_ucc_accuracy} | RCC Loss: {epoch_rcc_loss} | RCC Acc: {epoch_rcc_accuracy}\")\n",
    "        print(\n",
    "            f\"[VAL]: Val Loss: {epoch_val_loss} | Val AE Loss: {epoch_val_ae_loss} | Val UCC Loss: {epoch_val_ucc_loss} | Val UCC Acc: {epoch_val_ucc_accuracy} | Val RCC Loss: {epoch_val_rcc_loss} | Val RCC Acc: {epoch_val_rcc_accuracy}\")\n",
    "\n",
    "        return {\n",
    "            \"epoch_loss\": epoch_loss,\n",
    "            \"epoch_ae_loss\": epoch_ae_loss,\n",
    "            \"epoch_ucc_loss\": epoch_ucc_loss,\n",
    "            \"epoch_rcc_loss\": epoch_rcc_loss,\n",
    "            \"epoch_ucc_acc\": epoch_ucc_accuracy,\n",
    "            \"epoch_rcc_acc\": epoch_rcc_accuracy,\n",
    "            \"epoch_val_loss\": epoch_val_loss,\n",
    "            \"epoch_val_ae_loss\": epoch_val_ae_loss,\n",
    "            \"epoch_val_ucc_loss\": epoch_val_ucc_loss,\n",
    "            \"epoch_val_rcc_loss\": epoch_val_rcc_loss,\n",
    "            \"epoch_val_ucc_acc\": epoch_val_ucc_accuracy,\n",
    "            \"epoch_val_rcc_acc\": epoch_val_rcc_accuracy\n",
    "        }\n",
    "\n",
    "    # DONE\n",
    "    def store_running_history_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
    "        self.epoch_numbers.append(epoch + 1)\n",
    "\n",
    "        self.training_ae_losses.append(avg_train_stats[\"avg_ae_loss\"])\n",
    "        self.training_ucc_losses.append(avg_train_stats[\"avg_ucc_loss\"])\n",
    "        self.training_rcc_losses.append(avg_train_stats[\"avg_rcc_loss\"])\n",
    "        self.training_losses.append(avg_train_stats[\"avg_training_loss\"])\n",
    "        self.training_ucc_accuracies.append(avg_train_stats[\"avg_ucc_training_accuracy\"])\n",
    "        self.training_rcc_accuracies.append(avg_train_stats[\"avg_rcc_training_accuracy\"])\n",
    "\n",
    "        self.val_ae_losses.append(avg_val_stats[\"avg_val_ae_loss\"])\n",
    "        self.val_ucc_losses.append(avg_val_stats[\"avg_val_ucc_loss\"])\n",
    "        self.val_rcc_losses.append(avg_val_stats[\"avg_val_rcc_loss\"])\n",
    "        self.val_losses.append(avg_val_stats[\"avg_val_loss\"])\n",
    "        self.val_ucc_accuracies.append(avg_val_stats[\"avg_val_ucc_training_accuracy\"])\n",
    "        self.val_rcc_accuracies.append(avg_val_stats[\"avg_val_rcc_training_accuracy\"])\n",
    "\n",
    "    # DONE\n",
    "    def get_current_running_history_state_hook(self):\n",
    "        return self.epoch_numbers, \\\n",
    "            self.training_ae_losses, self.training_ucc_losses, self.training_rcc_losses, self.training_losses, self.training_ucc_accuracies, self.training_rcc_accuracies, \\\n",
    "            self.val_ae_losses, self.val_ucc_losses, self.val_rcc_losses, self.val_losses, self.val_ucc_accuracies, self.val_rcc_accuracies\n",
    "\n",
    "    # DONE\n",
    "    def save_model_checkpoint_hook(self, epoch):\n",
    "        # set it to train mode to save the weights (but doesn't matter apparently!)\n",
    "        self.autoencoder_model.train()\n",
    "        self.ucc_predictor_model.train()\n",
    "        self.rcc_predictor_model.train()\n",
    "\n",
    "        # create the directory if it doesn't exist\n",
    "        model_save_directory = os.path.join(self.save_dir, self.name)\n",
    "        os.makedirs(model_save_directory, exist_ok=True)\n",
    "\n",
    "        # Checkpoint the model at the end of each epoch\n",
    "        checkpoint_path = os.path.join(model_save_directory, f'model_epoch_{epoch + 1}.pt')\n",
    "        torch.save(\n",
    "            {\n",
    "                'ae_model_state_dict': self.autoencoder_model.state_dict(),\n",
    "                'ucc_model_state_dict': self.ucc_predictor_model.state_dict(),\n",
    "                'rcc_model_state_dict': self.rcc_predictor_model.state_dict(),\n",
    "                'ae_optimizer_state_dict': self.ae_optimizer.state_dict(),\n",
    "                'ucc_optimizer_state_dict': self.ucc_optimizer.state_dict(),\n",
    "                'rcc_optimizer_state_dict': self.rcc_optimizer.state_dict(),\n",
    "                'epoch': epoch + 1,\n",
    "                'epoch_numbers': self.epoch_numbers,\n",
    "                'training_losses': self.training_losses,\n",
    "                'training_ae_losses': self.training_ae_losses,\n",
    "                'training_ucc_losses': self.training_ucc_losses,\n",
    "                'training_rcc_losses': self.training_rcc_losses,\n",
    "                'training_ucc_accuracies': self.training_ucc_accuracies,\n",
    "                'training_rcc_accuracies': self.training_rcc_accuracies,\n",
    "                'val_losses': self.val_losses,\n",
    "                'val_ae_losses': self.val_ae_losses,\n",
    "                'val_ucc_losses': self.val_ucc_losses,\n",
    "                'val_rcc_losses': self.val_rcc_losses,\n",
    "                'val_ucc_accuracies': self.val_ucc_accuracies,\n",
    "                'val_rcc_accuracies': self.val_rcc_accuracies\n",
    "            },\n",
    "            checkpoint_path\n",
    "        )\n",
    "        print(f\"Saved the model checkpoint for experiment {self.name} for epoch {epoch + 1}\")\n",
    "\n",
    "    # DONE\n",
    "    # find the most recent file and return the path\n",
    "    def get_model_checkpoint_path(self, epoch_num=None):\n",
    "        directory = os.path.join(self.save_dir, self.name)\n",
    "        if epoch_num == None:\n",
    "            # Get a list of all files in the directory\n",
    "            files = os.listdir(directory)\n",
    "\n",
    "            # Filter out only the files (exclude directories)\n",
    "            files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "            # Sort the files by their modification time in descending order (most recent first)\n",
    "            files.sort(key=lambda x: os.path.getmtime(os.path.join(directory, x)), reverse=True)\n",
    "\n",
    "            # Get the name of the most recently added file\n",
    "            model_file = files[0] if files else None\n",
    "        else:\n",
    "            model_file = f\"model_epoch_{epoch_num}.pt\"\n",
    "        return os.path.join(directory, model_file)\n",
    "\n",
    "    # DONE\n",
    "    def show_sample_reconstructions(self, dataloader):\n",
    "        self.autoencoder_model.eval()\n",
    "\n",
    "        # Create a subplot grid\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(9, 9))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_data in dataloader:\n",
    "                val_images, _, _ = val_data\n",
    "\n",
    "                batch_size, bag_size, num_channels, height, width = val_images.size()\n",
    "                bag_val_images = val_images.view(batch_size * bag_size, num_channels, height, width)\n",
    "\n",
    "                # Forward pass through the model\n",
    "                _, _, val_reconstructed_images = self.forward_propagate_autoencoder(val_images)\n",
    "\n",
    "                # take only one image from the bag\n",
    "                sample_image = bag_val_images[0]\n",
    "                predicted_image = val_reconstructed_images[0]\n",
    "\n",
    "                # get it to cpu\n",
    "                sample_image = sample_image.to(\"cpu\")\n",
    "                predicted_image = predicted_image.to(\"cpu\")\n",
    "\n",
    "                # convert to PIL Image\n",
    "                sample_image = self.tensor_to_img_transform(sample_image)\n",
    "                predicted_image = self.tensor_to_img_transform(predicted_image)\n",
    "\n",
    "                axes[0].imshow(sample_image)\n",
    "                axes[0].set_title(f\"Sample Original Image\", color='green')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                axes[1].imshow(predicted_image)\n",
    "                axes[1].set_title(f\"Sample Reconstructed Image\", color='red')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # show only one image\n",
    "                break\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def test_model(self):\n",
    "        # class level init\n",
    "        self.eval_ucc_correct_predictions = 0\n",
    "        self.eval_ucc_total_batches = 0\n",
    "\n",
    "        self.eval_rcc_correct_predictions = 0\n",
    "        self.eval_rcc_total_batches = 0\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_ae_loss = 0.0\n",
    "        test_ucc_loss = 0.0\n",
    "        test_rcc_loss = 0.0\n",
    "\n",
    "        # set all models to eval mode\n",
    "        self.autoencoder_model.eval()\n",
    "        self.ucc_predictor_model.eval()\n",
    "        self.rcc_predictor_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_batch_idx, test_data in enumerate(self.test_loader):\n",
    "                test_images, test_one_hot_ucc_labels, test_rcc_labels = test_data\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                test_batch_ae_loss, test_encoded, test_decoded = self.forward_propagate_autoencoder(test_images)\n",
    "                test_batch_ucc_loss, test_batch_ucc_accuracy = self.forward_propogate_ucc(test_encoded,\n",
    "                                                                                        test_one_hot_ucc_labels, False)\n",
    "                test_batch_rcc_loss, test_batch_rcc_accuracy = self.forward_propogate_rcc(test_encoded, test_rcc_labels,\n",
    "                                                                                        False)\n",
    "\n",
    "                # calculate combined loss\n",
    "                test_batch_loss = test_batch_ae_loss + test_batch_ucc_loss + test_batch_rcc_loss\n",
    "\n",
    "                # cummulate the losses\n",
    "                test_loss += test_batch_loss\n",
    "                test_ae_loss += test_batch_ae_loss\n",
    "                test_ucc_loss += test_batch_ucc_loss\n",
    "                test_rcc_loss += test_batch_rcc_loss\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_test_loss = test_loss / len(self.test_loader)\n",
    "        avg_test_ucc_loss = test_ucc_loss / len(self.test_loader)\n",
    "        avg_test_rcc_loss = test_rcc_loss / len(self.test_loader)\n",
    "        avg_test_ae_loss = test_ae_loss / len(self.test_loader)\n",
    "        avg_test_ucc_training_accuracy = self.eval_ucc_correct_predictions / self.eval_ucc_total_batches\n",
    "        avg_test_rcc_training_accuracy = self.eval_rcc_correct_predictions / self.eval_rcc_total_batches\n",
    "\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.test_loader)\n",
    "\n",
    "        return {\n",
    "            \"avg_test_loss\": avg_test_loss,\n",
    "            \"avg_test_ae_loss\": avg_test_ae_loss,\n",
    "            \"avg_test_ucc_loss\": avg_test_ucc_loss,\n",
    "            \"avg_test_rcc_loss\": avg_test_rcc_loss,\n",
    "            \"avg_test_ucc_training_accuracy\": avg_test_ucc_training_accuracy,\n",
    "            \"avg_test_rcc_training_accuracy\": avg_test_rcc_training_accuracy\n",
    "        }\n",
    "\n",
    "    # DONE\n",
    "    def js_divergence(self, p, q):\n",
    "        \"\"\"\n",
    "        Calculate the Jensen-Shannon Divergence between two probability distributions p and q.\n",
    "\n",
    "        Args:\n",
    "        p (torch.Tensor): Probability distribution p.\n",
    "        q (torch.Tensor): Probability distribution q.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Jensen-Shannon Divergence between p and q.\n",
    "        \"\"\"\n",
    "        # Calculate the average distribution 'm'\n",
    "        m = 0.5 * (p + q)\n",
    "\n",
    "        # Calculate the KL Divergence of 'p' and 'q' from 'm'\n",
    "        kl_div_p = F.kl_div(p.log(), m, reduction='batchmean')\n",
    "        kl_div_q = F.kl_div(q.log(), m, reduction='batchmean')\n",
    "\n",
    "        # Compute the JS Divergence\n",
    "        js_divergence = 0.5 * (kl_div_p + kl_div_q)\n",
    "\n",
    "        return js_divergence\n",
    "\n",
    "    # DONE\n",
    "    def calculate_min_js_divergence(self):\n",
    "        num_classes = len(self.kde_loaders)\n",
    "        kde_per_class = {class_idx: 0.0 for class_idx in range(num_classes)}\n",
    "\n",
    "        # find the average kde across all classes\n",
    "        for class_idx, pure_class_kde_loader in tqdm(enumerate(self.kde_loaders)):\n",
    "            num_imgs_in_class = 0\n",
    "            for batch_idx, images in tqdm(enumerate(pure_class_kde_loader)):\n",
    "                # batch data is of shape ( Batch,bag, 3,32,32)\n",
    "                batch_size, bag_size, num_channels, height, width = images.size()\n",
    "                # reshaping to shape ( batch * bag, 3 ,32,32)\n",
    "                batches_of_bag_images = images.view(batch_size * bag_size, num_channels, height, width)\n",
    "                latent_features = self.autoencoder_model.encoder(batches_of_bag_images)  # shape (Batch * bag, 48*16)\n",
    "                batch_kde_distributions = self.ucc_predictor_model.kde(latent_features)  # shape [Batch=2, 8448]\n",
    "                num_imgs_in_class += batch_kde_distributions.size(0)\n",
    "                kde_distributions = torch.sum(batch_kde_distributions, dim=0)\n",
    "                kde_per_class[class_idx] += kde_distributions\n",
    "            kde_per_class[class_idx] /= num_imgs_in_class\n",
    "\n",
    "        # find the js_divergence\n",
    "        min_divergence = torch.inf\n",
    "        best_i = None\n",
    "        best_j = None\n",
    "        for i in range(num_classes):\n",
    "            for j in range(i + 1, num_classes):\n",
    "                divergence = self.js_divergence(kde_per_class[i], kde_per_class[j])\n",
    "                print(f\"JS Divergence between {i} & {j} is {divergence}\")\n",
    "                if divergence < min_divergence:\n",
    "                    min_divergence = divergence\n",
    "                    best_i = i\n",
    "                    best_j = j\n",
    "\n",
    "        print(f\"Min JS Divergence is {min_divergence} between classes {best_i} & {best_j}\")\n",
    "        # return the min divergence\n",
    "        return min_divergence\n",
    "\n",
    "    # DONE\n",
    "    def calculate_clustering_accuracy(self):\n",
    "        all_latent_features = []\n",
    "        truth_labels_arr = []\n",
    "        for pure_autoencoder_loader in self.autoencoder_loaders:\n",
    "            for batch_idx, data in tqdm(enumerate(pure_autoencoder_loader)):\n",
    "                # batch data is of shape (1,3,32,32), (1,1)\n",
    "                image, label = data\n",
    "                latent_features = self.autoencoder_model.encoder(image)  # shape (1, 48*16)\n",
    "\n",
    "                latent_features = latent_features.squeeze().numpy()  # ndarray shape (48*16)\n",
    "                label = label.squeeze().numpy()  # ndarray shape (1)\n",
    "\n",
    "                all_latent_features.append(latent_features)\n",
    "                truth_labels_arr.append(label)\n",
    "\n",
    "        all_latent_features = np.array(all_latent_features)\n",
    "\n",
    "        # Do kmeans fit\n",
    "        estimator = KMeans(n_clusters=10, init='k-means++', n_init=10)\n",
    "        estimator.fit(all_latent_features)\n",
    "        predicted_clustering_labels = estimator.labels_\n",
    "\n",
    "        # Calculate accuracy\n",
    "        cost_matrix = np.zeros((10, 10))\n",
    "        num_samples = np.zeros(10)\n",
    "        for truth_val in range(10):\n",
    "            temp_sample_indices = np.where(truth_labels_arr == truth_val)[0]\n",
    "            num_samples[truth_val] = temp_sample_indices.shape[0]\n",
    "\n",
    "            temp_predicted_labels = predicted_clustering_labels[temp_sample_indices]\n",
    "\n",
    "            for predicted_val in range(10):\n",
    "                temp_matching_pairs = np.where(temp_predicted_labels == predicted_val)[0]\n",
    "                cost_matrix[truth_val, predicted_val] = 1 - (\n",
    "                        temp_matching_pairs.shape[0] / temp_sample_indices.shape[0])\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        cost = cost_matrix[row_ind, col_ind]\n",
    "\n",
    "        clustering_acc = ((1 - cost) * num_samples).sum() / num_samples.sum()\n",
    "        return clustering_acc"
   ],
   "metadata": {
    "id": "fyosBGrM1iQW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the model instances\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vtnCmz6Y1iQY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment2 = \"ucc-rcc\"\n",
    "save_dir = os.path.abspath(config.weights_path)\n",
    "autoencoder_ucc_model = Autoencoder().to(config.device)\n",
    "ucc_predictor_model = UCCPredictor().to(config.device)\n",
    "rcc_predictor_model = RCCPredictor().to(config.device)\n",
    "\n",
    "#creating the trainer\n",
    "rcc_trainer = RCCTrainer(experiment2, autoencoder_ucc_model, ucc_predictor_model, rcc_predictor_model, dataset, save_dir)"
   ],
   "metadata": {
    "id": "1VobbyYn1iQY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3ZjbJHB61iQZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp2_epoch_numbers, exp2_training_ae_losses, exp2_training_ucc_losses, exp2_training_rcc_losses, exp2_training_losses, exp2_training_ucc_accuracies, exp2_training_rcc_accuracies, exp2_val_ae_losses, exp2_val_ucc_losses, exp2_val_rcc_losses, exp2_val_losses, exp2_val_ucc_accuracies, exp2_val_rcc_accuracies = rcc_trainer.train(1, epoch_saver_count=1)"
   ],
   "metadata": {
    "id": "B2k4aa5v1iQZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Training if required\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PpCLCRve1iQZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # exp2_epoch_numbers, exp2_training_ae_losses, exp2_training_ucc_losses, exp2_training_rcc_losses, exp2_training_losses, exp2_training_ucc_accuracies, exp2_training_rcc_accuracies, exp2_val_ae_losses, exp2_val_ucc_losses, exp2_val_rcc_losses, exp2_val_losses, exp2_val_ucc_accuracies, exp2_val_rcc_accuracies = rcc_trainer.train(10, epoch_saver_count=2, load_from_checkpoint=True, resume_epoch_num=42)"
   ],
   "metadata": {
    "id": "lN6stZ2x1iQZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "XwEObp691iQa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ucc_rcc_model_stats(experiment2, exp2_epoch_numbers, exp2_training_ucc_losses, exp2_training_ae_losses,\n",
    "                         exp2_training_rcc_losses, exp2_training_losses, exp2_training_ucc_accuracies,\n",
    "                         exp2_training_rcc_accuracies, exp2_val_ucc_losses, exp2_val_ae_losses, exp2_val_rcc_losses,\n",
    "                         exp2_val_losses, exp2_val_ucc_accuracies, exp2_val_rcc_accuracies)"
   ],
   "metadata": {
    "id": "8ZFwzwkE1iQa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1Kqi2erW1iQa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcc_trainer.test_model()"
   ],
   "metadata": {
    "id": "nQrtBRq41iQa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Min JS Divergence"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OqhXkxer1iQb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp2_min_js_divg = rcc_trainer.calculate_min_js_divergence()\n",
    "exp2_min_js_divg"
   ],
   "metadata": {
    "id": "hLRgUp5l1iQb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Clustering Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wUdKjdXm1iQb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp2_clustering_accuracies = rcc_trainer.calculate_clustering_accuracy()\n",
    "exp2_clustering_accuracies"
   ],
   "metadata": {
    "id": "Il2gbub21iQb"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b0a3428cbfab4922ba5a5819651bff65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45b9899987b0457697b98094691fe533",
       "IPY_MODEL_38811dd740724070bdee0edf35dc4adc",
       "IPY_MODEL_1e1ef139001343bb9f3c1418cfb46c93"
      ],
      "layout": "IPY_MODEL_4139665d030c4587b6eef55fd176443c"
     }
    },
    "45b9899987b0457697b98094691fe533": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fa71b74e950444baee1d7bab67f31c3",
      "placeholder": "​",
      "style": "IPY_MODEL_216fbc7e6cb747bc90d4cfe5157d4ebf",
      "value": ""
     }
    },
    "38811dd740724070bdee0edf35dc4adc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c322c79438b438e8cd4e949ee407530",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7342b7067b2541ae97ab185fb9b9cac1",
      "value": 1
     }
    },
    "1e1ef139001343bb9f3c1418cfb46c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd8c90fab7a14cf18b3dbcd4cea03f25",
      "placeholder": "​",
      "style": "IPY_MODEL_6b39ef7bfc0a4aa18d4e58f939d88124",
      "value": " 10/? [00:00&lt;00:00, 32.98it/s]"
     }
    },
    "4139665d030c4587b6eef55fd176443c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa71b74e950444baee1d7bab67f31c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "216fbc7e6cb747bc90d4cfe5157d4ebf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c322c79438b438e8cd4e949ee407530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7342b7067b2541ae97ab185fb9b9cac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd8c90fab7a14cf18b3dbcd4cea03f25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b39ef7bfc0a4aa18d4e58f939d88124": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ed3aa79907e41749053fc6a2d8c7878": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcde7ada4c7c4a83aacc5ff2633c20f2",
       "IPY_MODEL_58e4b6572b2644198c451ec4eb339dc2",
       "IPY_MODEL_d51b939bfd3d47798ca0ee3dce139d30"
      ],
      "layout": "IPY_MODEL_aadef4806a674d14834012356ca7f06d"
     }
    },
    "fcde7ada4c7c4a83aacc5ff2633c20f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da3b9b86c6294344b2099b907710153b",
      "placeholder": "​",
      "style": "IPY_MODEL_13f4f2dabdf2481da33d584e3c5fcbb9",
      "value": "100%"
     }
    },
    "58e4b6572b2644198c451ec4eb339dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a557936305f646ab8a0e61d3f47900ef",
      "max": 4000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb44fe378f99457ab7eb7854761fb19e",
      "value": 4000
     }
    },
    "d51b939bfd3d47798ca0ee3dce139d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db45c5e4a7e74f1eb6ea5387a15871d8",
      "placeholder": "​",
      "style": "IPY_MODEL_aad32bd7d0d1449caba3abacc701d81b",
      "value": " 4000/4000 [00:14&lt;00:00, 262.76it/s]"
     }
    },
    "aadef4806a674d14834012356ca7f06d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da3b9b86c6294344b2099b907710153b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13f4f2dabdf2481da33d584e3c5fcbb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a557936305f646ab8a0e61d3f47900ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb44fe378f99457ab7eb7854761fb19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db45c5e4a7e74f1eb6ea5387a15871d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aad32bd7d0d1449caba3abacc701d81b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6e2fa49e88d4c5993992632c6e4ed1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d69537adda54076a03c9acea74fb497",
       "IPY_MODEL_9ea7f77f3dfa4793a4f9da35fd3df7b5",
       "IPY_MODEL_d1859a99cc364d6cb41a89178d427f8f"
      ],
      "layout": "IPY_MODEL_98bcbffae02c401ebe1782629d146c65"
     }
    },
    "7d69537adda54076a03c9acea74fb497": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73f99b4b27ba4ddc89727b936c08ee3b",
      "placeholder": "​",
      "style": "IPY_MODEL_db92fa9c53d641528ee879774213400d",
      "value": "100%"
     }
    },
    "9ea7f77f3dfa4793a4f9da35fd3df7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dccbad301c0a40729a2077ef3abed5f2",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fd55dc0b97242baa14d76bcf3dc10a7",
      "value": 1000
     }
    },
    "d1859a99cc364d6cb41a89178d427f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64d4b51a25314baf8b3954e5d5ce2108",
      "placeholder": "​",
      "style": "IPY_MODEL_47fd830936af4604af5e63fd8bc6059a",
      "value": " 1000/1000 [00:00&lt;00:00, 2841.89it/s]"
     }
    },
    "98bcbffae02c401ebe1782629d146c65": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f99b4b27ba4ddc89727b936c08ee3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db92fa9c53d641528ee879774213400d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dccbad301c0a40729a2077ef3abed5f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fd55dc0b97242baa14d76bcf3dc10a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64d4b51a25314baf8b3954e5d5ce2108": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47fd830936af4604af5e63fd8bc6059a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f27428f6a839491992eebe2c46ec7a87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc6780cdfd0441db880a6a10ab95b5e4",
       "IPY_MODEL_9e973ee8841d433cad9a92448ac161e5",
       "IPY_MODEL_a4a987db4ec349a89da43f5b41d9d49e"
      ],
      "layout": "IPY_MODEL_97523dd1039f498b9804022d64055993"
     }
    },
    "fc6780cdfd0441db880a6a10ab95b5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce1de4909d9140188ffc8e451d9e7a87",
      "placeholder": "​",
      "style": "IPY_MODEL_e8220451de4443bca4fd44acbd4c4cb7",
      "value": "100%"
     }
    },
    "9e973ee8841d433cad9a92448ac161e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e274322b2d9048bea857a5e4ba634820",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_220b871f5a364b24bbd16a7d058a8c7e",
      "value": 1000
     }
    },
    "a4a987db4ec349a89da43f5b41d9d49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7de9f94413d4978bf718d1c7a355e75",
      "placeholder": "​",
      "style": "IPY_MODEL_d3ebeecef2a44cfdb8113a5f9bf2e3d2",
      "value": " 1000/1000 [00:00&lt;00:00, 3057.75it/s]"
     }
    },
    "97523dd1039f498b9804022d64055993": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce1de4909d9140188ffc8e451d9e7a87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8220451de4443bca4fd44acbd4c4cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e274322b2d9048bea857a5e4ba634820": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "220b871f5a364b24bbd16a7d058a8c7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7de9f94413d4978bf718d1c7a355e75": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3ebeecef2a44cfdb8113a5f9bf2e3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fc2ce4bba644c9ba75fd83b8bcdf781": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_badd6cd298104eebab15f7e5d915b323",
       "IPY_MODEL_bfda78f7eb924c198a7c89298310f0fa",
       "IPY_MODEL_e79c4cdb6aae4cf48712e542f96735e1"
      ],
      "layout": "IPY_MODEL_dbfe9b827823418c96bad872edd6dcef"
     }
    },
    "badd6cd298104eebab15f7e5d915b323": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa2724e5cb274e1ba27c2f4eea804b0c",
      "placeholder": "​",
      "style": "IPY_MODEL_bf59694ff0ad4ea9bc70f38565f9f3ae",
      "value": "100%"
     }
    },
    "bfda78f7eb924c198a7c89298310f0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0a892ad718b4eabaf944ae14b535e28",
      "max": 4000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7f5634e049e4c80bd47a8da7ce0b4a7",
      "value": 4000
     }
    },
    "e79c4cdb6aae4cf48712e542f96735e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_102e3115507142fb870b0c4f51af43b2",
      "placeholder": "​",
      "style": "IPY_MODEL_4f2dbb3c20ee409fa70a00a6dcc14a86",
      "value": " 4000/4000 [00:13&lt;00:00, 235.40it/s]"
     }
    },
    "dbfe9b827823418c96bad872edd6dcef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa2724e5cb274e1ba27c2f4eea804b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf59694ff0ad4ea9bc70f38565f9f3ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0a892ad718b4eabaf944ae14b535e28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7f5634e049e4c80bd47a8da7ce0b4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "102e3115507142fb870b0c4f51af43b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f2dbb3c20ee409fa70a00a6dcc14a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0562a595ba36497f968988c4f30007cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0257652b341d4b6b92f5e413c2f01737",
       "IPY_MODEL_44b36e153d44450f8c9289f23d540c58",
       "IPY_MODEL_524f59f623e94391bc4d1ec2f858d4f8"
      ],
      "layout": "IPY_MODEL_eca6b1c065604ced9c3d847afa286065"
     }
    },
    "0257652b341d4b6b92f5e413c2f01737": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1b21338c4174675bb4bcbaa30639afd",
      "placeholder": "​",
      "style": "IPY_MODEL_48a7c73005b243aa8f859772ef6c699d",
      "value": "100%"
     }
    },
    "44b36e153d44450f8c9289f23d540c58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daf98be49204424ab8a76db200535a63",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d18b7cd3f994b6b8c365f67a6b6e33f",
      "value": 1000
     }
    },
    "524f59f623e94391bc4d1ec2f858d4f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8721e904f0a44d2085b0a7f5753223e0",
      "placeholder": "​",
      "style": "IPY_MODEL_f10e12bfde6a4273a9abf00b79135751",
      "value": " 1000/1000 [00:00&lt;00:00, 2575.54it/s]"
     }
    },
    "eca6b1c065604ced9c3d847afa286065": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b21338c4174675bb4bcbaa30639afd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48a7c73005b243aa8f859772ef6c699d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daf98be49204424ab8a76db200535a63": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d18b7cd3f994b6b8c365f67a6b6e33f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8721e904f0a44d2085b0a7f5753223e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10e12bfde6a4273a9abf00b79135751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa05d1c7781c4bb6b7083cebc02d9070": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0473b48309db4fb6885d59673fec2ce0",
       "IPY_MODEL_d885c01d564d40bb8018857a5e7ff238",
       "IPY_MODEL_20e7741c0a704bc7a4d1042a886f50af"
      ],
      "layout": "IPY_MODEL_24d75655e37a40b7b5ba1676142adc0d"
     }
    },
    "0473b48309db4fb6885d59673fec2ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e7ae96813ce4601b8a051cce09448e2",
      "placeholder": "​",
      "style": "IPY_MODEL_34f094d5d63340a685ec4bb33bdd68f0",
      "value": "100%"
     }
    },
    "d885c01d564d40bb8018857a5e7ff238": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e667bfa596249d2925be3d7d12f4c65",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_412a26eae95f47189196ad2482ea7f1a",
      "value": 1000
     }
    },
    "20e7741c0a704bc7a4d1042a886f50af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dfb53d9dd194832be055e5918503592",
      "placeholder": "​",
      "style": "IPY_MODEL_c84bbf1170ab4bd68f34058e94fa8a95",
      "value": " 1000/1000 [00:00&lt;00:00, 2587.12it/s]"
     }
    },
    "24d75655e37a40b7b5ba1676142adc0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e7ae96813ce4601b8a051cce09448e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34f094d5d63340a685ec4bb33bdd68f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e667bfa596249d2925be3d7d12f4c65": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "412a26eae95f47189196ad2482ea7f1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6dfb53d9dd194832be055e5918503592": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c84bbf1170ab4bd68f34058e94fa8a95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e019bd261274eb889e12a6bb803980d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df9c0ae2b09746f78a992e73f382d46a",
       "IPY_MODEL_7c14752a41c74babaee2f3b760d87952",
       "IPY_MODEL_5bd551ff08954c95b31b654d8c741d63"
      ],
      "layout": "IPY_MODEL_078c903c16594b1e800c5f921255fa08"
     }
    },
    "df9c0ae2b09746f78a992e73f382d46a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59398352661e4b1587cc3a6a3db5943c",
      "placeholder": "​",
      "style": "IPY_MODEL_8e8e378b32d647ef838c4cb6427142b9",
      "value": "Total Epochs: 0.0% "
     }
    },
    "7c14752a41c74babaee2f3b760d87952": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f0300a87dee4820a74e31a748394c46",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4f7aaf438284532a00e9f6332b3b87b",
      "value": 0
     }
    },
    "5bd551ff08954c95b31b654d8c741d63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e109cc3b98e14e849f5464b5fc855ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_b46466bcecd24d89a33497be7c1aaa02",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "078c903c16594b1e800c5f921255fa08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "59398352661e4b1587cc3a6a3db5943c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e8e378b32d647ef838c4cb6427142b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f0300a87dee4820a74e31a748394c46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4f7aaf438284532a00e9f6332b3b87b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "red",
      "description_width": ""
     }
    },
    "e109cc3b98e14e849f5464b5fc855ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b46466bcecd24d89a33497be7c1aaa02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ff1edef82854a08af9b0b671cab1582": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3ac8abffcbd43e1ae49cbddd6cc8782",
       "IPY_MODEL_f7c70ff1bd4a475a92d34df099e89f22",
       "IPY_MODEL_83dbc2ae508147f3b38005bcc5a90c59"
      ],
      "layout": "IPY_MODEL_b0735fb89e274ab681caaa38006316c3"
     }
    },
    "a3ac8abffcbd43e1ae49cbddd6cc8782": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54ab6b76da194e0595828bf1e6ea2d0d",
      "placeholder": "​",
      "style": "IPY_MODEL_d9d78c8f00f942ac9397fa879e45ae30",
      "value": "Epoch 1/1:   0%"
     }
    },
    "f7c70ff1bd4a475a92d34df099e89f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc4933629e7141ecb0e5471bc96619cc",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5d6c9dfc393428087c79064f0b68306",
      "value": 0
     }
    },
    "83dbc2ae508147f3b38005bcc5a90c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e45ceb9b1f54c2e81300214c5791195",
      "placeholder": "​",
      "style": "IPY_MODEL_ffdc49f364ce4d6a9ec43d119f51ea9a",
      "value": " 0/2000 [00:00&lt;?, ?it/s]"
     }
    },
    "b0735fb89e274ab681caaa38006316c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "54ab6b76da194e0595828bf1e6ea2d0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d78c8f00f942ac9397fa879e45ae30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc4933629e7141ecb0e5471bc96619cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d6c9dfc393428087c79064f0b68306": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "green",
      "description_width": ""
     }
    },
    "7e45ceb9b1f54c2e81300214c5791195": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffdc49f364ce4d6a9ec43d119f51ea9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
