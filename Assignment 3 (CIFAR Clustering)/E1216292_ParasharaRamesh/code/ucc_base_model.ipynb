{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installing python modules used later on"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SlpsuqkV1iPk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Uncomment if training on google colab!\n",
    "\n",
    "!pip install pytorch_msssim\n",
    "!pip install torchinfo"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhfdu7AB1iPq",
    "outputId": "cfd3006f-bf55-4e1a-ac34-c11856e9e73e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mount Google Drive"
   ],
   "metadata": {
    "collapsed": false,
    "id": "aPdt08JV1iPt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Uncomment if training on google colab!\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUtNUuoA1iPu",
    "outputId": "7e9a1873-f401-4f62-b923-6fc3dcc54e52"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing relevant things"
   ],
   "metadata": {
    "collapsed": false,
    "id": "MSXaxVQa1iPu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kDt34Hh61iPv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from itertools import combinations\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset, ConcatDataset, Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from pytorch_msssim import SSIM\n",
    "import random\n",
    "from torchvision.models import ResNeXt50_32X4D_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config params"
   ],
   "metadata": {
    "collapsed": false,
    "id": "30WA5eST1iPw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # for local\n",
    "    # datasets_path = f\"../Dataset/splitted_cifar10_dataset.npz\"\n",
    "    # weights_path = f\"../weights\"\n",
    "\n",
    "    drive_path = \"/content/drive/MyDrive\"\n",
    "    datasets_path = f\"{drive_path}/splitted_cifar10_dataset.npz\"\n",
    "    weights_path = f\"{drive_path}/weights\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    sigma = 0.1\n",
    "    num_nodes = 11\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "    grad_clip = 1\n",
    "\n",
    "    batch_size = 20\n",
    "    ucc_limit = 4\n",
    "    rcc_limit = 10\n",
    "    bag_size = 36\n",
    "    num_classes = 10\n",
    "\n",
    "    train_steps = 100000\n",
    "    test_steps = 1000\n",
    "    val_steps = 100\n",
    "    debug_steps = 1000\n",
    "    saver_steps = 2000\n",
    "\n",
    "\n",
    "config = Config()"
   ],
   "metadata": {
    "id": "xjKkRwyL1iPw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Au0yZcaw1iPx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "splitted_dataset = np.load(config.datasets_path)\n",
    "\n",
    "x_train = splitted_dataset['x_train']\n",
    "print(f\"x_train shape :{x_train.shape}\")\n",
    "\n",
    "y_train = splitted_dataset['y_train']\n",
    "print(f\"y_train shape :{y_train.shape}\")\n",
    "\n",
    "x_val = splitted_dataset['x_val']\n",
    "print(f\"x_val shape :{x_val.shape}\")\n",
    "\n",
    "y_val = splitted_dataset['y_val']\n",
    "print(f\"y_val shape :{y_val.shape}\")\n",
    "\n",
    "x_test = splitted_dataset['x_test']\n",
    "print(f\"x_test shape :{x_test.shape}\")\n",
    "\n",
    "y_test = splitted_dataset['y_test']\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt12NdvB1iPx",
    "outputId": "48c596ea-003d-4f25-e004-ad42a4a388e8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Dataloader\n",
    "\n",
    "This dataloader moves data directly to the device when yielding data"
   ],
   "metadata": {
    "collapsed": false,
    "id": "xbz27xgV1iP1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Wrapper on top of dataloader to move tensors to device\n",
    "'''\n",
    "class DeviceDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            yield self._move_to_device(batch)\n",
    "\n",
    "    def _move_to_device(self, batch):\n",
    "        if isinstance(batch, torch.Tensor):\n",
    "            return batch.to(self.device)\n",
    "        elif isinstance(batch, (list, tuple)):\n",
    "            return [self._move_to_device(item) for item in batch]\n",
    "        elif isinstance(batch, dict):\n",
    "            return {key: self._move_to_device(value) for key, value in batch.items()}\n",
    "        else:\n",
    "            return batch\n"
   ],
   "metadata": {
    "id": "aZ3q0u8X1iP2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SL4Quij91iP2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CIFARDataset(Dataset):\n",
    "    def __init__(self, x, y, num_iter, train_mode):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.num_iter = num_iter\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "        self.num_classes = config.num_classes\n",
    "\n",
    "        # for each class get all the indexes of images\n",
    "        self.class_label_to_img_idxs = self.get_class_label_to_img_idxs_dict()\n",
    "\n",
    "        # pick the augmentation based on the mode\n",
    "        if self.train_mode:\n",
    "            self.transforms = [\n",
    "                # normal\n",
    "                transforms.Compose([\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random horizontal flips\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random rotations\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomRotation(3),\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random rotations & flips\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomRotation(3),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "            ]\n",
    "        else:\n",
    "            self.transforms = [\n",
    "                transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                ])\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iter * config.batch_size\n",
    "\n",
    "    def get_img_from_idx(self, index):\n",
    "        img = self.x[index]\n",
    "        img = Image.fromarray(img)\n",
    "        random_transform = random.choice(self.transforms)\n",
    "        return random_transform(img)\n",
    "\n",
    "    def get_label_from_idx(self, index):\n",
    "        return self.y[index][0]\n",
    "\n",
    "    def get_class_label_to_img_idxs_dict(self):\n",
    "        class_label_to_img_idxs_dict = dict()\n",
    "        for label in range(self.num_classes):\n",
    "            img_idxs = np.where(self.y == label)[0]\n",
    "            class_label_to_img_idxs_dict[label] = img_idxs\n",
    "\n",
    "        return class_label_to_img_idxs_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = index % self.num_classes\n",
    "        label_img_idxs = self.class_label_to_img_idxs[label]\n",
    "        random_idx = random.choice(label_img_idxs)\n",
    "        return self.get_img_from_idx(random_idx), self.get_label_from_idx(random_idx)\n"
   ],
   "metadata": {
    "id": "N_6_zQada_TB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UCCDataset(Dataset):\n",
    "    def __init__(self, x, y, num_iter, train_mode):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.num_iter = num_iter\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "        self.bag_size = config.bag_size\n",
    "        self.num_classes = config.num_classes\n",
    "        self.ucc_limit = config.ucc_limit\n",
    "\n",
    "        # pick the augmentation based on the mode\n",
    "        if self.train_mode:\n",
    "            self.transforms = [\n",
    "                # normal\n",
    "                transforms.Compose([\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random horizontal flips\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random rotations\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomRotation(3),\n",
    "                    transforms.ToTensor()\n",
    "                ]),\n",
    "                # random rotations & flips\n",
    "                transforms.Compose([\n",
    "                    transforms.RandomRotation(3),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "            ]\n",
    "        else:\n",
    "            self.transforms = [\n",
    "                transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                ])\n",
    "            ]\n",
    "\n",
    "        # for each class get all the indexes of images\n",
    "        self.class_label_to_img_idxs = self.get_class_label_to_img_idxs_dict()\n",
    "\n",
    "        # for each ucc class from (1->4) get all the unique combinations possible\n",
    "        self.ucc_to_all_combos = self.get_ucc_to_all_combinations_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iter * config.batch_size\n",
    "\n",
    "    def get_class_label_to_img_idxs_dict(self):\n",
    "        class_label_to_img_idxs_dict = dict()\n",
    "        for label_value in range(self.num_classes):\n",
    "            label_key = f\"class{label_value}\"\n",
    "\n",
    "            img_idxs = np.where(self.y == label_value)[0]\n",
    "            class_label_to_img_idxs_dict[label_key] = img_idxs\n",
    "\n",
    "        return class_label_to_img_idxs_dict\n",
    "\n",
    "    def get_ucc_to_all_combinations_dict(self):\n",
    "        class_labels = np.arange(self.num_classes)\n",
    "        ucc_to_all_combos_dict = dict()\n",
    "\n",
    "        for ucc in range(self.ucc_limit):  # go from 1->4\n",
    "            ucc_key = f\"ucc{ucc}\"\n",
    "\n",
    "            ucc_bag_labels = list()\n",
    "            for unique_ucc_combo in combinations(class_labels, ucc+1): #plus 1 here\n",
    "                ucc_bag_labels.append(np.array(unique_ucc_combo))\n",
    "\n",
    "            ucc_to_all_combos_dict[ucc_key] = np.array(ucc_bag_labels)\n",
    "\n",
    "        return ucc_to_all_combos_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ucc_label = index % self.ucc_limit\n",
    "        ucc_combo_with_bag_counts = self.get_random_ucc_combo_and_its_bag_counts(ucc_label)\n",
    "\n",
    "        selected_idxs = []\n",
    "        for label, freq in ucc_combo_with_bag_counts:\n",
    "            label_key = f\"class{label}\"\n",
    "            label_img_idxs = self.class_label_to_img_idxs[label_key]\n",
    "            selected_idxs.extend(list(label_img_idxs[np.random.randint(0, len(label_img_idxs), size=freq)]))\n",
    "\n",
    "        imgs = self.get_imgs_from_idxs(selected_idxs)\n",
    "        return imgs, ucc_label\n",
    "\n",
    "    def get_random_ucc_combo_and_its_bag_counts(self, ucc_label):\n",
    "        class_key = f\"ucc{ucc_label}\"\n",
    "\n",
    "        # Get unique combination of cifar10 labels for ucc label\n",
    "        ucc_bag_labels_list = self.ucc_to_all_combos[class_key]\n",
    "        idx = np.random.randint(0, ucc_bag_labels_list.shape[0])\n",
    "        ucc_labels = ucc_bag_labels_list[idx, :]\n",
    "\n",
    "        # Get even distribution of instances per label with max difference of 1\n",
    "        N = ucc_labels.shape[0]\n",
    "        n_instances = self.bag_size // N\n",
    "\n",
    "        counts = np.repeat(n_instances, N)\n",
    "\n",
    "        res = []\n",
    "        for label, freq in zip(ucc_labels, counts):\n",
    "            res.append((label, freq))\n",
    "        return res\n",
    "\n",
    "    def get_imgs_from_idxs(self, idxs):\n",
    "        imgs = self.x[idxs]\n",
    "        res = []\n",
    "        for i in range(len(imgs)):\n",
    "            img = Image.fromarray(imgs[i])\n",
    "            random_transform = random.choice(self.transforms)\n",
    "            res.append(random_transform(img).unsqueeze(0))\n",
    "        res = torch.concatenate(res, dim=0)\n",
    "        return res\n"
   ],
   "metadata": {
    "id": "JkfzExFo1iP3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the Dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zh4SdAvF1iP5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Dataloaders:\n",
    "    def __init__(self):\n",
    "        data = np.load(config.datasets_path)\n",
    "        x_train, y_train = data[\"x_train\"], data[\"y_train\"]\n",
    "        x_val, y_val = data[\"x_val\"], data[\"y_val\"]\n",
    "        x_test, y_test = data[\"x_test\"], data[\"y_test\"]\n",
    "\n",
    "        #construct ucc datasets\n",
    "        self.ucc_train_dataset = UCCDataset(x_train, y_train, config.train_steps, True)\n",
    "        self.ucc_val_dataset = UCCDataset(x_val, y_val, config.val_steps, False)\n",
    "        self.ucc_test_dataset = UCCDataset(x_test, y_test, config.test_steps, False)\n",
    "\n",
    "        #construct cifar datasets\n",
    "        self.cifar_train_dataset = CIFARDataset(x_train, y_train, config.train_steps, True)\n",
    "        self.cifar_val_dataset = CIFARDataset(x_val, y_val, config.val_steps, False)\n",
    "        self.cifar_test_dataset = CIFARDataset(x_test, y_test, config.test_steps, False)\n",
    "\n",
    "        #delete the extra unnecessary space\n",
    "        del data\n",
    "        del x_train\n",
    "        del x_test\n",
    "        del x_val\n",
    "        del y_train\n",
    "        del y_test\n",
    "        del y_val\n",
    "\n",
    "    def get_ucc_dataloaders(self):\n",
    "        train_loader = DeviceDataLoader(self.ucc_train_dataset, config.batch_size)\n",
    "        val_loader = DeviceDataLoader(self.ucc_val_dataset, config.batch_size)\n",
    "        test_loader = DeviceDataLoader(self.ucc_test_dataset, config.batch_size)\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def get_cifar_dataloaders(self):\n",
    "        train_loader = DeviceDataLoader(self.cifar_train_dataset, config.batch_size)\n",
    "        val_loader = DeviceDataLoader(self.cifar_val_dataset, config.batch_size)\n",
    "        test_loader = DeviceDataLoader(self.cifar_test_dataset, config.batch_size)\n",
    "        return train_loader, val_loader, test_loader\n"
   ],
   "metadata": {
    "id": "vOLdLabva_TC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloaders = Dataloaders()"
   ],
   "metadata": {
    "id": "Vhk3aDMf1iP6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking how one bag looks like"
   ],
   "metadata": {
    "collapsed": false,
    "id": "D7ynGZWxht_P"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#printing the images in a bag\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tensor_to_img_transform = transforms.ToPILImage()\n",
    "ucc_train_loader, ucc_val_loader, ucc_test_loader = dataloaders.get_ucc_dataloaders()\n",
    "ucc_dataloaders = [ucc_train_loader, ucc_val_loader, ucc_test_loader]\n",
    "names = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for ucc_dataloader, name in zip(ucc_dataloaders, names):\n",
    "    print(f\"Checking out {name}\")\n",
    "    for data in ucc_dataloader:\n",
    "        batches, _ = data\n",
    "        for bag in batches:\n",
    "            for image_index, image in enumerate(bag):\n",
    "                image = tensor_to_img_transform(image)\n",
    "                plt.subplot(4, 6, image_index + 1)  # Assuming 24 images per bag\n",
    "                plt.imshow(image)  # Display the image\n",
    "                plt.title(f\"Bag {image_index + 1}\")  # Set the title\n",
    "                plt.axis('off')  # Turn off axis labels\n",
    "            plt.show()\n",
    "            break\n",
    "        break\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aLNJYxByht_P",
    "outputId": "b5f782dc-0bb7-4bb8-edc5-45bcee8e182a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SSIM Loss definition"
   ],
   "metadata": {
    "collapsed": false,
    "id": "A1oDEUBr1iQV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.ssim = SSIM()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Calculate SSIM\n",
    "        ssim_value = self.ssim(x, y)\n",
    "        # Subtract SSIM from 1\n",
    "        loss = 1 - ssim_value\n",
    "        return loss"
   ],
   "metadata": {
    "id": "6l9rTIPl1iQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model architectures"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Mfu4D_oAht_P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "id": "t6ZcYlA8ht_P"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResidualZeroPaddingBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            first_block=False,\n",
    "            down_sample=False,\n",
    "            up_sample=False,\n",
    "    ):\n",
    "        super(ResidualZeroPaddingBlock, self).__init__()\n",
    "        self.first_block = first_block\n",
    "        self.down_sample = down_sample\n",
    "        self.up_sample = up_sample\n",
    "\n",
    "        if self.up_sample:\n",
    "            self.upsampling = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=2 if self.down_sample else 1,\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.skip_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=2 if self.down_sample else 1,\n",
    "        )\n",
    "\n",
    "        # Initialize the weights and biases\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        nn.init.constant_(self.conv1.bias, 0.1)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        nn.init.constant_(self.conv2.bias, 0.1)\n",
    "        nn.init.xavier_uniform_(self.skip_conv.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.first_block:\n",
    "            x = nn.LeakyReLU()(x)\n",
    "            if self.up_sample:\n",
    "                x = self.upsampling(x)\n",
    "            out = nn.LeakyReLU()(self.conv1(x))\n",
    "            out = self.conv2(out)\n",
    "            if x.shape != out.shape:\n",
    "                x = self.skip_conv(x)\n",
    "        else:\n",
    "            out = nn.LeakyReLU()(self.conv1(x))\n",
    "            out = nn.LeakyReLU()(self.conv2(out))\n",
    "        return x + out\n",
    "\n",
    "class WideResidualBlocks(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, out_channels, n, down_sample=False, up_sample=False\n",
    "    ):\n",
    "        super(WideResidualBlocks, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[\n",
    "                ResidualZeroPaddingBlock(\n",
    "                    in_channels if i == 0 else out_channels,\n",
    "                    out_channels,\n",
    "                    first_block=(i == 0),\n",
    "                    down_sample=down_sample,\n",
    "                    up_sample=up_sample,\n",
    "                )\n",
    "                for i in range(n)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *target_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.target_shape)\n",
    "\n",
    "class PretrainedAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pretrained_model = models.resnext50_32x4d(weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1).to(config.device)\n",
    "        self.pretrained_encoder = nn.Sequential(*list(pretrained_model.children())[:-1]).to(config.device)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 32, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        ).to(config.device)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 256),\n",
    "            Reshape(*[256, 1, 1]),\n",
    "            WideResidualBlocks(\n",
    "                256,\n",
    "                256,\n",
    "                1,\n",
    "                up_sample=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            WideResidualBlocks(\n",
    "                256,\n",
    "                128,\n",
    "                1,\n",
    "                up_sample=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            WideResidualBlocks(\n",
    "                128,\n",
    "                64,\n",
    "                1,\n",
    "                up_sample=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            WideResidualBlocks(\n",
    "                64,\n",
    "                32,\n",
    "                1,\n",
    "                up_sample=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            WideResidualBlocks(\n",
    "                32,\n",
    "                16,\n",
    "                1,\n",
    "                up_sample=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            WideResidualBlocks(\n",
    "                16,\n",
    "                8,\n",
    "                1\n",
    "            ),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(\n",
    "                8,\n",
    "                3,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "        ).to(config.device)\n",
    "\n",
    "        ## Freeze all the parameters\n",
    "        # for param in self.pretrained_encoder.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        pretrained_features = self.pretrained_encoder(x)\n",
    "        features = self.encoder(pretrained_features).to(config.device)\n",
    "        reconstruction = self.decoder(features)\n",
    "        return features, reconstruction"
   ],
   "metadata": {
    "id": "3Rg0ZO1rht_P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kernel Density Estimator"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wUH15pTxht_P"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class KDE(nn.Module):\n",
    "    def __init__(self, device=config.device, num_nodes=config.num_nodes, sigma=config.sigma):\n",
    "        super(KDE, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.sigma = sigma\n",
    "        self.device = device\n",
    "        print(\"KDE Layer initialized\")\n",
    "\n",
    "    def forward(self, data):\n",
    "        batch_size, num_instances, num_features = data.shape\n",
    "\n",
    "        # Create sample points\n",
    "        k_sample_points = (\n",
    "            torch.linspace(0, 1, steps=config.num_nodes)\n",
    "            .repeat(batch_size, num_instances, 1)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        # Calculate constants\n",
    "        k_alpha = 1 / np.sqrt(2 * np.pi * config.sigma ** 2)\n",
    "        k_beta = -1 / (2 * config.sigma ** 2)\n",
    "\n",
    "        # Iterate over features and calculate kernel density estimation for each feature\n",
    "        out_list = []\n",
    "        for i in range(num_features):\n",
    "            one_feature = data[:, :, i: i + 1].repeat(1, 1, config.num_nodes)\n",
    "            k_diff_2 = (k_sample_points - one_feature) ** 2\n",
    "            k_result = k_alpha * torch.exp(k_beta * k_diff_2)\n",
    "            k_out_unnormalized = k_result.sum(dim=1)\n",
    "            k_norm_coeff = k_out_unnormalized.sum(dim=1).view(-1, 1)\n",
    "            k_out = k_out_unnormalized / k_norm_coeff.repeat(\n",
    "                1, k_out_unnormalized.size(1)\n",
    "            )\n",
    "            out_list.append(k_out)\n",
    "\n",
    "        # Concatenate the results\n",
    "        concat_out = torch.cat(out_list, dim=-1).to(self.device)\n",
    "        return concat_out\n"
   ],
   "metadata": {
    "id": "kmp9V314ht_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UCC Prediction model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eBlKTOODht_Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# UCC model\n",
    "class UCCModel(nn.Module):\n",
    "    def __init__(self, device=config.device, autoencoder_model=None, ucc_limit=config.ucc_limit):\n",
    "        super().__init__()\n",
    "        if autoencoder_model:\n",
    "            self.autoencoder = autoencoder_model\n",
    "        else:\n",
    "            self.autoencoder = PretrainedAutoencoder()\n",
    "\n",
    "        self.kde = KDE(device)\n",
    "        self.ucc_predictor = nn.Sequential(\n",
    "            nn.Linear(352, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, ucc_limit)\n",
    "        )\n",
    "\n",
    "        print(\"UCC model initialized\")\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Input size: [batch, bag, 3, 32, 32]\n",
    "        # output size: [batch, 4] (ucc_logits), [batch * bag,3,32,32] ( decoded images)\n",
    "\n",
    "        # Stage 1. pass through autoencoder\n",
    "        batch_size, bag_size, num_channels, height, width = batch.size()\n",
    "        batches_of_image_bags = batch.view(batch_size * bag_size, num_channels, height, width).to(torch.float32)\n",
    "        features, decoded = self.autoencoder(\n",
    "            batches_of_image_bags\n",
    "        )  # we are feeding in Batch*bag images of shape (3,32,32)\n",
    "\n",
    "        # Stage 2. use the autoencoder latent features to pass through the ucc predictor\n",
    "        # features shape is now (Batch* Bag, 128) -> (Batch, Bag, 128)\n",
    "        features = features.view(batch_size, bag_size, features.size(1))\n",
    "\n",
    "        # Stage 3. pass through kde to get output shape (Batch, 128*11)\n",
    "        kde_prob_distributions = self.kde(features)\n",
    "\n",
    "        # Stage 4. pass through the ucc_predictor stack to get 4 logits in the end\n",
    "        ucc_logits = self.ucc_predictor(kde_prob_distributions)\n",
    "\n",
    "        return ucc_logits, decoded  # (Batch , 4), (Batch * Bag, 3,32,32)\n",
    "\n",
    "    def get_encoder_features(self, batch):\n",
    "        batch_size, bag_size, num_channels, height, width = batch.size()\n",
    "        batches_of_image_bags = batch.view(batch_size * bag_size, num_channels, height, width).to(torch.float32)\n",
    "        features, _ = self.autoencoder(\n",
    "            batches_of_image_bags\n",
    "        )  # we are feeding in Batch*bag images of shape (3,32,32)\n",
    "        return features\n",
    "\n",
    "    def get_kde_distributions(self, batch):\n",
    "        batch_size, bag_size, num_channels, height, width = batch.size()\n",
    "        batches_of_image_bags = batch.view(batch_size * bag_size, num_channels, height, width).to(torch.float32)\n",
    "        features, _ = self.autoencoder(\n",
    "            batches_of_image_bags\n",
    "        )  # we are feeding in Batch*bag images of shape (3,32,32)\n",
    "        features = features.view(batch_size, bag_size, features.size(1))\n",
    "\n",
    "        kde_prob_distributions = self.kde(features)\n",
    "        return kde_prob_distributions"
   ],
   "metadata": {
    "id": "2sMaUa7Ght_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UCC model trainable params"
   ],
   "metadata": {
    "collapsed": false,
    "id": "X2scQbfga_TD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ucc = UCCModel(config.device).to(config.device)\n",
    "summary(ucc, input_size=(config.bag_size, 3, 32, 32), device=config.device, batch_dim=0, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"], verbose=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHDxwkhfa_TD",
    "outputId": "c6c3ae7f-e6ca-4b03-fc4a-f854434db588"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXPERIMENT-1 : UCC Model\n",
    "\n",
    "This model tries to replicate the paper where we have an autoencoder path and a ucc path.\n",
    "\n",
    "Similarly experiment-2 will be the improvement model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qbzZGx0sht_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code for plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "hoEAbLjGht_Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_ucc_model_stats(\n",
    "        experiment, ucc_training_losses, ae_training_losses, combined_training_losses,\n",
    "        ucc_training_accuracy,\n",
    "        ucc_validation_losses, ae_validation_losses, combined_validation_losses,\n",
    "        ucc_validation_accuracy\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "    #reassigning epochs\n",
    "    steps = [1000 * (i + 1) for i in range(len(ucc_training_losses))]\n",
    "\n",
    "    # Plot training losses\n",
    "    axes[0, 0].plot(steps, ucc_training_losses, marker=\"o\", color=\"red\", label=\"UCC Training Loss\")\n",
    "    axes[0, 0].plot(steps, ae_training_losses, marker=\"o\", color=\"blue\", label=\"AE Training Loss\")\n",
    "    axes[0, 0].plot(steps, combined_training_losses, marker=\"o\", color=\"green\", label=\"Combined Training Loss\")\n",
    "    axes[0, 0].set_title(f'{experiment}: Training Loss vs Epochs')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Training Loss')\n",
    "    axes[0, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot training accuracy\n",
    "    axes[0, 1].plot(steps, ucc_training_accuracy, marker=\"o\", color=\"red\", label=\"UCC Training Accuracy\")\n",
    "    axes[0, 1].set_title(f'{experiment}: Training Accuracy vs Epochs')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Training Accuracy')\n",
    "    axes[0, 1].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation losses\n",
    "    axes[1, 0].plot(steps, ucc_validation_losses, marker=\"o\", color=\"red\", label=\"UCC Validation Loss\")\n",
    "    axes[1, 0].plot(steps, ae_validation_losses, marker=\"o\", color=\"blue\", label=\"AE Validation Loss\")\n",
    "    axes[1, 0].plot(steps, combined_validation_losses, marker=\"o\", color=\"green\", label=\"Combined Validation Loss\")\n",
    "    axes[1, 0].set_title(f'{experiment}: Validation Loss vs Epochs')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Validation Loss')\n",
    "    axes[1, 0].legend()  # Display the legend\n",
    "\n",
    "    # Plot validation accuracy 1,1\n",
    "    axes[1, 1].plot(steps, ucc_validation_accuracy, marker=\"o\", color=\"red\", label=\"UCC Validation Accuracy\")\n",
    "    axes[1, 1].set_title(f'{experiment}: Validation Accuracy vs Epochs')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Validation Accuracy')\n",
    "    axes[1, 1].legend()  # Display the legend\n",
    "\n",
    "    # Add space between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # close it properly\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ],
   "metadata": {
    "id": "IR0_ZMTAht_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UCC Trainer class"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Vj5p3PhHht_Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UCCTrainer:\n",
    "    def __init__(self,\n",
    "                 name, ucc_model,\n",
    "                 dataloader, save_dir, device=config.device,\n",
    "                 importances={\"ae\": 0.5, \"ucc\": 0.5},\n",
    "                 use_ssim=False\n",
    "                 ):\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "        self.device = device\n",
    "\n",
    "        # importances\n",
    "        self.ae_importance = importances[\"ae\"]\n",
    "        self.ucc_importance = importances[\"ucc\"]\n",
    "\n",
    "        # dataloaders\n",
    "        self.train_loader, self.val_loader, self.test_loader = dataloader.get_ucc_dataloaders()\n",
    "        self.cifar_train_loader, self.cifar_val_loader, self.cifar_test_loader = dataloader.get_cifar_dataloaders()\n",
    "\n",
    "        # create the directory if it doesn't exist!\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.save_dir, self.name), exist_ok=True)\n",
    "\n",
    "        self.ucc_model = ucc_model\n",
    "\n",
    "        # Adam optimizer(s)\n",
    "        self.ucc_optimizer = optim.Adam(self.ucc_model.parameters(), lr=config.learning_rate,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "\n",
    "        # Loss criterion(s)\n",
    "        self.ae_loss_criterion = SSIMLoss() if use_ssim else nn.MSELoss()\n",
    "        self.ucc_loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Transforms\n",
    "        self.tensor_to_img_transform = transforms.ToPILImage()\n",
    "\n",
    "        # Values which can change based on loaded checkpoint\n",
    "        self.steps = []\n",
    "        self.training_ae_losses = []\n",
    "        self.training_ucc_losses = []\n",
    "        self.training_losses = []\n",
    "        self.training_ucc_accuracies = []\n",
    "\n",
    "        self.val_ae_losses = []\n",
    "        self.val_ucc_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_ucc_accuracies = []\n",
    "\n",
    "        self.train_correct_predictions = 0\n",
    "        self.train_total_batches = 0\n",
    "\n",
    "        # Debug saver lists (i.e. capture these stats for every debug_steps)\n",
    "        self.debug_ae_losses = []\n",
    "        self.debug_ucc_losses = []\n",
    "        self.debug_total_losses = []\n",
    "\n",
    "    # main train code\n",
    "    def train(self,\n",
    "              resume_steps=None,\n",
    "              load_from_checkpoint=False,\n",
    "              saver_steps=config.saver_steps):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # initialize the params from the saved checkpoint\n",
    "        self.init_params_from_checkpoint_hook(load_from_checkpoint, resume_steps)\n",
    "\n",
    "        # set up scheduler\n",
    "        self.init_scheduler_hook()\n",
    "\n",
    "        # Custom progress bar for each epoch with color\n",
    "        batch_progress_bar = tqdm(\n",
    "            total=len(self.train_loader),\n",
    "            desc=f\"Steps\",\n",
    "            position=1,\n",
    "            leave=False,\n",
    "            dynamic_ncols=True,\n",
    "            ncols=100,\n",
    "            colour='green'\n",
    "        )\n",
    "\n",
    "        # set all models to train mode\n",
    "        self.ucc_model.train()\n",
    "\n",
    "        # iterate over each batch\n",
    "        for step, data in enumerate(self.train_loader):\n",
    "            # zero grad\n",
    "            self.ucc_optimizer.zero_grad()\n",
    "\n",
    "            images, ucc_labels = data\n",
    "\n",
    "            # forward propogate through the combined model\n",
    "            ucc_logits, decoded = self.ucc_model(images)\n",
    "\n",
    "            # calculate losses from both models for a batch of bags\n",
    "            ae_loss = self.calculate_autoencoder_loss(images, decoded)\n",
    "            ucc_loss, batch_ucc_accuracy = self.calculate_ucc_loss_and_acc(ucc_logits, ucc_labels, True)\n",
    "\n",
    "            # calculate combined loss\n",
    "            step_loss = (self.ae_importance * ae_loss) + (self.ucc_importance * ucc_loss)\n",
    "\n",
    "            # do loss backward for all losses\n",
    "            step_loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(self.ucc_model.parameters(), max_norm=config.grad_clip)\n",
    "\n",
    "            # do optimizer step\n",
    "            self.ucc_optimizer.step()\n",
    "\n",
    "            # scheduler update (remove if it doesnt work!)\n",
    "            self.ucc_scheduler.step()\n",
    "\n",
    "            # add to epoch batch_loss\n",
    "            self.debug_ae_losses.append(ae_loss.item())\n",
    "            self.debug_ucc_losses.append(ucc_loss.item())\n",
    "            self.debug_total_losses.append(step_loss.item())\n",
    "\n",
    "            # Update the epoch progress bar (overwrite in place)\n",
    "            batch_stats = {\n",
    "                \"batch_loss\": step_loss.item(),\n",
    "                \"batch_ae_loss\": ae_loss.item(),\n",
    "                \"batch_ucc_loss\": ucc_loss.item(),\n",
    "                \"batch_ucc_acc\": batch_ucc_accuracy\n",
    "            }\n",
    "\n",
    "            batch_progress_bar.set_postfix(batch_stats)\n",
    "            batch_progress_bar.update(1)\n",
    "\n",
    "            # Compute the average stats for every config.debug_steps steps\n",
    "            if (step + 1) % config.debug_steps == 0:\n",
    "                # calculate average epoch train statistics\n",
    "                avg_train_stats = self.calculate_avg_train_stats_hook()\n",
    "\n",
    "                # calculate validation statistics\n",
    "                avg_val_stats = self.validation_hook()\n",
    "\n",
    "                # Store running history\n",
    "                self.print_stats_and_store_running_history_hook(step + 1, avg_train_stats, avg_val_stats)\n",
    "\n",
    "                # Clear the list\n",
    "                self.debug_ae_losses = []\n",
    "                self.debug_ucc_losses = []\n",
    "                self.debug_total_losses = []\n",
    "\n",
    "            # Save model checkpoint periodically\n",
    "            if (step + 1) % saver_steps == 0:\n",
    "                print(f\"Going to save model {self.name} @ Step:{step + 1}\")\n",
    "                self.save_model_checkpoint_hook(step + 1)\n",
    "\n",
    "        # close the epoch progress bar\n",
    "        batch_progress_bar.close()\n",
    "\n",
    "        #save final model\n",
    "        print(f\"Going to save final model {self.name} @ Step: {step + 1}\")\n",
    "        self.save_model_checkpoint_hook(step + 1)\n",
    "\n",
    "        # Return the current state\n",
    "        return self.get_current_running_history_state_hook()\n",
    "\n",
    "    # hooks\n",
    "    def init_params_from_checkpoint_hook(self, load_from_checkpoint, resume_steps):\n",
    "        if load_from_checkpoint:\n",
    "            # NOTE: resume_epoch_num can be None here if we want to load from the most recently saved checkpoint!\n",
    "            checkpoint_path = self.get_model_checkpoint_path(resume_steps)\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "            # load previous state of models\n",
    "            self.ucc_model.load_state_dict(checkpoint['ucc_model_state_dict'])\n",
    "\n",
    "            # load previous state of optimizers\n",
    "            self.ucc_optimizer.load_state_dict(checkpoint['ucc_optimizer_state_dict'])\n",
    "\n",
    "            # Things we are keeping track of\n",
    "            self.steps = checkpoint['steps']\n",
    "\n",
    "            self.training_losses = checkpoint['training_losses']\n",
    "            self.training_ae_losses = checkpoint['training_ae_losses']\n",
    "            self.training_ucc_losses = checkpoint['training_ucc_losses']\n",
    "            self.training_ucc_accuracies = checkpoint['training_ucc_accuracies']\n",
    "\n",
    "            self.val_losses = checkpoint['val_losses']\n",
    "            self.val_ae_losses = checkpoint['val_ae_losses']\n",
    "            self.val_ucc_losses = checkpoint['val_ucc_losses']\n",
    "            self.val_ucc_accuracies = checkpoint['val_ucc_accuracies']\n",
    "\n",
    "            print(f\"Model checkpoint for {self.name} is loaded from {checkpoint_path}!\")\n",
    "\n",
    "    def init_scheduler_hook(self):\n",
    "        self.ucc_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.ucc_optimizer,\n",
    "            config.learning_rate,\n",
    "            total_steps=len(self.train_loader)\n",
    "        )\n",
    "\n",
    "    def calculate_autoencoder_loss(self, images, decoded):\n",
    "        # data is of shape (batchsize=2,bag=10,channels=3,height=32,width=32)\n",
    "        # generally batch size of 16 is good for cifar10 so predicting 20 won't be so bad\n",
    "        batch_size, bag_size, num_channels, height, width = images.size()\n",
    "        batches_of_bag_images = images.view(batch_size * bag_size, num_channels, height, width).to(torch.float32)\n",
    "        ae_loss = self.ae_loss_criterion(decoded, batches_of_bag_images)  # compares (Batch * Bag, 3,32,32)\n",
    "        return ae_loss\n",
    "\n",
    "    def calculate_ucc_loss_and_acc(self, ucc_logits, ucc_labels, is_train_mode=True):\n",
    "        # compute the batch stats right here and save it\n",
    "        ucc_probs = nn.Softmax(dim=1)(ucc_logits)\n",
    "        predicted = torch.argmax(ucc_probs, 1)  # adding one so that it can be match properly\n",
    "        batch_correct_predictions = (predicted == ucc_labels).sum().item()\n",
    "        batch_size = ucc_labels.size(0)\n",
    "        batch_ucc_accuracy = batch_correct_predictions / batch_size\n",
    "\n",
    "        # compute the ucc_loss between [batch, 4], [Batch,] batch size = 2\n",
    "        ucc_loss = self.ucc_loss_criterion(ucc_logits, ucc_labels)\n",
    "\n",
    "        # calculate batchwise accuracy/ucc_loss\n",
    "        if is_train_mode:\n",
    "            self.train_correct_predictions += batch_correct_predictions\n",
    "            self.train_total_batches += batch_size\n",
    "        else:\n",
    "            self.eval_correct_predictions += batch_correct_predictions\n",
    "            self.eval_total_batches += batch_size\n",
    "        return ucc_loss, batch_ucc_accuracy\n",
    "\n",
    "    def calculate_avg_train_stats_hook(self):\n",
    "        avg_ae_loss_for_epoch = np.mean(np.array(self.debug_ae_losses))\n",
    "        avg_ucc_loss_for_epoch = np.mean(np.array(self.debug_ucc_losses))\n",
    "        avg_training_loss_for_epoch = np.mean(np.array(self.debug_total_losses))\n",
    "        avg_ucc_training_accuracy = self.train_correct_predictions / self.train_total_batches\n",
    "\n",
    "        epoch_train_stats = {\n",
    "            \"avg_training_loss\": avg_training_loss_for_epoch,\n",
    "            \"avg_ae_loss\": avg_ae_loss_for_epoch,\n",
    "            \"avg_ucc_loss\": avg_ucc_loss_for_epoch,\n",
    "            \"avg_ucc_training_accuracy\": avg_ucc_training_accuracy\n",
    "        }\n",
    "\n",
    "        # reset\n",
    "        self.train_correct_predictions = 0\n",
    "        self.train_total_batches = 0\n",
    "\n",
    "        return epoch_train_stats\n",
    "\n",
    "    def validation_hook(self):\n",
    "        # class level init\n",
    "        self.eval_correct_predictions = 0\n",
    "        self.eval_total_batches = 0\n",
    "\n",
    "        val_loss = []\n",
    "        val_ae_loss = []\n",
    "        val_ucc_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # set all models to eval mode\n",
    "            self.ucc_model.eval()\n",
    "\n",
    "            for val_batch_idx, val_data in enumerate(self.val_loader):\n",
    "                val_images, val_ucc_labels = val_data\n",
    "\n",
    "                # forward propogate through the model\n",
    "                val_ucc_logits, val_decoded = self.ucc_model(val_images)\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                val_batch_ae_loss = self.calculate_autoencoder_loss(val_images, val_decoded)\n",
    "                val_batch_ucc_loss, val_batch_ucc_accuracy = self.calculate_ucc_loss_and_acc(val_ucc_logits,\n",
    "                                                                                             val_ucc_labels, False)\n",
    "                # calculate combined loss\n",
    "                val_batch_loss = (self.ae_importance * val_batch_ae_loss) + (self.ucc_importance * val_batch_ucc_loss)\n",
    "\n",
    "                # cummulate the losses\n",
    "                val_ae_loss.append(val_batch_ae_loss.item())\n",
    "                val_ucc_loss.append(val_batch_ucc_loss.item())\n",
    "                val_loss.append(val_batch_loss.item())\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = np.mean(np.array(val_loss))\n",
    "        avg_val_ucc_loss = np.mean(np.array(val_ucc_loss))\n",
    "        avg_val_ae_loss = np.mean(np.array(val_ae_loss))\n",
    "        avg_val_ucc_training_accuracy = self.eval_correct_predictions / self.eval_total_batches\n",
    "\n",
    "        stats = {\n",
    "            \"avg_val_loss\": avg_val_loss,\n",
    "            \"avg_val_ae_loss\": avg_val_ae_loss,\n",
    "            \"avg_val_ucc_loss\": avg_val_ucc_loss,\n",
    "            \"avg_val_ucc_training_accuracy\": avg_val_ucc_training_accuracy\n",
    "        }\n",
    "\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.val_loader)\n",
    "        return stats\n",
    "\n",
    "    def print_stats_and_store_running_history_hook(self, curr_step, avg_train_stats, avg_val_stats):\n",
    "        loss = avg_train_stats[\"avg_training_loss\"]\n",
    "        ae_loss = avg_train_stats[\"avg_ae_loss\"]\n",
    "        ucc_loss = avg_train_stats[\"avg_ucc_loss\"]\n",
    "        ucc_accuracy = avg_train_stats[\"avg_ucc_training_accuracy\"]\n",
    "\n",
    "        val_loss = avg_val_stats[\"avg_val_loss\"]\n",
    "        val_ae_loss = avg_val_stats[\"avg_val_ae_loss\"]\n",
    "        val_ucc_loss = avg_val_stats[\"avg_val_ucc_loss\"]\n",
    "        val_ucc_accuracy = avg_val_stats[\"avg_val_ucc_training_accuracy\"]\n",
    "\n",
    "        # store running history\n",
    "        self.steps.append(curr_step)\n",
    "        self.training_losses.append(loss)\n",
    "        self.training_ae_losses.append(ae_loss)\n",
    "        self.training_ucc_losses.append(ucc_loss)\n",
    "        self.training_ucc_accuracies.append(ucc_accuracy)\n",
    "\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_ae_losses.append(val_ae_loss)\n",
    "        self.val_ucc_losses.append(val_ucc_loss)\n",
    "        self.val_ucc_accuracies.append(val_ucc_accuracy)\n",
    "\n",
    "        # print stats\n",
    "        print(\n",
    "            f\"[TRAIN]:Step: {curr_step} | Loss: {loss} | AE Loss: {ae_loss} | UCC Loss: {ucc_loss} | UCC Acc: {ucc_accuracy}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"[VAL]:Step: {curr_step} | Val Loss: {val_loss} | Val AE Loss: {val_ae_loss} | Val UCC Loss: {val_ucc_loss} | Val UCC Acc: {val_ucc_accuracy}\"\n",
    "        )\n",
    "        print()\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    def get_current_running_history_state_hook(self):\n",
    "        return self.steps, \\\n",
    "            self.training_ae_losses, self.training_ucc_losses, self.training_losses, self.training_ucc_accuracies, \\\n",
    "            self.val_ae_losses, self.val_ucc_losses, self.val_losses, self.val_ucc_accuracies\n",
    "\n",
    "    def save_model_checkpoint_hook(self, step):\n",
    "        # set it to train mode to save the weights (but doesn't matter apparently!)\n",
    "        self.ucc_model.train()\n",
    "\n",
    "        # create the directory if it doesn't exist\n",
    "        model_save_directory = os.path.join(self.save_dir, self.name)\n",
    "        os.makedirs(model_save_directory, exist_ok=True)\n",
    "\n",
    "        # Checkpoint the model at the end of each epoch\n",
    "        checkpoint_path = os.path.join(model_save_directory, f'model_step_{step + 1}.pt')\n",
    "        torch.save(\n",
    "            {\n",
    "                'ucc_model_state_dict': self.ucc_model.state_dict(),\n",
    "                'ucc_optimizer_state_dict': self.ucc_optimizer.state_dict(),\n",
    "                'steps': self.steps,\n",
    "                'training_losses': self.training_losses,\n",
    "                'training_ae_losses': self.training_ae_losses,\n",
    "                'training_ucc_losses': self.training_ucc_losses,\n",
    "                'training_ucc_accuracies': self.training_ucc_accuracies,\n",
    "                'val_losses': self.val_losses,\n",
    "                'val_ae_losses': self.val_ae_losses,\n",
    "                'val_ucc_losses': self.val_ucc_losses,\n",
    "                'val_ucc_accuracies': self.val_ucc_accuracies,\n",
    "            },\n",
    "            checkpoint_path\n",
    "        )\n",
    "        print(f\"Saved the model checkpoint for experiment {self.name} for step {step + 1}\")\n",
    "\n",
    "    def test_model(self):\n",
    "        # class level init\n",
    "        self.eval_correct_predictions = 0\n",
    "        self.eval_total_batches = 0\n",
    "\n",
    "        test_loss = []\n",
    "        test_ae_loss = []\n",
    "        test_ucc_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # set all models to eval mode\n",
    "            self.ucc_model.eval()\n",
    "\n",
    "            for test_batch_idx, test_data in enumerate(self.test_loader):\n",
    "                test_images, test_ucc_labels = test_data\n",
    "\n",
    "                # forward propogate through the model\n",
    "                test_ucc_logits, test_decoded = self.ucc_model(test_images)\n",
    "\n",
    "                # calculate losses from both models for a batch of bags\n",
    "                test_batch_ae_loss = self.calculate_autoencoder_loss(test_images, test_decoded)\n",
    "                test_batch_ucc_loss, test_batch_ucc_accuracy = self.calculate_ucc_loss_and_acc(test_ucc_logits,\n",
    "                                                                                               test_ucc_labels,\n",
    "                                                                                               False)\n",
    "\n",
    "                # calculate combined loss\n",
    "                test_batch_loss = (self.ae_importance * test_batch_ae_loss) + (self.ucc_importance * test_batch_ucc_loss)\n",
    "\n",
    "                # cummulate the losses\n",
    "                test_ae_loss.append(test_batch_ae_loss.item())\n",
    "                test_ucc_loss.append(test_batch_ucc_loss.item())\n",
    "                test_loss.append(test_batch_loss.item())\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_test_loss = np.mean(np.array(test_loss))\n",
    "        avg_test_ucc_loss = np.mean(np.array(test_ucc_loss))\n",
    "        avg_test_ae_loss = np.mean(np.array(test_ae_loss))\n",
    "        avg_test_ucc_training_accuracy = self.eval_correct_predictions / self.eval_total_batches\n",
    "\n",
    "        stats = {\n",
    "            \"avg_test_loss\": avg_test_loss,\n",
    "            \"avg_test_ae_loss\": avg_test_ae_loss,\n",
    "            \"avg_test_ucc_loss\": avg_test_ucc_loss,\n",
    "            \"avg_test_ucc_training_accuracy\": avg_test_ucc_training_accuracy\n",
    "        }\n",
    "        # show some sample predictions\n",
    "        self.show_sample_reconstructions(self.test_loader)\n",
    "        return stats\n",
    "\n",
    "    def show_sample_reconstructions(self, dataloader):\n",
    "        # Create a subplot grid\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(3, 3))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # set all models to eval mode\n",
    "            self.ucc_model.eval()\n",
    "\n",
    "            for val_data in dataloader:\n",
    "                val_images, _ = val_data\n",
    "\n",
    "                # reshape to appropriate size\n",
    "                batch_size, bag_size, num_channels, height, width = val_images.size()\n",
    "                bag_val_images = val_images.view(batch_size * bag_size, num_channels, height, width)\n",
    "                print(\"Reshaped the original image into bag format\")\n",
    "\n",
    "                # forward propagate through the model\n",
    "                _, val_reconstructed_images = self.ucc_model(val_images)\n",
    "                print(\"Got a sample reconstruction, now trying to reshape in order to show an example\")\n",
    "\n",
    "                # take only one image from the bag\n",
    "                sample_image = bag_val_images[0]\n",
    "                predicted_image = val_reconstructed_images[0]\n",
    "\n",
    "                # get it to cpu\n",
    "                sample_image = sample_image.to(\"cpu\")\n",
    "                predicted_image = predicted_image.to(\"cpu\")\n",
    "\n",
    "                # convert to PIL Image\n",
    "                sample_image = self.tensor_to_img_transform(sample_image)\n",
    "                predicted_image = self.tensor_to_img_transform(predicted_image)\n",
    "\n",
    "                axes[0].imshow(sample_image)\n",
    "                axes[0].set_title(f\"Orig\", color='green')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                axes[1].imshow(predicted_image)\n",
    "                axes[1].set_title(f\"Recon\", color='red')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # show only one image\n",
    "                break\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # find the most recent file and return the path\n",
    "    def get_model_checkpoint_path(self, step_num=None):\n",
    "        directory = os.path.join(self.save_dir, self.name)\n",
    "        if step_num == None:\n",
    "            # Get a list of all files in the directory\n",
    "            files = os.listdir(directory)\n",
    "\n",
    "            # Filter out only the files (exclude directories)\n",
    "            files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "            # Sort the files by their modification time in descending order (most recent first)\n",
    "            files.sort(key=lambda x: os.path.getmtime(os.path.join(directory, x)), reverse=True)\n",
    "\n",
    "            # Get the name of the most recently added file\n",
    "            model_file = files[0] if files else None\n",
    "        else:\n",
    "            model_file = f\"model_step_{step_num}.pt\"\n",
    "        return os.path.join(directory, model_file)\n",
    "\n",
    "    # Calculate min JS Divergence\n",
    "    def calculate_js_divergence(self, p, q):\n",
    "        p = p/np.sum(p)\n",
    "        q = q/np.sum(q)\n",
    "        m = 0.5 * (p + q)\n",
    "        log_p_over_m = np.log2(p / m)\n",
    "        log_q_over_m = np.log2(q / m)\n",
    "        return 0.5 * np.sum(p * log_p_over_m) + 0.5 * np.sum(q * log_q_over_m)\n",
    "\n",
    "    def get_all_kde_distributions(self):\n",
    "        self.ucc_model.eval()\n",
    "\n",
    "        kde_distributions = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(self.cifar_test_loader):\n",
    "                imgs = imgs.unsqueeze(1).to(config.device)\n",
    "                kde_dist = self.ucc_model.get_kde_distributions(imgs)\n",
    "                kde_distributions.append(kde_dist.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        kde_distributions = np.concatenate(kde_distributions)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        return kde_distributions, all_labels\n",
    "\n",
    "    def compute_min_js_divergence(self):\n",
    "        kde_distributions, all_labels = self.get_all_kde_distributions()\n",
    "        print(\"Got the KDE distributions for the test dataset\")\n",
    "\n",
    "        # iterate for each class and get only those embeddings\n",
    "        distribution_of_all_label_classes = []\n",
    "        for i in range(config.num_classes):\n",
    "            idxs = np.where(all_labels == i)\n",
    "            kde_distribution_i = kde_distributions[idxs]\n",
    "            kde_distribution_i = np.mean(kde_distribution_i, axis=0)\n",
    "            distribution_of_all_label_classes.append(kde_distribution_i)\n",
    "        distribution_of_all_label_classes = np.array(distribution_of_all_label_classes)\n",
    "        print(\"Got the average kde distribution per label class, now computing min js divergence\")\n",
    "\n",
    "        res = np.zeros((config.num_classes, config.num_classes))\n",
    "        for i in range(config.num_classes):\n",
    "            p = np.clip(distribution_of_all_label_classes[i, :], 1e-12, 1)\n",
    "            # p = distribution_of_all_label_classes[i, :]\n",
    "            for j in range(i, config.num_classes):\n",
    "                q = np.clip(distribution_of_all_label_classes[j, :], 1e-12, 1)\n",
    "                # q = distribution_of_all_label_classes[j, :]\n",
    "\n",
    "                # fill the upper triangle\n",
    "                res[i, j] = self.calculate_js_divergence(p, q)\n",
    "\n",
    "                # fill the lower triangle\n",
    "                res[j, i] = res[i, j]\n",
    "\n",
    "        # we are not interested in the identity relation anyway\n",
    "        np.fill_diagonal(res, np.inf)\n",
    "        print(\"Computed all interclass js divergence scores, the entire interclass js divergence is \")\n",
    "        print(res)\n",
    "        # Find the minimum value\n",
    "        min_js_divergence = np.min(res)\n",
    "\n",
    "        # Find the indices of the minimum value\n",
    "        min_indices = np.argmin(res)\n",
    "        min_row, min_col = np.unravel_index(min_indices, res.shape)\n",
    "\n",
    "        print(f\"Min JS Divergence is {min_js_divergence}, between classes {min_row} & {min_col}\")\n",
    "        return min_js_divergence\n",
    "\n",
    "    # Calculate clustering accuracy\n",
    "    def get_all_encoder_features(self):\n",
    "        self.ucc_model.eval()\n",
    "\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(self.cifar_test_loader):\n",
    "                imgs = imgs.unsqueeze(1).to(config.device)\n",
    "                features = self.ucc_model.get_encoder_features(imgs)\n",
    "                all_features.append(features.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        all_features = np.concatenate(all_features)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        return all_features, all_labels\n",
    "\n",
    "    def perform_clustering_and_get_cluster_labels(self, features):\n",
    "        model = KMeans(n_clusters=10, init='k-means++', n_init=10)\n",
    "        model.fit(features)\n",
    "        return model.labels_\n",
    "\n",
    "    def compute_clustering_accuracy(self):\n",
    "        all_features, all_labels = self.get_all_encoder_features()\n",
    "        print(\"Computed all the features from the encoder\")\n",
    "        cluster_labels = self.perform_clustering_and_get_cluster_labels(all_features)\n",
    "        print(\"Performed clustering and computed all the cluster labels\")\n",
    "\n",
    "        cost_matrix = np.zeros((config.num_classes, config.num_classes))\n",
    "        num_samples = np.zeros(config.num_classes)\n",
    "\n",
    "        for true_label in range(config.num_classes):\n",
    "            true_label_idxs = np.where(all_labels == true_label)[0]\n",
    "            num_samples[true_label] = true_label_idxs.shape[0]\n",
    "\n",
    "            sample_preds = cluster_labels[true_label_idxs]\n",
    "\n",
    "            for pred_label in range(config.num_classes):\n",
    "                pairs = np.where(sample_preds == pred_label)[0]\n",
    "\n",
    "                cost_matrix[true_label, pred_label] = 1 - (pairs.shape[0] / true_label_idxs.shape[0])\n",
    "\n",
    "        print(\"Going to perform linear sum assignment of cost matrix\")\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        cost = cost_matrix[row_ind, col_ind]\n",
    "        clustering_acc = ((1 - cost) * num_samples).sum() / num_samples.sum()\n",
    "        print(f\"Clustering accuracy is {clustering_acc}\")\n",
    "        return clustering_acc\n"
   ],
   "metadata": {
    "id": "K372cEh9ht_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the model instances\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "tahh6ZQHht_Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment1 = \"ucc\"\n",
    "save_dir = os.path.abspath(config.weights_path)\n",
    "ucc_model = UCCModel(device=config.device).to(config.device)\n",
    "\n",
    "#creating the trainer\n",
    "ucc_trainer = UCCTrainer(experiment1, ucc_model, dataloaders, save_dir)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3Ubg9WCht_Q",
    "outputId": "38c4b456-44e6-4e95-e5f5-58f0b9eed8eb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GpvMO6SOht_R"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Going to start training..\")\n",
    "exp1_epoch_numbers, exp1_training_ae_losses, exp1_training_ucc_losses, exp1_training_losses, exp1_training_ucc_accuracies, exp1_val_ae_losses, exp1_val_ucc_losses, exp1_val_losses, exp1_val_ucc_accuracies = ucc_trainer.train()"
   ],
   "metadata": {
    "is_executing": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9acbbebcb3994e1e96f4791e12b8eccc",
      "f4e44fce13de4aa08a17f0eea17dbc04",
      "de82f7d7496d4a029319de55f1bbd014",
      "e889f3819c0b4ed599bb0af11ea8a3ee",
      "388443f40959439485812f398b585c33",
      "7bd8d984d5074b9397fe24bc429183e0",
      "cb72fa385f2a46aeb411cb633d601e2b",
      "0d8468985b2c497d82bf9fd50ca497d2",
      "b9c34525b44347e5b0e4471f805c1c14",
      "9f33a79a7e3647aaa44d1ed5a614c36b",
      "fee0780576014628890fe255dbfb2c84"
     ]
    },
    "id": "RnrniNW_ht_T",
    "outputId": "901b5855-0861-429b-8249-43524c1887b9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Training if required"
   ],
   "metadata": {
    "collapsed": false,
    "id": "P8d7PMEdht_U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# exp1_epoch_numbers, exp1_training_ae_losses, exp1_training_ucc_losses, exp1_training_losses, exp1_training_ucc_accuracies, exp1_val_ae_losses, exp1_val_ucc_losses, exp1_val_losses, exp1_val_ucc_accuracies = ucc_trainer.train(load_from_checkpoint=True, resume_steps=30001)"
   ],
   "metadata": {
    "is_executing": true,
    "id": "hxCh-ExNht_U",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4a1d4c7f08f9488282ac3d56c7a5d6eb",
      "44cf5f5a0e0f45fb9bfeb5df89ab19c9",
      "554c4e4f7eab4d5e8d181c1042f6643e",
      "86338526ad95464097931e28a1ff1f01",
      "e613097f270c429c9a08e20873b50cbe",
      "08ae6da7f64f4a2b89df810bbe4063a8",
      "fcf4448039224b76bd43bb15614a553c",
      "c3ca49cc02a7406e8b81a8e0a44c6544",
      "68a214699e82462f997c0df8ebe4a099",
      "76d9f4a3a25f44abac483b9307e2ff01",
      "02c3c27d0fe7453c88d797072f06a44c"
     ]
    },
    "outputId": "8244c643-a3ef-408b-fcf1-80edb9adb4c8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the model stats"
   ],
   "metadata": {
    "collapsed": false,
    "id": "WwoZVUHDht_U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ucc_model_stats(experiment1, exp1_training_ucc_losses, exp1_training_ae_losses, exp1_training_losses,\n",
    "                     exp1_training_ucc_accuracies, exp1_val_ucc_losses, exp1_val_ae_losses, exp1_val_losses,\n",
    "                     exp1_val_ucc_accuracies)"
   ],
   "metadata": {
    "is_executing": true,
    "id": "neEvotGsht_U",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "c08c0418-e784-4508-8fc6-825490a99510"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "D4GhKjJKht_U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ucc_trainer.test_model()"
   ],
   "metadata": {
    "is_executing": true,
    "id": "zl10Kxt2ht_U",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "outputId": "a780e142-8fb2-49bc-ff02-83450537da52"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Min JS Divergence"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GZnH4eRYht_U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "exp1_min_js_divg = ucc_trainer.compute_min_js_divergence()\n",
    "exp1_min_js_divg"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483,
     "referenced_widgets": [
      "10962e4181ab435e9d0fb4cb144b96d0",
      "4e4f04cf299444618b55f0203f08e645",
      "47ce7a98ce774195a983565809604023",
      "2db31df9166648f8b7a20a72bea1b5c2",
      "b98b2ece91ab4447a11029c6317a44ba",
      "f3798ac12c694e9b91e2f0e9f29bb80f",
      "4422e17c292645e4bb46155f950e75e8",
      "1a4ee2e873a347abb3ce68d752406567",
      "75a08b4bb68a43d2b001e00429a08397",
      "cd769bfb3c28418e8051f44cc9ef2212",
      "a51027f635b74774806d5089d221d83e"
     ]
    },
    "id": "B3IvdqeKle_D",
    "outputId": "2a9a2e35-7950-46c7-d6f6-8ad1e0cd9505"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating the Clustering Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "id": "lfEASpnkht_U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp1_clustering_accuracies = ucc_trainer.compute_clustering_accuracy()\n",
    "exp1_clustering_accuracies"
   ],
   "metadata": {
    "is_executing": true,
    "id": "dBTbeo4Sht_U",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "75c42f0b49954b319c7c9f1cb6a4be2b",
      "2eabb041b85245d3b406389e9780027b",
      "afcff6d9b2b0435c9b3780c20128e313",
      "51202062472f4d938cd779ec0abfab14",
      "60e6cddb67834329b3c590a170f9bf2a",
      "d7eead1b1f4748ae8787b2c60cdb896d",
      "843feef375eb48bdbb0d90e68f01cb93",
      "15b5ebf735c04cf1bf1022d405d92a1f",
      "dbbe6c87226442318e4ee0583f94f183",
      "b86b477c6eaa40158ca575720fb4ae3c",
      "8fc73f890c8846e4bd53f6de41e91a4c"
     ]
    },
    "outputId": "05437217-f7e2-492a-d218-b7d2be546aea"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "9acbbebcb3994e1e96f4791e12b8eccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4e44fce13de4aa08a17f0eea17dbc04",
       "IPY_MODEL_de82f7d7496d4a029319de55f1bbd014",
       "IPY_MODEL_e889f3819c0b4ed599bb0af11ea8a3ee"
      ],
      "layout": "IPY_MODEL_388443f40959439485812f398b585c33"
     }
    },
    "f4e44fce13de4aa08a17f0eea17dbc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bd8d984d5074b9397fe24bc429183e0",
      "placeholder": "​",
      "style": "IPY_MODEL_cb72fa385f2a46aeb411cb633d601e2b",
      "value": "Steps: 100%"
     }
    },
    "de82f7d7496d4a029319de55f1bbd014": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d8468985b2c497d82bf9fd50ca497d2",
      "max": 30000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9c34525b44347e5b0e4471f805c1c14",
      "value": 30000
     }
    },
    "e889f3819c0b4ed599bb0af11ea8a3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f33a79a7e3647aaa44d1ed5a614c36b",
      "placeholder": "​",
      "style": "IPY_MODEL_fee0780576014628890fe255dbfb2c84",
      "value": " 30000/30000 [4:29:43&lt;00:00,  1.87it/s, batch_loss=0.541, batch_ae_loss=0.0258, batch_ucc_loss=1.06, batch_ucc_acc=0.48]"
     }
    },
    "388443f40959439485812f398b585c33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "7bd8d984d5074b9397fe24bc429183e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb72fa385f2a46aeb411cb633d601e2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d8468985b2c497d82bf9fd50ca497d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9c34525b44347e5b0e4471f805c1c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "green",
      "description_width": ""
     }
    },
    "9f33a79a7e3647aaa44d1ed5a614c36b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fee0780576014628890fe255dbfb2c84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a1d4c7f08f9488282ac3d56c7a5d6eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44cf5f5a0e0f45fb9bfeb5df89ab19c9",
       "IPY_MODEL_554c4e4f7eab4d5e8d181c1042f6643e",
       "IPY_MODEL_86338526ad95464097931e28a1ff1f01"
      ],
      "layout": "IPY_MODEL_e613097f270c429c9a08e20873b50cbe"
     }
    },
    "44cf5f5a0e0f45fb9bfeb5df89ab19c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ae6da7f64f4a2b89df810bbe4063a8",
      "placeholder": "​",
      "style": "IPY_MODEL_fcf4448039224b76bd43bb15614a553c",
      "value": "Steps: 100%"
     }
    },
    "554c4e4f7eab4d5e8d181c1042f6643e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3ca49cc02a7406e8b81a8e0a44c6544",
      "max": 30000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68a214699e82462f997c0df8ebe4a099",
      "value": 30000
     }
    },
    "86338526ad95464097931e28a1ff1f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76d9f4a3a25f44abac483b9307e2ff01",
      "placeholder": "​",
      "style": "IPY_MODEL_02c3c27d0fe7453c88d797072f06a44c",
      "value": " 30000/30000 [4:31:29&lt;00:00,  1.92it/s, batch_loss=0.515, batch_ae_loss=0.0242, batch_ucc_loss=1, batch_ucc_acc=0.44]"
     }
    },
    "e613097f270c429c9a08e20873b50cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "08ae6da7f64f4a2b89df810bbe4063a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf4448039224b76bd43bb15614a553c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3ca49cc02a7406e8b81a8e0a44c6544": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68a214699e82462f997c0df8ebe4a099": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "green",
      "description_width": ""
     }
    },
    "76d9f4a3a25f44abac483b9307e2ff01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02c3c27d0fe7453c88d797072f06a44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10962e4181ab435e9d0fb4cb144b96d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e4f04cf299444618b55f0203f08e645",
       "IPY_MODEL_47ce7a98ce774195a983565809604023",
       "IPY_MODEL_2db31df9166648f8b7a20a72bea1b5c2"
      ],
      "layout": "IPY_MODEL_b98b2ece91ab4447a11029c6317a44ba"
     }
    },
    "4e4f04cf299444618b55f0203f08e645": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3798ac12c694e9b91e2f0e9f29bb80f",
      "placeholder": "​",
      "style": "IPY_MODEL_4422e17c292645e4bb46155f950e75e8",
      "value": "100%"
     }
    },
    "47ce7a98ce774195a983565809604023": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a4ee2e873a347abb3ce68d752406567",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75a08b4bb68a43d2b001e00429a08397",
      "value": 1000
     }
    },
    "2db31df9166648f8b7a20a72bea1b5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd769bfb3c28418e8051f44cc9ef2212",
      "placeholder": "​",
      "style": "IPY_MODEL_a51027f635b74774806d5089d221d83e",
      "value": " 1000/1000 [00:33&lt;00:00, 36.27it/s]"
     }
    },
    "b98b2ece91ab4447a11029c6317a44ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3798ac12c694e9b91e2f0e9f29bb80f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4422e17c292645e4bb46155f950e75e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a4ee2e873a347abb3ce68d752406567": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75a08b4bb68a43d2b001e00429a08397": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd769bfb3c28418e8051f44cc9ef2212": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51027f635b74774806d5089d221d83e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75c42f0b49954b319c7c9f1cb6a4be2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eabb041b85245d3b406389e9780027b",
       "IPY_MODEL_afcff6d9b2b0435c9b3780c20128e313",
       "IPY_MODEL_51202062472f4d938cd779ec0abfab14"
      ],
      "layout": "IPY_MODEL_60e6cddb67834329b3c590a170f9bf2a"
     }
    },
    "2eabb041b85245d3b406389e9780027b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7eead1b1f4748ae8787b2c60cdb896d",
      "placeholder": "​",
      "style": "IPY_MODEL_843feef375eb48bdbb0d90e68f01cb93",
      "value": "100%"
     }
    },
    "afcff6d9b2b0435c9b3780c20128e313": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15b5ebf735c04cf1bf1022d405d92a1f",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbbe6c87226442318e4ee0583f94f183",
      "value": 1000
     }
    },
    "51202062472f4d938cd779ec0abfab14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b86b477c6eaa40158ca575720fb4ae3c",
      "placeholder": "​",
      "style": "IPY_MODEL_8fc73f890c8846e4bd53f6de41e91a4c",
      "value": " 1000/1000 [00:15&lt;00:00, 72.28it/s]"
     }
    },
    "60e6cddb67834329b3c590a170f9bf2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7eead1b1f4748ae8787b2c60cdb896d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843feef375eb48bdbb0d90e68f01cb93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15b5ebf735c04cf1bf1022d405d92a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbbe6c87226442318e4ee0583f94f183": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b86b477c6eaa40158ca575720fb4ae3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fc73f890c8846e4bd53f6de41e91a4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
